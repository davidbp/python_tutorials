{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow Operations\n",
    "\n",
    "This notebook contains 4 main parts. \n",
    "\n",
    "- constants in tensorflow\n",
    "- variables in tensorflow\n",
    "- placeholders in tensorflow\n",
    "- Saving and restoring graphs\n",
    "\n",
    "##### Overview \n",
    "\n",
    "Tensorflow has two main objects that are used when building code. The graph and the session. If your code can be naturally separated in those two parts then probably tensorflow is a good fit. What are graphs and sessions though?\n",
    "\n",
    "A graph is a set of nodes and edges. In tensorflow graphs define computations but do not compute anything. Graphs don't hold values (except for constants), they simply define what to do with the data. \n",
    "\n",
    "- Example: A Linear regression can be represented as a graph. There is a variable `w` containing the weights of each of the features and a bias variable `b`. Both `w` and `b` are naturally defined as `tf.variable` objects. Inside the graph it is also natural to define operations to change the variables of the graph, such as the weights and bias (using the gradient of the mean squared error for example). This operations are defined in the graph but they are not executed now (this is done inside the session, explained below).\n",
    "\n",
    "Once a computation, or a model, is defined we might want to execute it (or do the computation). This is when sessions are nedded. A session is paired with a graph and inside the session the operations on the graph can be executed.  When the session is open with a particular graph the resources are allocated (memory for storing the variables for example). Once the session is closed this resources are freed.\n",
    "\n",
    "- Going back to our previous example: Once the linear regression graph is defined we can pass data and execute a particular computation, for example `update_model`.\n",
    "\n",
    "\n",
    "#### Let us recall about sessions and tensor operations..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.13.0', '1.2.0')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib  import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "np.__version__, tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value in x:  4\n"
     ]
    }
   ],
   "source": [
    "# Let us recall the different parts of a tensorflow program\n",
    "# 1) A graph defining operations\n",
    "# 2) A session that takes a graph and evaluates (fetches) variables, in this case, x\n",
    "a = tf.constant(2)\n",
    "b = tf.constant(2)\n",
    "x = tf.add(a,b)\n",
    "with tf.Session() as sess:\n",
    "    print(\"value in x: \",sess.run(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value in x:  4\n"
     ]
    }
   ],
   "source": [
    "# inside the with tf.Session as sess statement \n",
    "# sess.run(x) is the same as x.eval() \n",
    "with tf.Session() as sess:\n",
    "    print(\"value in x: \", x.eval())  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard\n",
    "\n",
    "We can visualize our session using tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant(2, name=\"Pedro\")\n",
    "b = tf.constant(2, name=\"Maria\")\n",
    "x = tf.add(a,b, name=\"add\")\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    writer = tf.summary.FileWriter(\"./graphs\", sess.graph)\n",
    "    \n",
    "    print(sess.run(x))\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the terminal you can write\n",
    "\n",
    "    tensorboard --logdir=\"./graphs\" --port 6006\n",
    "    \n",
    "Then open your browser and go to\n",
    " \n",
    "    http://localhost:6006/\n",
    "    \n",
    "Inside the GRAPHS tab (at the top) you can see the operation graph of the add operation defined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About tf.constant constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = tf.constant([[1, 2]], name=\"a\")\n",
    "b = tf.constant([[0, 1], [2, 3]], name=\"b\")\n",
    "x = tf.add(a, b, name=\"add\")\n",
    "y = tf.multiply(a, b, name=\"multiply\")\n",
    "z = tf.matmul(a, b, name=\"matmul\")\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    x_val, y_val, z_val = sess.run([x, y, z])\n",
    "    print(\"x val: \\n\",  x_val, \"\\ny_val: \\n\", y_val, \"\\nz_val: \\n\", z_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling tensor with zeros, ones or a specified value\n",
    "\n",
    "Some usefull functions\n",
    "\n",
    "- `tf.zeros(shape, dtype=tf.float32, name=None)`\n",
    "\n",
    "- `tf.ones(shape, dtype=tf.float32, name=None)`\n",
    "\n",
    "- `tf.zeros_like(input_tensor, dtype=None, name=None, optimize=True)`\n",
    "\n",
    "- `tf.ones_like(input_tensor, dtype=None, name=None, optimize=True)`\n",
    "\n",
    "- `tf.fill(dims, value, name=None)`\n",
    "\n",
    "Example\n",
    "\n",
    "     tf.fill([2,3],5) ===> [[5,5,5], [5,5,5]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aux = np.zeros((2,3))\n",
    "aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.zeros_like(aux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#like np.zeros\n",
    "input_tensor = tf.zeros(shape=[2,3], dtype=tf.float32, name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# like np.zeros_like\n",
    "tf.zeros_like(input_tensor, dtype=None, name=None, optimize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranges\n",
    "\n",
    "- `tf.linspace`\n",
    "\n",
    "- `tf.range`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get `num` equally spaced points between `start` and `stop`\n",
    "aux = tf.linspace(start=1., stop=10., num=5, name=None) \n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(\"value in x: \", aux.eval())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aux = tf.range(start=5, limit=15, delta=2) \n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(\"value in x: \", aux.eval())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aux = tf.range(20) \n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(\"value in x: \", aux.eval())  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomly generated constants\n",
    "\n",
    "- `tf.random_normal(shape, mean=0.0, stddev=1.0, dtype=tf.float32, seed=None, name=None)`\n",
    "\n",
    "- `tf.truncated_normal(shape, mean=0.0, stddev=1.0, dtype=tf.float32, seed=None, name=None)`\n",
    "\n",
    "- `tf.random_uniform(shape, minval=0, maxval=None, dtype=tf.float32, seed=None, name=None)`\n",
    "\n",
    "- `tf.radon_shuffle(value, seed=None, name=None)`\n",
    "\n",
    "- `tf.random_crop(value, size, seed=None, name=None)`\n",
    "\n",
    "- `tf.multinomial(logits, num_samples, seed=None, name=None)`\n",
    "\n",
    "- `tf.random_gamma(shape, alpha, beta=None, dtype=tf.float32, seed=None, name=None)`\n",
    "\n",
    "\n",
    "##### Reproducible results\n",
    "\n",
    "- `tf.set_random_seed(seed)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "x = tf.random_normal(shape=(10,2), mean=0.0, stddev=1.0,seed=123)\n",
    "with tf.Session() as sess:\n",
    "    print(\"value in x: \", x.eval())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "x = tf.random_normal(shape=(10,2), mean=0.0, stddev=1.0,seed=123)\n",
    "with tf.Session() as sess:\n",
    "    print(\"value in x: \", x.eval())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "x = tf.random_normal(shape=(10,2), mean=0.0, stddev=1.0)\n",
    "with tf.Session() as sess:\n",
    "    print(\"value in x: \", x.eval())  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Be carefull with constants\n",
    "\n",
    "Important:\n",
    "\n",
    "**Only use constants for primitive types.\n",
    "Use variables or readers for more data that \n",
    "requires more memory**\n",
    "\n",
    "- Constants are stored in the graph definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "import tensorflow as tf\n",
    "# you will see value of my_const stored in the graphâ€™s definition\n",
    "my_const = tf.constant([1.0], name=\"my_const\")\n",
    "with tf.Session() as sess:\n",
    "    print(sess.graph.as_graph_def())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "g2 = tf.Graph()\n",
    "with g2.as_default():\n",
    "    my_const = tf.constant([1.0], name=\"my_const\")\n",
    "    \n",
    "print(g2.as_graph_def())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About variables\n",
    "\n",
    "Variables need to be initialized in a session, if you want to evaluate them. By evaluating we mean  to compute variable.eval() or sess.run(variable).\n",
    "\n",
    "The following cell is an example where we want to evaluate `f` which depends on variables not initialized. Therefore the code will not work.\n",
    "\n",
    "##### How to initialize a variable\n",
    "\n",
    "To initialize a variable `x` use\n",
    "\n",
    "    sess.run(x.initializer)\n",
    "    \n",
    "To initialize a variable `x` in a `with` statement\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        x.initializer.run()\n",
    "\n",
    "##### How to initialize a subset of variables\n",
    "\n",
    "    init_ab = tf.variables_initializer([a, b], name=\"init_ab\")\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init_ab)\n",
    "\n",
    "##### How to initialize all variables in a session\n",
    "\n",
    "To initialize all variables in a session use\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = tf.Variable(3, name=\"x\")\n",
    "y = tf.Variable(4, name=\"y\")\n",
    "f = x * y + y + 1\n",
    "\n",
    "# This won't work, since variables have not been initialized in the session\n",
    "sess = tf.Session()\n",
    "result = sess.run(f)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we initialize the variables the code will work as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.Variable(3, name=\"x\")\n",
    "y = tf.Variable(4, name=\"y\")\n",
    "f = x * y + y + 1\n",
    "\n",
    "# This won't work, since variables have not been initialized in the session\n",
    "sess = tf.Session()\n",
    "sess.run(x.initializer)\n",
    "sess.run(y.initializer)\n",
    "result = sess.run(f)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.Variable(3, name=\"x\")\n",
    "y = tf.Variable(4, name=\"y\")\n",
    "f = x * y + y + 1\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(x.initializer)\n",
    "    sess.run(y.initializer)\n",
    "    result = sess.run(f)\n",
    "    print(result)\n",
    "    \n",
    "with tf.Session() as sess:\n",
    "    x.initializer.run()\n",
    "    y.initializer.run()\n",
    "    result = sess.run(f)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing all variables with `tf.global_variables_initializer()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    result = sess.run(f)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating a variable\n",
    "\n",
    "Recall that `var.eval()` is the same as `sess.run(W)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.truncated_normal([700, 10]))\n",
    "with tf.Session() as sess:\n",
    "    sess.run(W.initializer)\n",
    "    print(W.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.truncated_normal([700, 10]))\n",
    "with tf.Session() as sess:\n",
    "    sess.run(W.initializer)\n",
    "    print(sess.run(W))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tf.Variable.assing()\n",
    "\n",
    "This function allows to initialize and assign a value to a variable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(3.14)\n",
    "W.assign(10)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(W.initializer)   # Will print 3.14 since its the initial variable def \n",
    "    print(W.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(3.14)\n",
    "assign_op = W.assign(10)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(assign_op)   # running the assign operation we wrote 10 inside variable W\n",
    "    print(W.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a variable whose original value is 2\n",
    "my_var = tf.Variable(2, name=\"my_var\") \n",
    "# assign a * 2 to a and call that op a_times_two\n",
    "my_var_times_two = my_var.assign(2 * my_var)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(my_var.initializer)\n",
    "    print(sess.run(my_var_times_two))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a variable whose original value is 2\n",
    "my_var = tf.Variable(2, name=\"my_var\") \n",
    "# assign a * 2 to a and call that op a_times_two\n",
    "my_var_times_two = my_var.assign(2 * my_var)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(my_var.initializer)\n",
    "    print(sess.run(my_var_times_two)) # >> 4\n",
    "    print(sess.run(my_var_times_two)) # >> 8\n",
    "    print(sess.run(my_var_times_two)) # >> 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Session vs InteractiveSession\n",
    "\n",
    "You sometimes see InteractiveSession instead of Session\n",
    "\n",
    "The only difference is an InteractiveSession makes itself the default "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "a = tf.constant(5.0)\n",
    "b = tf.constant(6.0)\n",
    "c = a * b\n",
    "# We can just use 'c.eval()' without specifying the context 'sess'\n",
    "print(c.eval())\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Placeholders\n",
    "\n",
    "```python\n",
    "    tf.placeholder(dtype, shape=None, name=None)\n",
    "```\n",
    "\n",
    "#### Some notes on placeholders and variables\n",
    "\n",
    "- tf.Variable needs an initial value when you declare it.\n",
    "- tf.Variable values are saved in the graph of a session (and require initial values)\n",
    "- tf.placeholder doesn't need an initial value, it is specified at run time with the feed_dict argument inside Session.run, the values of a placeholder are never saved.\n",
    "\n",
    "#### Why the distinction\n",
    "\n",
    "It comes naturally from the context in which tensorflow was build. Variables will usually be the parameters of our models. We can (and only need to) save or restore the Variables to save or rebuild the graph.\n",
    "\n",
    "Placeholders are mostly holders for the different datasets (for example training data or test data) but Variables are trained in the training process and remain the same (to predict the outcome of the input or map the inputs and outputs[labels] of the samples) later until you retrain the model(using different or the same samples to fill into the Placeholders often through the dict, for instance session.run(a_graph, dict={a_placeholder_name: sample_values}), Placeholders are also passed as parameters to set models).\n",
    "\n",
    "To sum up, if the values are from the samples (observations you already have) you safely make a placeholder to hold them, while if you need a parameter to be trained harness a Variable (simply put, set the Variables for the values you want to get using TF automatically). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a placeholder of type float 32-bit, shape is a vector of 3 elements\n",
    "a = tf.placeholder(tf.float32, shape=[3])\n",
    "\n",
    "# create a constant of type float 32-bit, shape is a vector of 3 elements\n",
    "b = tf.constant([5, 5, 5], tf.float32)\n",
    "\n",
    "# use the placeholder as you would a constant or a variable\n",
    "c = a + b  # Short for tf.add(a, b)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # feed [1, 2, 3] to placeholder a via the dict {a: [1, 2, 3]} fetch value of c\n",
    "    print(sess.run(c, {a: [1, 2, 3]}))\n",
    "    print(sess.run(c, {a: [0, 1, 1]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "You can feed_dict any feedable tensor.\n",
    "Placeholder is just a way to indicate that \n",
    "something must be fed\n",
    "\n",
    "```\n",
    "tf.Graph.is_feedable(tensor) \n",
    "```\n",
    "\n",
    "This can be helpful for debugging or testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create operations, tensors, etc (using the default graph)\n",
    "a = tf.add(2, 5)\n",
    "b = tf.multiply(a, 3)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # define a dictionary that says to replace the value of 'a' with 15\n",
    "    replace_dict = {a: 15}\n",
    "    # Run the session, passing in 'replace_dict' as the value to 'feed_dict'\n",
    "    print(sess.run(b, feed_dict=replace_dict)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Be carefull with lazy evaluation\n",
    "\n",
    "#### The following cell is GOOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.Variable(10, name='x')\n",
    "y = tf.Variable(20, name='y')\n",
    "z = tf.add(x, y) # you create the node for add node before executing the graph\n",
    "\n",
    "#graph = tf.Graph([x,y,z])\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    writer = tf.summary.FileWriter('./my_graph/l2', sess.graph)\n",
    "    for _ in range(10):\n",
    "        sess.run(z)\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The following cell is BAD!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.Variable(10, name='x')\n",
    "y = tf.Variable(20, name='y')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    writer = tf.summary.FileWriter('./my_graph/l2', sess.graph)\n",
    "    for _ in range(10):\n",
    "        sess.run(tf.add(x, y)) # someone decides to be clever to save one line of code\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why is the second answer bad?\n",
    "\n",
    "Both give the same value of z.\n",
    "\n",
    "In the first case tensorflow knows beforehand that z = x+y, once the session is started the memory for z is allocated. z is evaluated 10 times but there is no need to allocate 10 times memory.\n",
    "\n",
    "In the second case while running the session  tf.add(x,y) is evaluated 10 times and there are 10 allocations \"for z\".\n",
    "\n",
    "\n",
    "#### How to use tensroflow properly\n",
    "\n",
    "- Separate definition of ops from computing/running ops \n",
    "- Use Python property to ensure function is also loaded once the first time it is called"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and restoring graphs\n",
    "\n",
    "Tensorflow is build to facilitate saving models to disk, during execution (just in case your computer crashes) or at the end of the execution.\n",
    "\n",
    "To save a graph you need to use a `Saver` node at the end of the construction phase (after all nodes are created). During execution `save()` must be called to save the model, passing as argument the session and the path of the checkpoint file.\n",
    "\n",
    "\n",
    "- `tf.train.Saver()`: to save the session\n",
    "     \n",
    "- `saver.restore(sess, path_to_ckpt)`: to restore a session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "x = tf.Variable(10, name='x')\n",
    "y = tf.Variable(10, name='y')\n",
    "saver = tf.train.Saver({\"x\":x, \"y\":y})\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver.save(sess, \"./saved_tests/my_save_test_begin.cpkt\")\n",
    "    print(sess.run(x))\n",
    "    x = x + 1\n",
    "    saver.save(sess, \"./saved_tests/my_save_test_final.cpkt\")\n",
    "    print(sess.run(x))\n",
    "    y=y+23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Restoring with save.restore\n",
    "Restoring a model is as easy as calling saver.restore()\n",
    "\n",
    "After a session is closed, we can open a new session and use `save.restore\n",
    "\n",
    "!!! DONT GET WHY x is 11 at my_save_test_begin since x = x+1 happens after saver.save()\n",
    "is executed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    s= saver.restore(sess, \"./saved_tests/my_save_test_begin.cpkt\")\n",
    "    sess.graph\n",
    "    print(sess.run(x))\n",
    "    print(sess.run(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./saved_tests/my_save_test_final.cpkt\")\n",
    "    print(sess.run(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default a Saver saves and restores all variables under their own name defined in the curresnt session. For more control, you can specify which variables to save or restore, and even what names to use.\n",
    "\n",
    "For example the following Saver will save or restore only the x\n",
    "variable under the name \"x\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    x = tf.Variable(10, name='x')\n",
    "    y = tf.Variable(10, name='y')\n",
    "    saver = tf.train.Saver()\n",
    "    x = x + 10\n",
    "    \n",
    "with tf.Session(graph=g) as sess:\n",
    "    # The first time we use the graph we need to initialize the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver.save(sess, \"./saved_tests/notebook_2_print_x.cpkt\")\n",
    "    print(sess.run(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session(graph=g) as sess:\n",
    "    saver.restore(sess, \"./saved_tests/notebook_2_print_x.cpkt\")\n",
    "    #sess.run(tf.global_variables_initializer())\n",
    "    x = x + 20\n",
    "    z = x + 100\n",
    "    print(sess.run(x))\n",
    "    print(sess.run(y))\n",
    "    #saver.save(sess, \"./saved_tests/notebook_2_print_x.cpkt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can continue working with the graph later on and if we canged previously variables (for example weights of a model) the changes will be kept.\n",
    "\n",
    "The question is... how do we store the graph to disk?\n",
    "\n",
    "Besides "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Session(graph=g) as sess:\n",
    "    saver.restore(sess, \"./saved_tests/notebook_2_print_x.cpkt\")\n",
    "    print(sess.run(x))\n",
    "    print(sess.run(y))\n",
    "    print(sess.run(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### About saving and restoring models \n",
    "- http://www.vishakhhegde.com/savegraphtensorflow.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## About tf.slice\n",
    "\n",
    "- `tf.slice` allow us to get an slice (or subset) of a variable.\n",
    "\n",
    "We can use `tf.slice` on a placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2]\n",
      " [11 21]\n",
      " [11 21]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "ph = tf.placeholder(shape=[None,None], dtype=tf.int32)\n",
    "\n",
    "# look the -1 in the first position\n",
    "x = tf.slice(ph, [0, 0], [-1, 2])\n",
    "\n",
    "input_ = np.array([[ 1, 2, 3, 4, 5, 6, 7, 8],\n",
    "                   [11,21,31,41,51,61,71,81],\n",
    "                   [11,21,31,41,51,61,71,81]])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(x, feed_dict={ph: input_}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3  4  5  6]\n",
      " [31 41 51 61]\n",
      " [31 41 51 61]]\n"
     ]
    }
   ],
   "source": [
    "x = tf.slice(ph, [0,2], [-1,4])\n",
    "\n",
    "input_ = np.array([[ 1, 2, 3, 4, 5, 6, 7, 8],\n",
    "                   [11,21,31,41,51,61,71,81],\n",
    "                   [11,21,31,41,51,61,71,81]])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        print(sess.run(x, feed_dict={ph: input_}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelling a heap in tensorflow \n",
    "\n",
    "The following example shows how to from a matrix [1,400]\n",
    "1) get the last 4 elements and save then in the variable `get_last_visible_vector`\n",
    "2) Get 396 elements from position 4 up to position 400 save them in `history_pop_oldest_vis_vector`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "History with oldest vis vector out\n",
      "[[396 397 398 399]]\n",
      "\n",
      "History with oldest vis vector out\n",
      "[[  4   5   6   7   8   9  10  11  12  13  14  15  16  17  18  19  20  21\n",
      "   22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39\n",
      "   40  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57\n",
      "   58  59  60  61  62  63  64  65  66  67  68  69  70  71  72  73  74  75\n",
      "   76  77  78  79  80  81  82  83  84  85  86  87  88  89  90  91  92  93\n",
      "   94  95  96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111\n",
      "  112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129\n",
      "  130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147\n",
      "  148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165\n",
      "  166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183\n",
      "  184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201\n",
      "  202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219\n",
      "  220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237\n",
      "  238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255\n",
      "  256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273\n",
      "  274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291\n",
      "  292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309\n",
      "  310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327\n",
      "  328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345\n",
      "  346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363\n",
      "  364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381\n",
      "  382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399]]\n",
      "History with oldest vis vector out shape: (1, 396)\n"
     ]
    }
   ],
   "source": [
    "n_his = 400\n",
    "n_vis = 4\n",
    "\n",
    "pla_his = tf.placeholder(shape=[None,None], dtype=tf.int32)\n",
    "get_last_visible_vector = tf.slice(pla_his, [0, n_his - n_vis], [-1, n_vis])\n",
    "get_history_pop_oldest_vis_vector = tf.slice(pla_his, [0, n_vis], [-1, n_his - n_vis])\n",
    "input_ = np.array([range(0,400)])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        print(\"\\nHistory with oldest vis vector out\")\n",
    "        print(sess.run(get_last_visible_vector, feed_dict={pla_his: input_}))\n",
    "        print(\"\\nHistory with oldest vis vector out\")\n",
    "        history_pop_oldest_vis_vector = sess.run(get_history_pop_oldest_vis_vector, feed_dict={pla_his: input_})\n",
    "        print(sess.run(get_history_pop_oldest_vis_vector, feed_dict={pla_his: input_}))\n",
    "        print(\"History with oldest vis vector out shape:\", history_pop_oldest_vis_vector.shape)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell shows how to go from $h_0 = [1,2,3,4,...,400]$ up to $h_1 = [4,5,6,...,404]$ by eliminating the first 4 elements of $h_0$ and  adding 4 elements to $h_1$. This can be usefull for creating \"heaps\" that push out elements and get in elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   4.    5.    6.    7.    8.    9.   10.   11.   12.   13.   14.   15.\n",
      "    16.   17.   18.   19.   20.   21.   22.   23.   24.   25.   26.   27.\n",
      "    28.   29.   30.   31.   32.   33.   34.   35.   36.   37.   38.   39.\n",
      "    40.   41.   42.   43.   44.   45.   46.   47.   48.   49.   50.   51.\n",
      "    52.   53.   54.   55.   56.   57.   58.   59.   60.   61.   62.   63.\n",
      "    64.   65.   66.   67.   68.   69.   70.   71.   72.   73.   74.   75.\n",
      "    76.   77.   78.   79.   80.   81.   82.   83.   84.   85.   86.   87.\n",
      "    88.   89.   90.   91.   92.   93.   94.   95.   96.   97.   98.   99.\n",
      "   100.  101.  102.  103.  104.  105.  106.  107.  108.  109.  110.  111.\n",
      "   112.  113.  114.  115.  116.  117.  118.  119.  120.  121.  122.  123.\n",
      "   124.  125.  126.  127.  128.  129.  130.  131.  132.  133.  134.  135.\n",
      "   136.  137.  138.  139.  140.  141.  142.  143.  144.  145.  146.  147.\n",
      "   148.  149.  150.  151.  152.  153.  154.  155.  156.  157.  158.  159.\n",
      "   160.  161.  162.  163.  164.  165.  166.  167.  168.  169.  170.  171.\n",
      "   172.  173.  174.  175.  176.  177.  178.  179.  180.  181.  182.  183.\n",
      "   184.  185.  186.  187.  188.  189.  190.  191.  192.  193.  194.  195.\n",
      "   196.  197.  198.  199.  200.  201.  202.  203.  204.  205.  206.  207.\n",
      "   208.  209.  210.  211.  212.  213.  214.  215.  216.  217.  218.  219.\n",
      "   220.  221.  222.  223.  224.  225.  226.  227.  228.  229.  230.  231.\n",
      "   232.  233.  234.  235.  236.  237.  238.  239.  240.  241.  242.  243.\n",
      "   244.  245.  246.  247.  248.  249.  250.  251.  252.  253.  254.  255.\n",
      "   256.  257.  258.  259.  260.  261.  262.  263.  264.  265.  266.  267.\n",
      "   268.  269.  270.  271.  272.  273.  274.  275.  276.  277.  278.  279.\n",
      "   280.  281.  282.  283.  284.  285.  286.  287.  288.  289.  290.  291.\n",
      "   292.  293.  294.  295.  296.  297.  298.  299.  300.  301.  302.  303.\n",
      "   304.  305.  306.  307.  308.  309.  310.  311.  312.  313.  314.  315.\n",
      "   316.  317.  318.  319.  320.  321.  322.  323.  324.  325.  326.  327.\n",
      "   328.  329.  330.  331.  332.  333.  334.  335.  336.  337.  338.  339.\n",
      "   340.  341.  342.  343.  344.  345.  346.  347.  348.  349.  350.  351.\n",
      "   352.  353.  354.  355.  356.  357.  358.  359.  360.  361.  362.  363.\n",
      "   364.  365.  366.  367.  368.  369.  370.  371.  372.  373.  374.  375.\n",
      "   376.  377.  378.  379.  380.  381.  382.  383.  384.  385.  386.  387.\n",
      "   388.  389.  390.  391.  392.  393.  394.  395.  396.  397.  398.  399.\n",
      "   -99.  -99.  -99.  -99.]]\n"
     ]
    }
   ],
   "source": [
    "n_his = 400\n",
    "n_vis = 4\n",
    "\n",
    "tf.reset_default_graph()\n",
    "var_history = tf.get_variable(\"var_history\", \n",
    "                              dtype=np.float32, \n",
    "                              initializer=np.array([range(0,400)], \"float32\")) \n",
    "\n",
    "var_all_but_oldest_history = tf.get_variable(\"var_all_but_oldest_history\", \n",
    "                              dtype=np.float32, shape=(1, n_his-n_vis)) \n",
    "\n",
    "get_history_pop_oldest_vis_vector = tf.slice(var_history, [0, n_vis], [-1, n_his - n_vis])\n",
    "#var_history[0][0:n_vis] = var_history[]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        #print(sess.run(var_history))\n",
    "        \n",
    "        #var_history[0][0:n_his-n_vis] = var_history[0][n_vis:n_his] \n",
    "        #var_history.assign([0,0],100)\n",
    "        sess.run(var_all_but_oldest_history.assign(var_history[0:1, n_vis:n_his]))\n",
    "        sess.run(var_history[0:1, 0:n_his - n_vis].assign(var_all_but_oldest_history))\n",
    "        current_vis_vec = np.array([[-99,-99,-99,-99]], dtype=\"float32\")\n",
    "        sess.run(var_history[0:1, n_his-n_vis:n_his].assign(current_vis_vec))\n",
    "        \n",
    "        #print(sess.run(var_all_but_oldest_history))\n",
    "        print(sess.run(var_history))\n",
    "\n",
    "        #print(sess.run(get_history_pop_oldest_vis_vector ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  40.   41.   42.   43.   44.   45.   46.   47.   48.   49.   50.   51.\n",
      "    52.   53.   54.   55.   56.   57.   58.   59.   60.   61.   62.   63.\n",
      "    64.   65.   66.   67.   68.   69.   70.   71.   72.   73.   74.   75.\n",
      "    76.   77.   78.   79.   80.   81.   82.   83.   84.   85.   86.   87.\n",
      "    88.   89.   90.   91.   92.   93.   94.   95.   96.   97.   98.   99.\n",
      "   100.  101.  102.  103.  104.  105.  106.  107.  108.  109.  110.  111.\n",
      "   112.  113.  114.  115.  116.  117.  118.  119.  120.  121.  122.  123.\n",
      "   124.  125.  126.  127.  128.  129.  130.  131.  132.  133.  134.  135.\n",
      "   136.  137.  138.  139.  140.  141.  142.  143.  144.  145.  146.  147.\n",
      "   148.  149.  150.  151.  152.  153.  154.  155.  156.  157.  158.  159.\n",
      "   160.  161.  162.  163.  164.  165.  166.  167.  168.  169.  170.  171.\n",
      "   172.  173.  174.  175.  176.  177.  178.  179.  180.  181.  182.  183.\n",
      "   184.  185.  186.  187.  188.  189.  190.  191.  192.  193.  194.  195.\n",
      "   196.  197.  198.  199.  200.  201.  202.  203.  204.  205.  206.  207.\n",
      "   208.  209.  210.  211.  212.  213.  214.  215.  216.  217.  218.  219.\n",
      "   220.  221.  222.  223.  224.  225.  226.  227.  228.  229.  230.  231.\n",
      "   232.  233.  234.  235.  236.  237.  238.  239.  240.  241.  242.  243.\n",
      "   244.  245.  246.  247.  248.  249.  250.  251.  252.  253.  254.  255.\n",
      "   256.  257.  258.  259.  260.  261.  262.  263.  264.  265.  266.  267.\n",
      "   268.  269.  270.  271.  272.  273.  274.  275.  276.  277.  278.  279.\n",
      "   280.  281.  282.  283.  284.  285.  286.  287.  288.  289.  290.  291.\n",
      "   292.  293.  294.  295.  296.  297.  298.  299.  300.  301.  302.  303.\n",
      "   304.  305.  306.  307.  308.  309.  310.  311.  312.  313.  314.  315.\n",
      "   316.  317.  318.  319.  320.  321.  322.  323.  324.  325.  326.  327.\n",
      "   328.  329.  330.  331.  332.  333.  334.  335.  336.  337.  338.  339.\n",
      "   340.  341.  342.  343.  344.  345.  346.  347.  348.  349.  350.  351.\n",
      "   352.  353.  354.  355.  356.  357.  358.  359.  360.  361.  362.  363.\n",
      "   364.  365.  366.  367.  368.  369.  370.  371.  372.  373.  374.  375.\n",
      "   376.  377.  378.  379.  380.  381.  382.  383.  384.  385.  386.  387.\n",
      "   388.  389.  390.  391.  392.  393.  394.  395.  396.  397.  398.  399.\n",
      "     9.    9.    9.    9.    9.    9.    9.    9.    9.    9.    9.    9.\n",
      "     9.    9.    9.    9.    9.    9.    9.    9.    9.    9.    9.    9.\n",
      "     9.    9.    9.    9.    9.    9.    9.    9.    9.    9.    9.    9.\n",
      "     9.    9.    9.    9.]]\n"
     ]
    }
   ],
   "source": [
    "n_his = 400\n",
    "n_vis = 4\n",
    "\n",
    "tf.reset_default_graph()\n",
    "var_history = tf.get_variable(\"var_history\", \n",
    "                              dtype=np.float32, \n",
    "                              initializer=np.array([range(0,400)], \"float32\")) \n",
    "\n",
    "var_all_but_oldest_history = tf.get_variable(\"var_all_but_oldest_history\", \n",
    "                              dtype=np.float32, shape=(1, n_his-n_vis)) \n",
    "\n",
    "#get_history_pop_oldest_vis_vector = tf.slice(var_history, [0, n_vis], [-1, n_his - n_vis])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in range(10):\n",
    "        sess.run(var_all_but_oldest_history.assign(var_history[0:1, n_vis:n_his]))\n",
    "        sess.run(var_history[0:1, 0:n_his - n_vis].assign(var_all_but_oldest_history))\n",
    "        ## current_vis_vec = \"predict(current_vis_vec, his_current)\"\n",
    "        #current_vis_vec = np.array([[i,i,i,i]], dtype=\"float32\")\n",
    "        \n",
    "        sess.run(var_history[0:1, n_his-n_vis:n_his].assign(current_vis_vec))       \n",
    "    print(sess.run(var_history))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
