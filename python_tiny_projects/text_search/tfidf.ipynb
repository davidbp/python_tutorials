{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T18:53:30.669193Z",
     "start_time": "2021-03-21T18:53:28.528848Z"
    }
   },
   "outputs": [],
   "source": [
    "#import logging\n",
    "#import codecs\n",
    "#import glob\n",
    "#import logging\n",
    "#import multiprocessing\n",
    "import os\n",
    "import pprint\n",
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More  document features\n",
    "\n",
    "\n",
    "We will denote by\n",
    "\n",
    "- $W= \\{w_1, \\dots, w_D\\}$ the set of words used to make the representations.\n",
    "- $X$ our corpus of documents.\n",
    "- $X_w$ the set of documents that contain word $w$. \n",
    "\n",
    "### Bag of words vector  (or `tf` vector)\n",
    "\n",
    "\n",
    "- The bag of words representation for a document $x$ given a vocabulary $W$, or the term frequency vector **$\\text{tf}(X;W)$** is defined as \n",
    "\n",
    "$$\n",
    "\\text{tf}(x;W) = \\left( \\#\\{w_1| w_1 \\in x\\}, \\dots, \\#\\{w_D| w_D \\in x\\})\\right)\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "### Term frequency Inverse Document frequency ( `tf * idf`)\n",
    "\n",
    "The objective of tf-idf representation is to emphasize the most relevant words of the documents. We want to emphasize:\n",
    "\n",
    "- Words that appear **frequently in the document**: term frequency \n",
    "- Words that appear **rarely in the corpus**: inverse document frequency\n",
    "\n",
    "#### Definition of the feature vectors\n",
    "\n",
    "\n",
    "- The **$\\text{tf}(X;W)$** vector for a document $x$ is defined as \n",
    "\n",
    "$$\n",
    "\\text{tf}(x;W) = \\left( \\#\\{w_1| w_1 \\in x\\}, \\dots, \\#\\{w_D| w_D \\in x\\})\\right)\n",
    "$$\n",
    "\n",
    "- The **$\\text{idf}(W; X)$** vector is defined as \n",
    "\n",
    "**$$\\text{idf}(W; X) = \\left( \\text{idf}(w_1; X), \\dots, \\text{idf}(w_D; X)\\right)$$** \n",
    "   \n",
    "$\\,\\,\\,\\,\\,\\,\\,$ A component of the feature for word $w \\in W$ in the corpus $X$ is defined as \n",
    "\n",
    "$$\n",
    "\\text{idf}(w, X) = log\\left(\\frac{|X|}{1+|X_{w}|}\\right)\n",
    "$$\n",
    "\n",
    "$\\,\\,\\,\\,\\,\\,\\,$Which simply means the full vector is \n",
    "$$\n",
    "\\text{idf}(w, X) = \\left( log\\left(\\frac{|X|}{1+|X_{w_1}|}\\right), \\dots, log\\left(\\frac{|X|}{1+|X_{w_D}|}\\right) \\right)\n",
    "$$\n",
    "\n",
    "- The tfidf vector for a document $x$ will be: $tf(x; X) * idf(X)$\n",
    "\n",
    "#### Observations\n",
    "\n",
    "- If a word appears in a few documents the idf vector will increase its weight.\n",
    "\n",
    "- If a word appears in a lots of documents documents the idf vector will decrease its weight.\n",
    "\n",
    "#### `sklearn.feature_extraction.text.TfidfVectorizer`\n",
    "\n",
    "- Notice that the implementation in sklearn already prevents zero divisions by default. This happens if `smooth_idf=True`.\n",
    "\n",
    "- By default the tfidf will only use words since `ngram_range=(1, 1)`. But this can be changed to allow n-grams in the feature vector components.\n",
    "\n",
    "#### Example\n",
    "\n",
    "Let us assume we have a corpus with one milion documents\n",
    "\n",
    "- Consider a word appearping in 100 documents:\n",
    "\n",
    "$$\\log\\left(\\frac{1000.000}{1 + 100} \\right) = 9.200$$\n",
    "\n",
    "- Consider a word appearing in 100.000 documents\n",
    "\n",
    "$$\\log\\left(\\frac{1000.000}{1 + 100.000} \\right) = 2.197$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T18:54:45.276853Z",
     "start_time": "2021-03-21T18:54:45.272770Z"
    }
   },
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "\n",
    "def build_vocabulary(corpus, splitter):\n",
    "    vocabulary = set()\n",
    "    X_w = dict()    \n",
    "    for document in corpus:\n",
    "        words      = set(splitter.findall(document.lower()))\n",
    "        vocabulary = vocabulary.union(words)\n",
    "        for w in words:\n",
    "            X_w[w] = X_w.get(w, 0) + 1\n",
    "    \n",
    "    return vocabulary, X_w\n",
    "\n",
    "def term_frequency(document, word_to_ind, splitter, \n",
    "                   normalize=True, word_inds=False):\n",
    "    \n",
    "    words = splitter.findall(document.lower())\n",
    "    n_features = len(word_to_ind)\n",
    "    tf = sp.sparse.lil_matrix( (1, n_features), dtype=float)\n",
    "    \n",
    "    word_indices = []\n",
    "    for w in words:\n",
    "        word_indices.append(word_to_ind[w])\n",
    "        tf[0, word_to_ind[w]] += 1\n",
    "    \n",
    "    if word_inds:\n",
    "        if normalize:\n",
    "            return tf.multiply(1/sp.sparse.linalg.norm(tf))\n",
    "        else:\n",
    "            return tf\n",
    "    else:\n",
    "        if normalize:\n",
    "            return tf.multiply(1/sp.sparse.linalg.norm(tf))\n",
    "        else:\n",
    "            return tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T18:53:31.910932Z",
     "start_time": "2021-03-21T18:53:31.694601Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T18:54:01.372259Z",
     "start_time": "2021-03-21T18:53:32.825877Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.2 s, sys: 1.14 s, total: 28.3 s\n",
      "Wall time: 28.5 s\n"
     ]
    }
   ],
   "source": [
    "splitter = re.compile('(?u)\\\\b\\\\w\\\\w+\\\\b')\n",
    "%time vocabulary, X_w = build_vocabulary(newsgroups_train.data, splitter)\n",
    "\n",
    "word_to_ind = {v:i for i,v in enumerate(vocabulary)}\n",
    "ind_to_word = {v:k for k,v in word_to_ind.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T18:54:47.008945Z",
     "start_time": "2021-03-21T18:54:47.005078Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.42 ms, sys: 292 µs, total: 1.71 ms\n",
      "Wall time: 1.46 ms\n"
     ]
    }
   ],
   "source": [
    "%time tf = term_frequency(newsgroups_train.data[0],\\\n",
    "                          word_to_ind, splitter, word_inds=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify that the term frequency is OK, compare with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T19:01:00.871380Z",
     "start_time": "2021-03-21T19:01:00.846050Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     0,      1,      2, ..., 130104, 130105, 130106])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(list(tfidf_sk.vocabulary_.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T18:54:50.555835Z",
     "start_time": "2021-03-21T18:54:48.523214Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.98 s, sys: 25.7 ms, total: 2.01 s\n",
      "Wall time: 2.01 s\n"
     ]
    }
   ],
   "source": [
    "tfidf_sk = sklearn.feature_extraction.text.TfidfVectorizer(use_idf=False,\n",
    "                                                           smooth_idf=False, \n",
    "                                                           sublinear_tf=False)\n",
    "\n",
    "%time tfidf_sk.fit(newsgroups_train.data)\n",
    "\n",
    "inverse_vocabulary_ = {v: k for k, v in tfidf_sk.vocabulary_.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T18:54:51.564124Z",
     "start_time": "2021-03-21T18:54:51.561205Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 366 µs, sys: 17 µs, total: 383 µs\n",
      "Wall time: 384 µs\n"
     ]
    }
   ],
   "source": [
    "%time x_sk = tfidf_sk.transform([newsgroups_train.data[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T18:54:52.184909Z",
     "start_time": "2021-03-21T18:54:52.180383Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isclose(tf.sum(), x_sk.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T18:54:53.095047Z",
     "start_time": "2021-03-21T18:54:53.091188Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_x_own = [ind_to_word[k] for k in tf.nonzero()[1]]\n",
    "words_x_sk = [inverse_vocabulary_[k] for k in x_sk.nonzero()[1]]\n",
    "set(words_x_own) == set(words_x_sk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Generate tfidf and compare with sklearn \n",
    "\n",
    "Finish the `compute_idf` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T18:54:55.996351Z",
     "start_time": "2021-03-21T18:54:55.993811Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_idf(X_w, word_to_ind, n_documents):\n",
    "\n",
    "    n_features = len(word_to_ind)\n",
    "    #idf = sp.sparse.csr_matrix( (1, n_features), dtype=float)\n",
    "    idf = np.zeros([1, n_features])\n",
    "    \n",
    "    for w in X_w:\n",
    "        idf[0, word_to_ind[w]] = np.log((1+n_documents)/(1 + X_w[w]))+1 \n",
    "        \n",
    "    #idf = idf + 1    \n",
    "    return sp.sparse.csr_matrix(idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T18:54:57.233041Z",
     "start_time": "2021-03-21T18:54:57.040213Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 187 ms, sys: 3.42 ms, total: 190 ms\n",
      "Wall time: 190 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# lil_matrix is more efficient.\n",
    "tf = term_frequency(newsgroups_train.data[0], word_to_ind,\\\n",
    "                    splitter, normalize=False,word_inds=False)\n",
    "\n",
    "idf = compute_idf(X_w,word_to_ind, len(newsgroups_train.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T18:54:58.123161Z",
     "start_time": "2021-03-21T18:54:58.120099Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9.640737377507692, 1.0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf.max(), idf.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T18:54:58.743893Z",
     "start_time": "2021-03-21T18:54:58.741963Z"
    }
   },
   "outputs": [],
   "source": [
    "n_documents = len(X_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T18:54:59.263559Z",
     "start_time": "2021-03-21T18:54:59.259534Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = tf.multiply(idf)\n",
    "tfidf = tfidf/sp.sparse.linalg.norm(tfidf)\n",
    "sp.sparse.linalg.norm(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T18:55:02.180536Z",
     "start_time": "2021-03-21T18:55:00.189469Z"
    }
   },
   "outputs": [],
   "source": [
    "tfidf_vectorizer = sklearn.feature_extraction.text.TfidfVectorizer()\n",
    "tfidf_vectorizer.fit(newsgroups_train.data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T18:55:02.703879Z",
     "start_time": "2021-03-21T18:55:02.700450Z"
    }
   },
   "outputs": [],
   "source": [
    "tfidf_sklearn = tfidf_vectorizer.transform(newsgroups_train.data[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T18:55:03.226606Z",
     "start_time": "2021-03-21T18:55:03.223012Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('float64'), dtype('float64'))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.data.dtype, tfidf_sklearn.data.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T18:55:03.764037Z",
     "start_time": "2021-03-21T18:55:03.760407Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.697815233022509 7.697815233022508\n",
      "\n",
      "sklearn tfidf and our tfidf are the same: True\n"
     ]
    }
   ],
   "source": [
    "print(tfidf.sum(), tfidf_sklearn.sum())\n",
    "print(\"\\nsklearn tfidf and our tfidf are the same:\",\n",
    "      np.isclose(tfidf_sklearn.sum(),tfidf.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tfidf in data \n",
    "\n",
    "\n",
    "Now we will use a dataframe containing text and use the tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T18:55:08.916765Z",
     "start_time": "2021-03-21T18:55:08.392356Z"
    }
   },
   "outputs": [],
   "source": [
    "people = pd.read_csv('../data/people_wiki_small.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T18:55:09.462929Z",
     "start_time": "2021-03-21T18:55:09.450782Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>URI</th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;http://dbpedia.org/resource/Digby_Morrell&gt;</td>\n",
       "      <td>Digby Morrell</td>\n",
       "      <td>digby morrell born 10 october 1979 is a former...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>&lt;http://dbpedia.org/resource/Alfred_J._Lewy&gt;</td>\n",
       "      <td>Alfred J. Lewy</td>\n",
       "      <td>alfred j lewy aka sandy lewy graduated from un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>&lt;http://dbpedia.org/resource/Harpdog_Brown&gt;</td>\n",
       "      <td>Harpdog Brown</td>\n",
       "      <td>harpdog brown is a singer and harmonica player...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>&lt;http://dbpedia.org/resource/Franz_Rottensteiner&gt;</td>\n",
       "      <td>Franz Rottensteiner</td>\n",
       "      <td>franz rottensteiner born in waidmannsfeld lowe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>&lt;http://dbpedia.org/resource/G-Enka&gt;</td>\n",
       "      <td>G-Enka</td>\n",
       "      <td>henry krvits born 30 december 1974 in tallinn ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                                URI  \\\n",
       "0           0        <http://dbpedia.org/resource/Digby_Morrell>   \n",
       "1           1       <http://dbpedia.org/resource/Alfred_J._Lewy>   \n",
       "2           2        <http://dbpedia.org/resource/Harpdog_Brown>   \n",
       "3           3  <http://dbpedia.org/resource/Franz_Rottensteiner>   \n",
       "4           4               <http://dbpedia.org/resource/G-Enka>   \n",
       "\n",
       "                  name                                               text  \n",
       "0        Digby Morrell  digby morrell born 10 october 1979 is a former...  \n",
       "1       Alfred J. Lewy  alfred j lewy aka sandy lewy graduated from un...  \n",
       "2        Harpdog Brown  harpdog brown is a singer and harmonica player...  \n",
       "3  Franz Rottensteiner  franz rottensteiner born in waidmannsfeld lowe...  \n",
       "4               G-Enka  henry krvits born 30 december 1974 in tallinn ...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T18:55:10.982856Z",
     "start_time": "2021-03-21T18:55:10.979518Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0     int64\n",
       "URI           object\n",
       "name          object\n",
       "text          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T18:55:11.630660Z",
     "start_time": "2021-03-21T18:55:11.627944Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'franz rottensteiner born in waidmannsfeld lower austria austria on 18 january 1942 is an austrian publisher and critic in the fields of science fiction and the fantasticrottensteiner studied journalism english and history at the university of vienna receiving his doctorate in 1969 he served about fifteen years as librarian and editor at the sterreichisches institut fr bauforschung in vienna in addition he produced a number of translations into german of leading sf authors including herbert w franke stanislaw lem philip k dick kobo abe cordwainer smith brian w aldiss and the strugatski brothersin 1973 his new york anthology view from another shore of european science fiction introduced a number of continental authors to the englishreading public some of the authors in the work are stanislaw lem josef nesvadba gerard klein and jeanpierre andrevonthe year 1975 saw the start of his series die phantastischen romane for seven years it republished works of both lesser and betterknown writers as well as new ones ending with a total of 28 volumes in the years 19791985 he brought out trnaslations of h g wellss works in an eighteen volumes seriesrottensteiner provoked some controversy with his negative assessment of american science fiction what matters is the highest achievements and there the us has yet to produce a figure comparable to hg wells olaf stapledon karel apek or stanisaw lem rottensteiner describedroger zelazny barry n malzberg and robert silverberg as producing travesties of fiction and stated asimov is a typical nonwriter and heinlein and andersonare just banal however rottensteiner praised philip k dick listing him as one of the greatest sf writers from 1980 through 1998 he was advisor for suhrkamp verlags phantastische bibliothek which brought out some three hundred books in all he has edited about fifty anthologies produced two illustrated books the science fiction book 1975 und the fantasy book 1978 as well as working on numerous reference works on science fiction his close association with and promotion of lem until 1995 was a factor in the recognition of the latter in the united statesrottensteiner has been the editor of quarber merkur the leading german language critical journal of science fiction since 1963 in 2004 on the occasion of the hundredth number of this journal he was awarded a special kurdlawitzpreis'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people[\"text\"][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: get_text_given_name\n",
    "\n",
    "build a function  `get_text_given_name` that returns the text of a particular person from the data.\n",
    "\n",
    "First try to think how can you select the text for Barack Obama..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T18:55:13.256396Z",
     "start_time": "2021-03-21T18:55:13.251850Z"
    }
   },
   "outputs": [],
   "source": [
    "obama = people[people['name'] == 'Barack Obama']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T18:55:13.999670Z",
     "start_time": "2021-03-21T18:55:13.994024Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35817    barack hussein obama ii brk husen bm born augu...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people[people['name'] == 'Barack Obama'][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T18:55:15.245889Z",
     "start_time": "2021-03-21T18:55:15.243431Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_text(df, boolean_series):\n",
    "    row_df = df[boolean_series].text\n",
    "    return df.loc[row_df.index[0]].text\n",
    "\n",
    "def get_text_given_name(df, name):\n",
    "    row_df = df[df[\"name\"] == name]\n",
    "    return df.loc[row_df.index[0]].text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T18:55:15.883139Z",
     "start_time": "2021-03-21T18:55:15.877725Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'barack hussein obama ii brk husen bm born august 4 1961 is the 44th and current president of the united states and the first african american to hold the office born in honolulu hawaii obama is a graduate of columbia university and harvard law school where he served as president of the harvard law review he was a community organizer in chicago before earning his law degree he worked as a civil rights attorney and taught constitutional law at the university of chicago law school from 1992 to 2004 he served three terms representing the 13th district in the illinois senate from 1997 to 2004 running unsuccessfully for the united states house of representatives in 2000in 2004 obama received national attention during his campaign to represent illinois in the united states senate with his victory in the march democratic party primary his keynote address at the democratic national convention in july and his election to the senate in november he began his presidential campaign in 2007 and after a close primary campaign against hillary rodham clinton in 2008 he won sufficient delegates in the democratic party primaries to receive the presidential nomination he then defeated republican nominee john mccain in the general election and was inaugurated as president on january 20 2009 nine months after his election obama was named the 2009 nobel peace prize laureateduring his first two years in office obama signed into law economic stimulus legislation in response to the great recession in the form of the american recovery and reinvestment act of 2009 and the tax relief unemployment insurance reauthorization and job creation act of 2010 other major domestic initiatives in his first term included the patient protection and affordable care act often referred to as obamacare the doddfrank wall street reform and consumer protection act and the dont ask dont tell repeal act of 2010 in foreign policy obama ended us military involvement in the iraq war increased us troop levels in afghanistan signed the new start arms control treaty with russia ordered us military involvement in libya and ordered the military operation that resulted in the death of osama bin laden in january 2011 the republicans regained control of the house of representatives as the democratic party lost a total of 63 seats and after a lengthy debate over federal spending and whether or not to raise the nations debt limit obama signed the budget control act of 2011 and the american taxpayer relief act of 2012obama was reelected president in november 2012 defeating republican nominee mitt romney and was sworn in for a second term on january 20 2013 during his second term obama has promoted domestic policies related to gun control in response to the sandy hook elementary school shooting and has called for full equality for lgbt americans while his administration has filed briefs which urged the supreme court to strike down the defense of marriage act of 1996 and californias proposition 8 as unconstitutional in foreign policy obama ordered us military involvement in iraq in response to gains made by the islamic state in iraq after the 2011 withdrawal from iraq continued the process of ending us combat operations in afghanistan and has sought to normalize us relations with cuba'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_text_given_name(people, \"Barack Obama\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### End of the exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use the tfidf to get a representation of the vector containing the description of obama and Emma Watson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T18:55:17.787900Z",
     "start_time": "2021-03-21T18:55:17.786015Z"
    }
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "tfidf = sklearn.feature_extraction.text.TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T18:55:18.721448Z",
     "start_time": "2021-03-21T18:55:18.719561Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as scp\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T18:55:19.448407Z",
     "start_time": "2021-03-21T18:55:19.439669Z"
    }
   },
   "outputs": [],
   "source": [
    "obama_vec, emma_vec = tfidf.fit_transform([get_text_given_name(people, \"Barack Obama\"), \n",
    "                                           get_text_given_name(people, \"Emma Watson\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T18:55:28.928246Z",
     "start_time": "2021-03-21T18:55:21.172484Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.6 s, sys: 132 ms, total: 7.74 s\n",
      "Wall time: 7.75 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_tfidf = tfidf.fit_transform(people[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise:\n",
    "\n",
    "Build the function `get_closest_k_names(tfidf_vec, X_tfidf, k=10)` that returns the names of the people associated to the text that is closer to the query text.\n",
    "\n",
    "Try to find the closest names to:\n",
    "\n",
    "```\n",
    "\"Brad Pitt\"\n",
    "\"Angelina Jolie\"\n",
    "\"Barack Obama\"\n",
    "\"Bill Clinton\"\n",
    "\"Emma Watson\"\n",
    "```\n",
    "\n",
    "Do they make any sense? (You might want to check the wikipedia)\n",
    "\n",
    "You will need to compute the tfidf for each individual in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T18:55:31.309556Z",
     "start_time": "2021-03-21T18:55:31.274887Z"
    }
   },
   "outputs": [],
   "source": [
    "brad_pitt_tfidf = tfidf.transform([get_text_given_name(people, \"Brad Pitt\")])\n",
    "angelina_tfidf  = tfidf.transform([get_text_given_name(people, \"Angelina Jolie\")])\n",
    "obama_tfidf     = tfidf.transform([get_text_given_name(people, \"Barack Obama\")])\n",
    "bill_tfidf      = tfidf.transform([get_text_given_name(people, \"Bill Clinton\")])\n",
    "emma_tfidf      = tfidf.transform([get_text_given_name(people, \"Emma Watson\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T18:55:32.087404Z",
     "start_time": "2021-03-21T18:55:32.085241Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_closest_k_names(tfidf_vec, X_tfidf, k=10):\n",
    "    aux = np.argsort(cosine_similarity(tfidf_vec, X_tfidf))\n",
    "    return people[\"name\"][aux[0][-k-1:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T18:55:33.307596Z",
     "start_time": "2021-03-21T18:55:33.075144Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29609         Bettina Devin\n",
       "8504     Margaret C. Snyder\n",
       "3633        Priyanka Chopra\n",
       "26909      Pat Studdy-Clift\n",
       "11666            Jane Fonda\n",
       "34756          Maggie Smith\n",
       "35902     Natashia Williams\n",
       "8973           John Granger\n",
       "17821         Emma Thompson\n",
       "3115           Stuart Craig\n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_closest_k_names(emma_tfidf, X_tfidf, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T18:55:34.134087Z",
     "start_time": "2021-03-21T18:55:33.891198Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19416         Donnie Fowler\n",
       "11723           Howard Dean\n",
       "37166    Richard L. Barclay\n",
       "9517          Deval Patrick\n",
       "28453            Jill Alper\n",
       "35817          Barack Obama\n",
       "2092     Richard Blumenthal\n",
       "28447        George W. Bush\n",
       "4096       Sheffield Nelson\n",
       "25658           Dick Morris\n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_closest_k_names(bill_tfidf, X_tfidf, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T18:55:35.094001Z",
     "start_time": "2021-03-21T18:55:34.864163Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24263      Jessica Lange\n",
       "11666         Jane Fonda\n",
       "11156      Anne Hathaway\n",
       "28076          Amy Adams\n",
       "33529     Cate Blanchett\n",
       "24426          Brad Pitt\n",
       "21644       Jodie Foster\n",
       "16242       Meryl Streep\n",
       "34756       Maggie Smith\n",
       "29009    Barbara Hershey\n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_closest_k_names(angelina_tfidf, X_tfidf, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
