{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining models\n",
    "\n",
    "Pipelines are containers of steps. A step can be one of the following:\n",
    "\n",
    "- Transformer\n",
    "- Estimator\n",
    "- Pipeline\n",
    "- FeatureUnion\n",
    "\n",
    "Now we will inspect feature Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.datasets import samples_generator\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "### New ###\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "import numpy as np\n",
    "# generate some data to play with\n",
    "X, y = samples_generator.make_classification(n_samples=1000, n_informative=5, n_redundant=0, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking features from PCA and KernelPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [(\"pca\", PCA()), (\"kernel_pca\",KernelPCA())]\n",
    "feature_combiner = FeatureUnion(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 511)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_combiner.fit_transform(X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning on top of the stacked features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmpipe = Pipeline([(\"feature_combination\",feature_combiner), ('svc', clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('feature_combination', FeatureUnion(n_jobs=None,\n",
       "       transformer_list=[('pca', PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)), ('kernel_pca', KernelPCA(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto',...r', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svmpipe.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 511)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svmpipe.steps[0][1].transform(X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Combining models probabilities as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import rmtree\n",
    "from tempfile import mkdtemp\n",
    "cachedir = mkdtemp()\n",
    "rmtree(cachedir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "anova_filter = SelectKBest(f_regression, k=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice we cannot do this since classifiers don't have a transform method\n",
    "# THIS WILL PRODUCE AN ERROR\n",
    "#model_combiner = FeatureUnion([(\"logistic\", sklearn.linear_model.LogisticRegression()),\\\n",
    "#                                (\"svm\", clf)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ClassifierTransformer:  Features from  model Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection._split import check_cv\n",
    "from sklearn.base import is_classifier, clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierTransformer(sklearn.base.BaseEstimator, sklearn.base.TransformerMixin):\n",
    "    \n",
    "    def __init__(self, estimator=None, n_classes=2, cv=3):\n",
    "        self.estimator = estimator\n",
    "        self.n_classes = n_classes\n",
    "        self.cv = cv\n",
    "    \n",
    "    def _get_labels(self, y):\n",
    "        y_labels = np.zeros(len(y))\n",
    "        y_us = np.sort(np.unique(y))\n",
    "        stepsize = int(len(y_us) / self.n_classes)\n",
    "        \n",
    "        for i_class in range(self.n_classes):\n",
    "\n",
    "            if i_class + 1 == self.n_classes:\n",
    "                y_labels[y >= y_us[i_class * stepsize]] = i_class\n",
    "            else:\n",
    "                y_labels[\n",
    "                    np.logical_and(\n",
    "                        y >= y_us[i_class * stepsize],\n",
    "                        y < y_us[(i_class + 1) * stepsize]\n",
    "                    )\n",
    "                ] = i_class\n",
    "        return y_labels\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Function gets as input the targets.\n",
    "        Targets (which are expected to be real values not classes as in this example) are used\n",
    "        to build y_labels which are integers that have been assigned a particular class acording\n",
    "        to the discretization done in _get_labels.\n",
    "        \"\"\"\n",
    "        y_labels = self._get_labels(y)\n",
    "\n",
    "        cv = check_cv(self.cv, y_labels, classifier=is_classifier(self.estimator))\n",
    "        self.estimators_ = []\n",
    "        \n",
    "        for train_indices, _ in cv.split(X, y_labels):\n",
    "            self.estimators_.append(\n",
    "                clone(self.estimator).fit(X[train_indices], y_labels[train_indices])\n",
    "            )\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"\n",
    "        This function generates \n",
    "        \n",
    "        X_prob: A matrix containing n_classes columns with the proabbility of each datapoint\n",
    "                beeing of a particular class.\n",
    "                \n",
    "        X_pred: A vector containing the chosen classes (coded as integers) for each datapoint. \n",
    "        \n",
    "        \"\"\"\n",
    "        cv = check_cv(self.cv, y, classifier=is_classifier(self.estimator))\n",
    "        \n",
    "        X_prob = np.zeros((X.shape[0], self.n_classes))\n",
    "        X_pred = np.zeros(X.shape[0])\n",
    "        for estimator, (_, test) in zip(self.estimators_, cv.split(X)):\n",
    "            X_prob[test] = estimator.predict_proba(X[test])\n",
    "            X_pred[test] = estimator.predict(X[test])\n",
    "            \n",
    "        return np.hstack([X_prob, np.array([X_pred]).T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rfc():\n",
    "    return RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_features=0.5,\n",
    "        max_depth=None,\n",
    "        max_leaf_nodes=270,\n",
    "        min_impurity_decrease=0.0001,\n",
    "        random_state=123,\n",
    "        n_jobs=-1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmpipe2 = Pipeline([ \n",
    "                     ('fu', FeatureUnion([ (\"feature_combination\",feature_combiner),\n",
    "                                           (\"c1\", ClassifierTransformer(get_rfc(), n_classes=2, cv=3)),\n",
    "                                           (\"c2\", ClassifierTransformer(get_rfc(), n_classes=10, cv=3)),\n",
    "                                         ])),\n",
    "                     ('svc', clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('fu', FeatureUnion(n_jobs=None,\n",
       "       transformer_list=[('feature_combination', FeatureUnion(n_jobs=None,\n",
       "       transformer_list=[('pca', PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)), ('kernel_pca', KernelPCA(alpha...r', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False))])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svmpipe2.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 525)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svmpipe2.steps[0][1].transform(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svmpipe2.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmpipe3 = Pipeline([ \n",
    "                     ('fu', FeatureUnion([ (\"feature_combination\",feature_combiner),\n",
    "        #                                   (\"c1\", ClassifierTransformer(get_rfc(), n_classes=5, cv=3)),\n",
    "        #                                   (\"c2\", ClassifierTransformer(get_rfc(), n_classes=10, cv=3)),\n",
    "                                         ])),\n",
    "                     ('svc', clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 511)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svmpipe3.fit(X, y);\n",
    "svmpipe3.steps[0][1].transform(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The c1 and c2 stacking of features adds 14 features\n",
      "Then 14 features crom from c1__n_classes=2, c2__n_classes=10 and a constant +2 which is\n",
      "\t one column for the predicted class of c1\n",
      "\t one column for the predicted class of c2\n"
     ]
    }
   ],
   "source": [
    "print(\"The c1 and c2 stacking of features adds {} features\".format(513-499))\n",
    "print(\"Then 14 features crom from c1__n_classes=2, c2__n_classes=10 and a constant +2\\\n",
    " which is\\n\\t one column for the predicted class of c1\\n\\t one column for the predicted class of c2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with same pipeline where the SVM does not have as input the outputs of c1 and c2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('feature_combination', FeatureUnion(n_jobs=None,\n",
       "       transformer_list=[('pca', PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)), ('kernel_pca', KernelPCA(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto',...r', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False))])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svmpipe = Pipeline([(\"feature_combination\",feature_combiner), ('svc', clf)])\n",
    "svmpipe.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.842"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svmpipe.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 511)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svmpipe.steps[0][1].transform(X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting values for the different parts of a pipeline via CrossValidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_grid = {\"fu__feature_combination__pca__n_components\":[10,15,20], \n",
    "                 \"fu__feature_combination__kernel_pca__degree\":[2,3,4],\n",
    "                 \"fu__c1__n_classes\":[2,3,4,5,10],\n",
    "                 \"fu__c2__n_classes\":[2,3,4,5,10],\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_cv = GridSearchCV(svmpipe2, param_grid=pipeline_grid, n_jobs = -1, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('fu', FeatureUnion(n_jobs=None,\n",
       "       transformer_list=[('feature_combination', FeatureUnion(n_jobs=None,\n",
       "       transformer_list=[('pca', PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)), ('kernel_pca', KernelPCA(alpha...r', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'fu__feature_combination__pca__n_components': [10, 15, 20], 'fu__feature_combination__kernel_pca__degree': [2, 3, 4], 'fu__c1__n_classes': [2, 3, 4, 5, 10], 'fu__c2__n_classes': [2, 3, 4, 5, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_cv.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_cv.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_configurations = len(pipe_cv.cv_results_[\"params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are a total of 225 tested combinations of hyperparams\n"
     ]
    }
   ],
   "source": [
    "print(\"There are a total of {} tested combinations of hyperparams\".format( n_configurations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fu__c1__n_classes': 2,\n",
       " 'fu__c2__n_classes': 2,\n",
       " 'fu__feature_combination__kernel_pca__degree': 2,\n",
       " 'fu__feature_combination__pca__n_components': 10}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_cv.cv_results_[\"params\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fu__c1__n_classes': 2,\n",
       " 'fu__c2__n_classes': 2,\n",
       " 'fu__feature_combination__kernel_pca__degree': 2,\n",
       " 'fu__feature_combination__pca__n_components': 15}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_cv.cv_results_[\"params\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928,\n",
       "       0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928,\n",
       "       0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928,\n",
       "       0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928,\n",
       "       0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928,\n",
       "       0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928,\n",
       "       0.825, 0.825, 0.825, 0.825, 0.825, 0.825, 0.825, 0.825, 0.825,\n",
       "       0.825, 0.825, 0.825, 0.825, 0.825, 0.825, 0.825, 0.825, 0.825,\n",
       "       0.825, 0.825, 0.825, 0.825, 0.825, 0.825, 0.825, 0.825, 0.825,\n",
       "       0.825, 0.825, 0.825, 0.825, 0.825, 0.825, 0.825, 0.825, 0.825,\n",
       "       0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928,\n",
       "       0.825, 0.825, 0.825, 0.825, 0.825, 0.825, 0.825, 0.825, 0.825,\n",
       "       0.825, 0.825, 0.825, 0.825, 0.825, 0.825, 0.825, 0.825, 0.825,\n",
       "       0.825, 0.825, 0.825, 0.825, 0.825, 0.825, 0.825, 0.825, 0.825,\n",
       "       0.825, 0.825, 0.825, 0.825, 0.825, 0.825, 0.825, 0.825, 0.825,\n",
       "       0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928,\n",
       "       0.825, 0.825, 0.825, 0.825, 0.825, 0.825, 0.825, 0.825, 0.825,\n",
       "       0.825, 0.825, 0.825, 0.825, 0.825, 0.825, 0.825, 0.825, 0.825,\n",
       "       0.825, 0.825, 0.825, 0.825, 0.825, 0.825, 0.825, 0.825, 0.825,\n",
       "       0.825, 0.825, 0.825, 0.825, 0.825, 0.825, 0.825, 0.825, 0.825,\n",
       "       0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928, 0.928,\n",
       "       0.825, 0.825, 0.825, 0.825, 0.825, 0.825, 0.825, 0.825, 0.825,\n",
       "       0.825, 0.825, 0.825, 0.825, 0.825, 0.825, 0.825, 0.825, 0.825,\n",
       "       0.825, 0.825, 0.825, 0.825, 0.825, 0.825, 0.825, 0.825, 0.825,\n",
       "       0.825, 0.825, 0.825, 0.825, 0.825, 0.825, 0.825, 0.825, 0.825])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_cv.cv_results_['mean_test_score']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
