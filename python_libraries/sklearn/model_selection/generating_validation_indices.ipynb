{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#model-selection\" data-toc-modified-id=\"model-selection-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>model selection</a></span><ul class=\"toc-item\"><li><span><a href=\"#Finding-the-indices-for-KFold\" data-toc-modified-id=\"Finding-the-indices-for-KFold-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Finding the indices for <code>KFold</code></a></span></li></ul></li><li><span><a href=\"#Training-models-in-crosvalidation-using-GridsearchCV\" data-toc-modified-id=\"Training-models-in-crosvalidation-using-GridsearchCV-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Training models in crosvalidation using GridsearchCV</a></span><ul class=\"toc-item\"><li><span><a href=\"#Saved-metrics-in-a-GridSearchCV-object\" data-toc-modified-id=\"Saved-metrics-in-a-GridSearchCV-object-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Saved metrics in a <code>GridSearchCV</code> object</a></span><ul class=\"toc-item\"><li><span><a href=\"#Configurations-of--Hyperparameters-tested\" data-toc-modified-id=\"Configurations-of--Hyperparameters-tested-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Configurations of  Hyperparameters tested</a></span></li></ul></li></ul></li><li><span><a href=\"#Generating-all-possible-combinations-of-hyperparameters\" data-toc-modified-id=\"Generating-all-possible-combinations-of-hyperparameters-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Generating all possible combinations of hyperparameters</a></span><ul class=\"toc-item\"><li><span><a href=\"#Ranking-results-of-the-crossvalidation-process\" data-toc-modified-id=\"Ranking-results-of-the-crossvalidation-process-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Ranking results of the crossvalidation process</a></span></li><li><span><a href=\"#Creating-your-own-GridSearchCV\" data-toc-modified-id=\"Creating-your-own-GridSearchCV-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Creating your own <code>GridSearchCV</code></a></span><ul class=\"toc-item\"><li><span><a href=\"#Training-using-crosvalidation-a-given-model\" data-toc-modified-id=\"Training-using-crosvalidation-a-given-model-3.2.1\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>Training using crosvalidation a given model</a></span></li><li><span><a href=\"#TODO:-Make-a-function-that-given-cv_results_df-and-path_folder...\" data-toc-modified-id=\"TODO:-Make-a-function-that-given-cv_results_df-and-path_folder...-3.2.2\"><span class=\"toc-item-num\">3.2.2&nbsp;&nbsp;</span>TODO: Make a function that given cv_results_df and path_folder...</a></span></li></ul></li></ul></li><li><span><a href=\"#Finding-indices-with-GroupKFold\" data-toc-modified-id=\"Finding-indices-with-GroupKFold-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Finding indices with <code>GroupKFold</code></a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Finding the indices for `KFold`\n",
    "\n",
    "The class `KFold` allows us to generate the train and validation indicies for performing training and validation indicies with different parts of our data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 4)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "X = np.random.randn(100,4)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [0 1 2 3 4 5 6 7 8 9]\n",
      "1 [10 11 12 13 14 15 16 17 18 19]\n",
      "2 [20 21 22 23 24 25 26 27 28 29]\n",
      "3 [30 31 32 33 34 35 36 37 38 39]\n",
      "4 [40 41 42 43 44 45 46 47 48 49]\n",
      "5 [50 51 52 53 54 55 56 57 58 59]\n",
      "6 [60 61 62 63 64 65 66 67 68 69]\n",
      "7 [70 71 72 73 74 75 76 77 78 79]\n",
      "8 [80 81 82 83 84 85 86 87 88 89]\n",
      "9 [90 91 92 93 94 95 96 97 98 99]\n"
     ]
    }
   ],
   "source": [
    "folds = KFold(10,shuffle=False)\n",
    "splits = folds.split(X)\n",
    "for fold, (tr_ind,va_ind) in enumerate(splits):\n",
    "    print(fold, va_ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If shuffle is true then we sample all rows from our dataset randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4  9 26 33 44 70 74 82 93 98]\n",
      "[10 21 38 47 49 51 64 71 78 90]\n",
      "[12 14 18 39 53 65 79 80 83 88]\n",
      "[ 0  8 11 31 35 40 72 73 95 97]\n",
      "[20 46 48 52 59 63 68 69 85 91]\n",
      "[ 6 27 54 55 56 60 75 81 89 92]\n",
      "[17 19 24 36 42 45 50 62 84 96]\n",
      "[22 28 32 34 37 43 58 61 66 87]\n",
      "[ 2  5  7 13 15 16 25 41 57 99]\n",
      "[ 1  3 23 29 30 67 76 77 86 94]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "folds = KFold(10,shuffle=True)\n",
    "splits = folds.split(X)\n",
    "for tr_ind,va_ind in splits:\n",
    "    print(va_ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training models in crosvalidation using GridsearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import datasets\n",
    "from sklearn.datasets import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/anaconda/envs/notebook/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "dataset = sklearn.datasets.california_housing.fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20640, 8), (20640,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = dataset.data\n",
    "y = dataset.target\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15480, 8), (15480,), (5160, 8), (5160,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr, X_te, y_tr, y_te = sklearn.model_selection.train_test_split(X,y, random_state=1234)\n",
    "\n",
    "X_tr.shape, y_tr.shape, X_te.shape, y_te.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn.ensemble import *\n",
    "\n",
    "rf = sklearn.ensemble.RandomForestRegressor()\n",
    "\n",
    "param_grid = {\"max_depth\":[5,None,10], \"max_features\":[\"auto\",0.5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_grid = sklearn.model_selection.GridSearchCV(rf, \n",
    "                                               param_grid=param_grid,\n",
    "                                               cv=4,\n",
    "                                               n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/anaconda/envs/notebook/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, error_score='raise-deprecating',\n",
       "             estimator=RandomForestRegressor(bootstrap=True, criterion='mse',\n",
       "                                             max_depth=None,\n",
       "                                             max_features='auto',\n",
       "                                             max_leaf_nodes=None,\n",
       "                                             min_impurity_decrease=0.0,\n",
       "                                             min_impurity_split=None,\n",
       "                                             min_samples_leaf=1,\n",
       "                                             min_samples_split=2,\n",
       "                                             min_weight_fraction_leaf=0.0,\n",
       "                                             n_estimators='warn', n_jobs=None,\n",
       "                                             oob_score=False, random_state=None,\n",
       "                                             verbose=0, warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'max_depth': [5, None, 10],\n",
       "                         'max_features': ['auto', 0.5]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_grid.fit(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "                      max_features=0.5, max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                      n_jobs=None, oob_score=False, random_state=None,\n",
       "                      verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saved metrics in a `GridSearchCV` object\n",
    "\n",
    "After fitting a `GridsearchCV` object we can inspect the information saved during crossvalidation inside the field `.cv_results_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mean_fit_time',\n",
       " 'std_fit_time',\n",
       " 'mean_score_time',\n",
       " 'std_score_time',\n",
       " 'param_max_depth',\n",
       " 'param_max_features',\n",
       " 'params',\n",
       " 'split0_test_score',\n",
       " 'split1_test_score',\n",
       " 'split2_test_score',\n",
       " 'split3_test_score',\n",
       " 'mean_test_score',\n",
       " 'std_test_score',\n",
       " 'rank_test_score']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(rf_grid.cv_results_.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Configurations of  Hyperparameters tested\n",
    "\n",
    "All the combinations of parameters tested are kept in `'params'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'max_depth': 5, 'max_features': 'auto'},\n",
       " {'max_depth': 5, 'max_features': 0.5},\n",
       " {'max_depth': None, 'max_features': 'auto'},\n",
       " {'max_depth': None, 'max_features': 0.5},\n",
       " {'max_depth': 10, 'max_features': 'auto'},\n",
       " {'max_depth': 10, 'max_features': 0.5}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_grid.cv_results_[\"params\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The different scores for each of the CV splits are found in `splitsK_test_score`.\n",
    "\n",
    "In this case we have 4 arrays because we used `cv=4` when we instanciated `rf_grid`.\n",
    "\n",
    "```\n",
    "'split0_test_score'\n",
    "'split1_test_score'\n",
    "'split2_test_score'\n",
    "'split3_test_score'\n",
    " ```\n",
    " \n",
    " Each array contains  possition `k` the test results of the k'th combination of hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_grid.n_splits_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.676594  , 0.67458859, 0.78570293, 0.79470538, 0.77237557,\n",
       "        0.77456112]),\n",
       " array([0.64978134, 0.64974643, 0.77543228, 0.78006514, 0.75181548,\n",
       "        0.77282568]),\n",
       " array([0.6571138 , 0.65878861, 0.77061052, 0.78591699, 0.7627303 ,\n",
       "        0.76966836]),\n",
       " array([0.65224242, 0.66934132, 0.78320904, 0.78694664, 0.76129547,\n",
       "        0.7840957 ])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores = [rf_grid.cv_results_[f\"split{i}_test_score\" ] for i in range(4)]\n",
    "all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7869085345386662"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that `rf_grid.best_score_` is different than `np.max(all_scores)`.\n",
    "\n",
    "The best score is found using the mean value of the crossvalidation scores.\n",
    "\n",
    "Therefore `rf_grid.best_score_= np.max(rf_grid.cv_results_[\"mean_test_score\"])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7869085345386662, 0.7869085345386662)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(rf_grid.cv_results_[\"mean_test_score\"]), rf_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.65893289, 0.66311624, 0.77873869, 0.78690853, 0.76205421,\n",
       "       0.77528771])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_grid.cv_results_[\"mean_test_score\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we can compute `mean_test_score` simpy computing the mean\n",
    "over the different results in the different splits of the crossvalidation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.65893289, 0.66311624, 0.77873869, 0.78690853, 0.76205421,\n",
       "       0.77528771])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(all_scores).mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating all possible combinations of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': [5, None, 10], 'max_features': ['auto', 0.5]}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function product can take as input several iterators and it will generate\n",
    "all the combinations of the values in the iterators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 1), ('a', 2), ('b', 1), ('b', 2), ('c', 1), ('c', 2)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in product([\"a\",\"b\",\"c\"],[1,2])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use it to generate the combinations of different hyperparamaters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5, 'auto'), (5, 0.5), (None, 'auto'), (None, 0.5), (10, 'auto'), (10, 0.5)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in product(param_grid[\"max_depth\"], param_grid[\"max_features\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the `*` notation allows us to generate a correctly formated input for `product`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5, 'auto'), (5, 0.5), (None, 'auto'), (None, 0.5), (10, 'auto'), (10, 0.5)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combination_params_values = [x for x in product(*param_grid.values())]\n",
    "combination_params_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we can then write the name of the param for each component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 5, 'max_features': 'auto'}\n",
      "{'max_depth': 5, 'max_features': 0.5}\n",
      "{'max_depth': None, 'max_features': 'auto'}\n",
      "{'max_depth': None, 'max_features': 0.5}\n",
      "{'max_depth': 10, 'max_features': 'auto'}\n",
      "{'max_depth': 10, 'max_features': 0.5}\n"
     ]
    }
   ],
   "source": [
    "params_keys = list(param_grid.keys())\n",
    "\n",
    "for values in combination_params_values:\n",
    "    print(dict(zip(param_grid.keys(),values)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do all this in a single function that will generate the list with the combinations we want to explore given an space of hyperparameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_params(param_grid):\n",
    "    combination_params_values = [x for x in product(*param_grid.values())]\n",
    "    params = []\n",
    "    for values in combination_params_values:\n",
    "        params.append(dict(zip(param_grid.keys(),values)))\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'max_depth': 5, 'max_features': 'auto'},\n",
       " {'max_depth': 5, 'max_features': 0.5},\n",
       " {'max_depth': None, 'max_features': 'auto'},\n",
       " {'max_depth': None, 'max_features': 0.5},\n",
       " {'max_depth': 10, 'max_features': 'auto'},\n",
       " {'max_depth': 10, 'max_features': 0.5}]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_params(param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that this is the same as "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'max_depth': 5, 'max_features': 'auto'},\n",
       " {'max_depth': 5, 'max_features': 0.5},\n",
       " {'max_depth': None, 'max_features': 'auto'},\n",
       " {'max_depth': None, 'max_features': 0.5},\n",
       " {'max_depth': 10, 'max_features': 'auto'},\n",
       " {'max_depth': 10, 'max_features': 0.5}]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_grid.cv_results_[\"params\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranking results of the crossvalidation process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All combinations of hyperparameters are stored in **`.cv_results_[\"params\"]`**\n",
    "\n",
    "We can visuallize in a single dataframe the differnet pa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({\"params\": rf_grid.cv_results_[\"params\"], \n",
    "                        \"std_test_score\": rf_grid.cv_results_[\"std_test_score\"],\n",
    "                        \"mean_test_score\": rf_grid.cv_results_[\"mean_test_score\"],\n",
    "                       })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>{'max_depth': None, 'max_features': 0.5}</td>\n",
       "      <td>0.005211</td>\n",
       "      <td>0.786909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': None, 'max_features': 'auto'}</td>\n",
       "      <td>0.006031</td>\n",
       "      <td>0.778739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 10, 'max_features': 0.5}</td>\n",
       "      <td>0.005379</td>\n",
       "      <td>0.775288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>{'max_depth': 10, 'max_features': 'auto'}</td>\n",
       "      <td>0.007287</td>\n",
       "      <td>0.762054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 0.5}</td>\n",
       "      <td>0.009590</td>\n",
       "      <td>0.663116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'auto'}</td>\n",
       "      <td>0.010533</td>\n",
       "      <td>0.658933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        params  std_test_score  \\\n",
       "3     {'max_depth': None, 'max_features': 0.5}        0.005211   \n",
       "2  {'max_depth': None, 'max_features': 'auto'}        0.006031   \n",
       "5       {'max_depth': 10, 'max_features': 0.5}        0.005379   \n",
       "4    {'max_depth': 10, 'max_features': 'auto'}        0.007287   \n",
       "1        {'max_depth': 5, 'max_features': 0.5}        0.009590   \n",
       "0     {'max_depth': 5, 'max_features': 'auto'}        0.010533   \n",
       "\n",
       "   mean_test_score  \n",
       "3         0.786909  \n",
       "2         0.778739  \n",
       "5         0.775288  \n",
       "4         0.762054  \n",
       "1         0.663116  \n",
       "0         0.658933  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = results.sort_values(by=[\"mean_test_score\"], ascending=False)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also see the order (rank) of each parameter configuration in **`.cv_results_[\"rank_test_score\"]`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 5, 2, 1, 4, 3], dtype=int32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_test_score = rf_grid.cv_results_[\"rank_test_score\"]\n",
    "rank_test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that **results of the grid search are sorted by `rf_grid.cv_results_[\"rank_test_score\"]`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'max_depth': 10, 'max_features': 0.5},\n",
       " {'max_depth': 10, 'max_features': 'auto'},\n",
       " {'max_depth': 5, 'max_features': 0.5},\n",
       " {'max_depth': 5, 'max_features': 'auto'},\n",
       " {'max_depth': None, 'max_features': 0.5},\n",
       " {'max_depth': None, 'max_features': 'auto'}]"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[rf_grid.cv_results_[\"params\"][k-1] for k in rank_test_score]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ranking the results of crossvalidation: 1:best result, 2:second best result etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find in `rank_test_score` a ranking of the best (1) to the worst (6) results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 5, 2, 1, 4, 3], dtype=int32)"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_grid.cv_results_[\"rank_test_score\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can generate this vector using `scipy.stats.rankdata` in order to rank the solutions according to `mean_test_score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 5, 2, 1, 4, 3])"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy\n",
    "rank = scipy.stats.rankdata(-rf_grid.cv_results_[\"mean_test_score\"],method='ordinal')\n",
    "rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating your own `GridSearchCV` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"max_depth\":[5,None,10], \"max_features\":[\"auto\",0.5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'max_depth': 5, 'max_features': 'auto'},\n",
       " {'max_depth': 5, 'max_features': 0.5},\n",
       " {'max_depth': None, 'max_features': 'auto'},\n",
       " {'max_depth': None, 'max_features': 0.5},\n",
       " {'max_depth': 10, 'max_features': 'auto'},\n",
       " {'max_depth': 10, 'max_features': 0.5}]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_params(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = sklearn.ensemble.RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training using crosvalidation a given model\n",
    "\n",
    "We want to have code that can train for each combination in `param_grid` we would like to train `cv` models and save the scores\n",
    "of the different fitted models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': [5, None, 10], 'max_features': ['auto', 0.5]}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "                      max_features='auto', max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators='warn',\n",
       "                      n_jobs=None, oob_score=False, random_state=None,\n",
       "                      verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_str(model, cv, params_combination):\n",
    "\n",
    "    final_name = type(model).__name__ + \"__fold{:02d}\".format(cv)\n",
    "    for item in params_combination.items():\n",
    "        final_name += \"__\"\n",
    "        final_name += item[0]+\"=\" +str(item[1])\n",
    "        \n",
    "    return final_name + \".joblib\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RandomForestRegressor__fold02__max_depth=5__max_features=auto.joblib'"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_combinations = generate_params(param_grid)\n",
    "model_str(rf,2, params_combinations[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['generating_validation_indices.ipynb', '.ipynb_checkpoints']"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir(\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import joblib\n",
    "from joblib import dump, load\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import datetime\n",
    "\n",
    "\n",
    "def CVfit(X, y, model, cv, param_grid, scorer, path_folder=\"\",\n",
    "          save_models=False, save_summary=True, add_time=False, verbose=0):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    Important notes:\n",
    "    \n",
    "    - By default this method uses the model.score function to score the test results.\n",
    "    \n",
    "    - If `scorer=\"roc_auc_score\"` or `scorer=sklearn.metrics.roc_auc_score` then the method uses \n",
    "    `model.predict_proba` instead of `model.predict` when scoring the predictions.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    cv_results_params = generate_params(param_grid)\n",
    "    folds = KFold(cv,shuffle=False)\n",
    "    cv_results_ = {}\n",
    "    cv_results_[\"params\"] = cv_results_params\n",
    "    \n",
    "    if add_time:\n",
    "        now = datetime.datetime.now()\n",
    "        time_id = f\"__{now.hour}:{now.minute}:{now.second}__{now.day}-{now.month}-{now.year}\"\n",
    "        path_folder = path_folder +  time_id       \n",
    "    \n",
    "    for fold in range(cv):\n",
    "        cv_results_[f\"split{fold}_test_score\"] = np.array([])\n",
    "    \n",
    "    # Create target Directory if don't exist\n",
    "    if not os.path.exists(path_folder):\n",
    "        os.mkdir(path_folder)\n",
    "        print(\"Directory \" , path_folder ,  \" Created \")\n",
    "    else:    \n",
    "        print(\"WARNING: Directory \" , path_folder ,  \" already exists\")\n",
    "\n",
    "    \n",
    "    cvfit_log_file = open(os.path.join(path_folder, 'cvfit_log.txt'), \"w\")\n",
    "\n",
    "        \n",
    "    for param_combination in cv_results_params:\n",
    "        splits = folds.split(X)\n",
    "        model_current = model.__class__(**param_combination)\n",
    "        \n",
    "        for fold, (tr_ind, va_ind) in enumerate(splits):\n",
    "            fold_str = f\"split{fold}_test_score\"\n",
    "            name = model_str(model_current, fold, param_combination)\n",
    "                \n",
    "            model_current.fit(X[tr_ind], y[tr_ind])\n",
    "            \n",
    "            if scorer:\n",
    "                if scorer.__name__ ==  \"roc_auc_score\":\n",
    "                    test_score_fold = scorer(model_current.predict_proba(X[va_ind]), y[va_ind])\n",
    "                elif scorer == \"roc_auc_score\":\n",
    "                    test_score_fold = roc_auc_score(model_current.predict_proba(X[va_ind]), y[va_ind])\n",
    "                else:\n",
    "                    test_score_fold = scorer(model_current.predict(X[va_ind]), y[va_ind])\n",
    "            else:\n",
    "                test_score_fold       = model_current.score(X[va_ind], y[va_ind])\n",
    "            \n",
    "            cv_results_[fold_str] = np.append(cv_results_[fold_str], test_score_fold) \n",
    "            \n",
    "            line_for_log = name + f\" --> test_score={test_score_fold}\"\n",
    "            cvfit_log_file.write(line_for_log + \"\\n\")\n",
    "            \n",
    "            if save_models:\n",
    "                file_path = os.path.join(path_folder, name) \n",
    "                fileName = Path(file_path)\n",
    "            \n",
    "                if fileName.is_file():\n",
    "                    print(\"WARNING: An exact model with the same hyperparameters is trying to be saved\")\n",
    "                    print(f\"file {file_path} already exists\")\n",
    "                    return None\n",
    "                else:\n",
    "                    joblib.dump(model_current, file_path) \n",
    "            \n",
    "               \n",
    "            if verbose ==1:\n",
    "                print(name,f\" --> test_score={test_score_fold}\")\n",
    "            \n",
    "    cvfit_log_file.close()\n",
    "    test_scores = [cv_results_[f\"split{i}_test_score\"] for i in range(4)]\n",
    "    test_scores_arr = np.array(test_scores)\n",
    "    \n",
    "    #cv_results_[\"best_test_score\"] = np.max(test_scores_arr)\n",
    "    cv_results_[\"mean_test_score\"] = test_scores_arr.mean(axis=0)\n",
    "    cv_results_[\"std_test_score\"] = test_scores_arr.mean(axis=0)\n",
    "\n",
    "    rank = scipy.stats.rankdata(-cv_results_[\"mean_test_score\"], method='ordinal')\n",
    "    cv_results_[\"rank_test_score\"] = rank\n",
    "    # Save in key \"best_params\" the best combination of hyperparams found\n",
    "    # index_best  = np.argmax(rf_grid.cv_results_[\"mean_test_score\"])\n",
    "    # best_params = rf_grid.cv_results_[\"params\"][ind_best]\n",
    "    # cv_results_[\"best_params\"] = best_params\n",
    "\n",
    "    if save_summary:\n",
    "        cv_results_df = pd.DataFrame(cv_results_).sort_values([\"rank_test_score\"])\n",
    "        cv_results_df.to_csv( os.path.join(path_folder, \"cv_results_df.csv\"),index=False)\n",
    "        \n",
    "    return cv_results_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory  ./saved_models  Created \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/anaconda/envs/notebook/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor__fold00__max_depth=5__max_features=auto.joblib  --> test_score=0.5410553804345379\n",
      "RandomForestRegressor__fold01__max_depth=5__max_features=auto.joblib  --> test_score=0.6293521452137196\n",
      "RandomForestRegressor__fold02__max_depth=5__max_features=auto.joblib  --> test_score=0.5310345264500143\n",
      "RandomForestRegressor__fold03__max_depth=5__max_features=auto.joblib  --> test_score=0.4779886097279118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/anaconda/envs/notebook/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor__fold00__max_depth=5__max_features=0.5.joblib  --> test_score=0.48391586439129697\n",
      "RandomForestRegressor__fold01__max_depth=5__max_features=0.5.joblib  --> test_score=0.6053155529144562\n",
      "RandomForestRegressor__fold02__max_depth=5__max_features=0.5.joblib  --> test_score=0.5200855437708678\n",
      "RandomForestRegressor__fold03__max_depth=5__max_features=0.5.joblib  --> test_score=0.47701358070600564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/anaconda/envs/notebook/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor__fold00__max_depth=None__max_features=auto.joblib  --> test_score=0.5219805060595394\n",
      "RandomForestRegressor__fold01__max_depth=None__max_features=auto.joblib  --> test_score=0.7201074668026454\n",
      "RandomForestRegressor__fold02__max_depth=None__max_features=auto.joblib  --> test_score=0.5950860431097469\n",
      "RandomForestRegressor__fold03__max_depth=None__max_features=auto.joblib  --> test_score=0.5884795157097984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/anaconda/envs/notebook/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor__fold00__max_depth=None__max_features=0.5.joblib  --> test_score=0.5427432321265331\n",
      "RandomForestRegressor__fold01__max_depth=None__max_features=0.5.joblib  --> test_score=0.7116653483733969\n",
      "RandomForestRegressor__fold02__max_depth=None__max_features=0.5.joblib  --> test_score=0.5816723574974257\n",
      "RandomForestRegressor__fold03__max_depth=None__max_features=0.5.joblib  --> test_score=0.5650162821608253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/anaconda/envs/notebook/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor__fold00__max_depth=10__max_features=auto.joblib  --> test_score=0.5551012007678806\n",
      "RandomForestRegressor__fold01__max_depth=10__max_features=auto.joblib  --> test_score=0.7104417896554114\n",
      "RandomForestRegressor__fold02__max_depth=10__max_features=auto.joblib  --> test_score=0.5979676016606522\n",
      "RandomForestRegressor__fold03__max_depth=10__max_features=auto.joblib  --> test_score=0.5895472341329304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/anaconda/envs/notebook/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor__fold00__max_depth=10__max_features=0.5.joblib  --> test_score=0.5363102282995238\n",
      "RandomForestRegressor__fold01__max_depth=10__max_features=0.5.joblib  --> test_score=0.705049207022969\n",
      "RandomForestRegressor__fold02__max_depth=10__max_features=0.5.joblib  --> test_score=0.6008648914338821\n",
      "RandomForestRegressor__fold03__max_depth=10__max_features=0.5.joblib  --> test_score=0.5431611312564343\n"
     ]
    }
   ],
   "source": [
    "cv = 4\n",
    "rf = sklearn.ensemble.RandomForestRegressor()\n",
    "path_models = \"./saved_models\"\n",
    "cv_results_ = CVfit(X, y, rf, cv, param_grid, scorer=None, \n",
    "                    path_folder=path_models, \n",
    "                    save_models=True, add_time=False, save_summary=True, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This function returns a dict `cv_results` containing the evaluation metrics of the crossvalidation process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['params', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'split3_test_score', 'mean_test_score', 'std_test_score', 'rank_test_score'])"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results_.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_max_depth', 'param_max_features', 'params', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'split3_test_score', 'mean_test_score', 'std_test_score', 'rank_test_score'])"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_grid.cv_results_.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['saved_models', 'generating_validation_indices.ipynb', '.ipynb_checkpoints']"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we executed with `save_summary=True` we will have `cv_results_df.csv` inside the folder where the models are saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results_df = pd.read_csv( os.path.join(path_models,\"cv_results_df.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>{'max_depth': 10, 'max_features': 'auto'}</td>\n",
       "      <td>0.555101</td>\n",
       "      <td>0.710442</td>\n",
       "      <td>0.597968</td>\n",
       "      <td>0.589547</td>\n",
       "      <td>0.613264</td>\n",
       "      <td>0.613264</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': None, 'max_features': 'auto'}</td>\n",
       "      <td>0.521981</td>\n",
       "      <td>0.720107</td>\n",
       "      <td>0.595086</td>\n",
       "      <td>0.588480</td>\n",
       "      <td>0.606413</td>\n",
       "      <td>0.606413</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': None, 'max_features': 0.5}</td>\n",
       "      <td>0.542743</td>\n",
       "      <td>0.711665</td>\n",
       "      <td>0.581672</td>\n",
       "      <td>0.565016</td>\n",
       "      <td>0.600274</td>\n",
       "      <td>0.600274</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>{'max_depth': 10, 'max_features': 0.5}</td>\n",
       "      <td>0.536310</td>\n",
       "      <td>0.705049</td>\n",
       "      <td>0.600865</td>\n",
       "      <td>0.543161</td>\n",
       "      <td>0.596346</td>\n",
       "      <td>0.596346</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'auto'}</td>\n",
       "      <td>0.541055</td>\n",
       "      <td>0.629352</td>\n",
       "      <td>0.531035</td>\n",
       "      <td>0.477989</td>\n",
       "      <td>0.544858</td>\n",
       "      <td>0.544858</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 0.5}</td>\n",
       "      <td>0.483916</td>\n",
       "      <td>0.605316</td>\n",
       "      <td>0.520086</td>\n",
       "      <td>0.477014</td>\n",
       "      <td>0.521583</td>\n",
       "      <td>0.521583</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        params  split0_test_score  \\\n",
       "0    {'max_depth': 10, 'max_features': 'auto'}           0.555101   \n",
       "1  {'max_depth': None, 'max_features': 'auto'}           0.521981   \n",
       "2     {'max_depth': None, 'max_features': 0.5}           0.542743   \n",
       "3       {'max_depth': 10, 'max_features': 0.5}           0.536310   \n",
       "4     {'max_depth': 5, 'max_features': 'auto'}           0.541055   \n",
       "5        {'max_depth': 5, 'max_features': 0.5}           0.483916   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  mean_test_score  \\\n",
       "0           0.710442           0.597968           0.589547         0.613264   \n",
       "1           0.720107           0.595086           0.588480         0.606413   \n",
       "2           0.711665           0.581672           0.565016         0.600274   \n",
       "3           0.705049           0.600865           0.543161         0.596346   \n",
       "4           0.629352           0.531035           0.477989         0.544858   \n",
       "5           0.605316           0.520086           0.477014         0.521583   \n",
       "\n",
       "   std_test_score  rank_test_score  \n",
       "0        0.613264                1  \n",
       "1        0.606413                2  \n",
       "2        0.600274                3  \n",
       "3        0.596346                4  \n",
       "4        0.544858                5  \n",
       "5        0.521583                6  "
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also inspect the log of the cvfit and see the information that is printed when verbose=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor__fold00__max_depth=5__max_features=auto.joblib --> test_score=0.5410553804345379\r\n",
      "RandomForestRegressor__fold01__max_depth=5__max_features=auto.joblib --> test_score=0.6293521452137196\r\n",
      "RandomForestRegressor__fold02__max_depth=5__max_features=auto.joblib --> test_score=0.5310345264500143\r\n",
      "RandomForestRegressor__fold03__max_depth=5__max_features=auto.joblib --> test_score=0.4779886097279118\r\n",
      "RandomForestRegressor__fold00__max_depth=5__max_features=0.5.joblib --> test_score=0.48391586439129697\r\n",
      "RandomForestRegressor__fold01__max_depth=5__max_features=0.5.joblib --> test_score=0.6053155529144562\r\n",
      "RandomForestRegressor__fold02__max_depth=5__max_features=0.5.joblib --> test_score=0.5200855437708678\r\n",
      "RandomForestRegressor__fold03__max_depth=5__max_features=0.5.joblib --> test_score=0.47701358070600564\r\n",
      "RandomForestRegressor__fold00__max_depth=None__max_features=auto.joblib --> test_score=0.5219805060595394\r\n",
      "RandomForestRegressor__fold01__max_depth=None__max_features=auto.joblib --> test_score=0.7201074668026454\r\n",
      "RandomForestRegressor__fold02__max_depth=None__max_features=auto.joblib --> test_score=0.5950860431097469\r\n",
      "RandomForestRegressor__fold03__max_depth=None__max_features=auto.joblib --> test_score=0.5884795157097984\r\n",
      "RandomForestRegressor__fold00__max_depth=None__max_features=0.5.joblib --> test_score=0.5427432321265331\r\n",
      "RandomForestRegressor__fold01__max_depth=None__max_features=0.5.joblib --> test_score=0.7116653483733969\r\n",
      "RandomForestRegressor__fold02__max_depth=None__max_features=0.5.joblib --> test_score=0.5816723574974257\r\n",
      "RandomForestRegressor__fold03__max_depth=None__max_features=0.5.joblib --> test_score=0.5650162821608253\r\n",
      "RandomForestRegressor__fold00__max_depth=10__max_features=auto.joblib --> test_score=0.5551012007678806\r\n",
      "RandomForestRegressor__fold01__max_depth=10__max_features=auto.joblib --> test_score=0.7104417896554114\r\n",
      "RandomForestRegressor__fold02__max_depth=10__max_features=auto.joblib --> test_score=0.5979676016606522\r\n",
      "RandomForestRegressor__fold03__max_depth=10__max_features=auto.joblib --> test_score=0.5895472341329304\r\n",
      "RandomForestRegressor__fold00__max_depth=10__max_features=0.5.joblib --> test_score=0.5363102282995238\r\n",
      "RandomForestRegressor__fold01__max_depth=10__max_features=0.5.joblib --> test_score=0.705049207022969\r\n",
      "RandomForestRegressor__fold02__max_depth=10__max_features=0.5.joblib --> test_score=0.6008648914338821\r\n",
      "RandomForestRegressor__fold03__max_depth=10__max_features=0.5.joblib --> test_score=0.5431611312564343\r\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!cat saved_models/cvfit_log.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Make a function that given cv_results_df and path_folder...\n",
    "\n",
    "- Loads different models (topK) and creates a \"metamodel\". To do so I need to create a new MetaModel class.\n",
    "\n",
    "    - The metamodel is essentially a list of models: `[m1,m2,m3,...]`\n",
    "    \n",
    "    - The metamodel.predict(X) simply does `np.mean(m1.predict(X), m2.predict(X),....)`\n",
    "    \n",
    "    - The metamodel should have a weighted average prediction method. \n",
    "    \n",
    "          - The `mean_test_score` could be used to assign a weight into the average\n",
    "          - The `std_test_score` could be used to assign a confidence of the prediction of the metamodel\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models will be saved in `path_folder`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RandomForestRegressor__fold00__max_depth=10__max_features=auto.joblib',\n",
       " 'RandomForestRegressor__fold00__max_depth=10__max_features=0.5.joblib',\n",
       " 'RandomForestRegressor__fold03__max_depth=10__max_features=auto.joblib',\n",
       " 'RandomForestRegressor__fold02__max_depth=10__max_features=0.5.joblib',\n",
       " 'RandomForestRegressor__fold03__max_depth=5__max_features=auto.joblib',\n",
       " 'RandomForestRegressor__fold03__max_depth=5__max_features=0.5.joblib',\n",
       " 'RandomForestRegressor__fold00__max_depth=5__max_features=0.5.joblib',\n",
       " 'RandomForestRegressor__fold01__max_depth=5__max_features=auto.joblib',\n",
       " 'RandomForestRegressor__fold01__max_depth=10__max_features=0.5.joblib',\n",
       " 'RandomForestRegressor__fold03__max_depth=None__max_features=0.5.joblib',\n",
       " 'RandomForestRegressor__fold01__max_depth=10__max_features=auto.joblib',\n",
       " 'cv_results_df.csv',\n",
       " 'RandomForestRegressor__fold00__max_depth=5__max_features=auto.joblib',\n",
       " 'RandomForestRegressor__fold02__max_depth=None__max_features=auto.joblib',\n",
       " 'RandomForestRegressor__fold02__max_depth=5__max_features=0.5.joblib',\n",
       " 'RandomForestRegressor__fold01__max_depth=None__max_features=0.5.joblib',\n",
       " 'RandomForestRegressor__fold03__max_depth=None__max_features=auto.joblib',\n",
       " 'RandomForestRegressor__fold03__max_depth=10__max_features=0.5.joblib',\n",
       " 'RandomForestRegressor__fold02__max_depth=None__max_features=0.5.joblib',\n",
       " 'RandomForestRegressor__fold01__max_depth=None__max_features=auto.joblib',\n",
       " 'RandomForestRegressor__fold02__max_depth=5__max_features=auto.joblib',\n",
       " 'RandomForestRegressor__fold00__max_depth=None__max_features=auto.joblib',\n",
       " 'RandomForestRegressor__fold00__max_depth=None__max_features=0.5.joblib',\n",
       " 'RandomForestRegressor__fold01__max_depth=5__max_features=0.5.joblib',\n",
       " 'RandomForestRegressor__fold02__max_depth=10__max_features=auto.joblib']"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = os.listdir(path_models)\n",
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can load a model from disk using **`joblib.load`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=10,\n",
       "                      max_features='auto', max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                      n_jobs=None, oob_score=False, random_state=None,\n",
       "                      verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = joblib.load(os.path.join(path_models, models[0]))\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Finding indices with `GroupKFold`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "X = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])\n",
    "y = np.array([1, 2, 3, 4])\n",
    "groups = np.array([0, 0, 2, 2])\n",
    "group_kfold = GroupKFold(n_splits=2)\n",
    "group_kfold.get_n_splits(X, y, groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroupKFold(n_splits=2)\n"
     ]
    }
   ],
   "source": [
    "print(group_kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [0 1] TEST: [2 3]\n",
      "[[1 2]\n",
      " [3 4]] [[5 6]\n",
      " [7 8]] [1 2] [3 4]\n",
      "\n",
      "\n",
      "TRAIN: [2 3] TEST: [0 1]\n",
      "[[5 6]\n",
      " [7 8]] [[1 2]\n",
      " [3 4]] [3 4] [1 2]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in group_kfold.split(X, y, groups):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    print(X_train, X_test, y_train, y_test)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
