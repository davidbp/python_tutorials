{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction-to-tensorflow\" data-toc-modified-id=\"Introduction-to-tensorflow-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction to tensorflow</a></span></li><li><span><a href=\"#Implementing-a-model-with-tf.keras.models.Sequential\" data-toc-modified-id=\"Implementing-a-model-with-tf.keras.models.Sequential-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Implementing a model with <code>tf.keras.models.Sequential</code></a></span></li><li><span><a href=\"#Inspecting-intermediate-activations-of-a-particular-layer\" data-toc-modified-id=\"Inspecting-intermediate-activations-of-a-particular-layer-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Inspecting intermediate activations of a particular layer</a></span></li><li><span><a href=\"#Custom-train-loop\" data-toc-modified-id=\"Custom-train-loop-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Custom train loop</a></span></li><li><span><a href=\"#CategoricalCrossentropy()\" data-toc-modified-id=\"CategoricalCrossentropy()-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span><code>CategoricalCrossentropy()</code></a></span></li><li><span><a href=\"#SparseCategoricalCrossentropy()\" data-toc-modified-id=\"SparseCategoricalCrossentropy()-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span><code>SparseCategoricalCrossentropy()</code></a></span></li><li><span><a href=\"#Using-next-in-the-iterators\" data-toc-modified-id=\"Using-next-in-the-iterators-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Using next in the iterators</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-12T11:35:49.890103Z",
     "start_time": "2020-11-12T11:35:48.198615Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-12T11:36:03.425227Z",
     "start_time": "2020-11-12T11:36:03.422223Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.ndarray)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train),  type(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing a model with `tf.keras.models.Sequential`\n",
    "\n",
    "\n",
    "Many models can be build stacking different types of layers that are chained using the **`tf.keras.models.Sequential`** function. \n",
    "\n",
    "- **`tf.keras.models.Sequential`**\n",
    "\n",
    "    - groups a linear stack of layers into a `tf.keras.Model`.\n",
    "    \n",
    "    -  provides training and inference features on this model.\n",
    "    \n",
    "    \n",
    "Let us build a feedforward neural network with a single hidden layer of 128 units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-12T11:41:10.683066Z",
     "start_time": "2020-11-12T11:41:10.660856Z"
    }
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-12T11:41:23.387965Z",
     "start_time": "2020-11-12T11:41:23.385406Z"
    }
   },
   "source": [
    "Once the model is build it has to be compiled with an optimizer and a loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-12T17:22:57.099883Z",
     "start_time": "2020-11-12T17:22:57.090907Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-12T17:21:51.867160Z",
     "start_time": "2020-11-12T17:21:51.860429Z"
    }
   },
   "outputs": [],
   "source": [
    "?model.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-12T17:22:38.523886Z",
     "start_time": "2020-11-12T17:22:28.817738Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0467 - accuracy: 0.9847: 1s - los - ETA: 0s - loss: 0.047 - ETA: 0s - loss: 0.0467 - accuracy: 0.98\n",
      "Epoch 2/2\n",
      "3750/3750 [==============================] - 5s 1ms/step - loss: 0.0438 - accuracy: 0.9854\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08194960653781891, 0.9797000288963318]"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=2,batch_size=16)\n",
    "model.evaluate(x_test,  y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `model.predict` to generate predictions for a single example or for a batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-12T11:43:09.235147Z",
     "start_time": "2020-11-12T11:43:09.207469Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.2092703e-14, 3.8814462e-11, 6.4564543e-12, 7.1231596e-04,\n",
       "        3.8425109e-25, 9.9928766e-01, 3.3170677e-17, 1.4139238e-13,\n",
       "        3.1058227e-15, 8.6925600e-10]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_train[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-12T11:51:46.084304Z",
     "start_time": "2020-11-12T11:51:46.053222Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.2092703e-14, 3.8814462e-11, 6.4564660e-12, 7.1231532e-04,\n",
       "        3.8425109e-25, 9.9928766e-01, 3.3170677e-17, 1.4139238e-13,\n",
       "        3.1058227e-15, 8.6925600e-10],\n",
       "       [9.9999869e-01, 6.5247768e-12, 1.3151504e-06, 6.4917568e-12,\n",
       "        9.2095436e-15, 1.4805157e-10, 1.1843172e-09, 3.6655631e-10,\n",
       "        3.7651793e-10, 2.3940161e-09],\n",
       "       [1.5755981e-10, 2.2667291e-06, 9.3890430e-06, 5.4509592e-08,\n",
       "        9.9942857e-01, 1.5296407e-10, 8.9152143e-09, 5.2883424e-04,\n",
       "        9.6269346e-08, 3.0765470e-05]], dtype=float32)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = x_train[0:3] \n",
    "model.predict(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the class prediction we just need to pick the coordinates with highest score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-12T11:51:46.531636Z",
     "start_time": "2020-11-12T11:51:46.502729Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(model.predict(batch),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-12T11:51:51.681274Z",
     "start_time": "2020-11-12T11:51:51.678332Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4], dtype=uint8)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-12T11:45:07.654964Z",
     "start_time": "2020-11-12T11:45:07.652192Z"
    }
   },
   "source": [
    "## Inspecting intermediate activations of a particular layer\n",
    "\n",
    "The layers from a model created with `tf.keras.models.sequential` are stored in  `.layers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-12T11:48:45.158923Z",
     "start_time": "2020-11-12T11:48:45.156068Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Flatten at 0x1455a2d90>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1455a2490>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x142cff6d0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1455a2810>]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can retrieve the activations for all layers as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-12T11:52:05.712678Z",
     "start_time": "2020-11-12T11:52:05.708140Z"
    }
   },
   "outputs": [],
   "source": [
    "output_names = [l.name for l in model.layers]\n",
    "model.outputs = [l.ou tput for l in model.layers]\n",
    "model.build(input_shape=x_train[0:1].shape)\n",
    "batch = x_train[0:2]\n",
    "output_values = model(batch)\n",
    "#layer_name_to_output_value = dict(zip(output_names, output_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-12T11:52:11.178396Z",
     "start_time": "2020-11-12T11:52:11.175661Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 28, 28)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-12T11:50:13.531780Z",
     "start_time": "2020-11-12T11:50:13.528910Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 784])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_values[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-12T11:50:13.690297Z",
     "start_time": "2020-11-12T11:50:13.686376Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 128])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_values[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-12T11:50:13.845903Z",
     "start_time": "2020-11-12T11:50:13.843016Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 128])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_values[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-12T11:50:13.993027Z",
     "start_time": "2020-11-12T11:50:13.990198Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 10])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_values[3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-12T11:50:16.501817Z",
     "start_time": "2020-11-12T11:50:16.498539Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 10), dtype=float32, numpy=\n",
       "array([[3.2092703e-14, 3.8814462e-11, 6.4564786e-12, 7.1231596e-04,\n",
       "        3.8425109e-25, 9.9928766e-01, 3.3170677e-17, 1.4139238e-13,\n",
       "        3.1058346e-15, 8.6925600e-10],\n",
       "       [9.9999869e-01, 6.5247768e-12, 1.3151516e-06, 6.4917568e-12,\n",
       "        9.2095783e-15, 1.4805157e-10, 1.1843194e-09, 3.6655701e-10,\n",
       "        3.7651790e-10, 2.3940208e-09]], dtype=float32)>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_values[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the output values of the last layer are precisely  the predictions of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-12T14:42:44.747727Z",
     "start_time": "2020-11-12T14:42:44.719064Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.2092703e-14, 3.8814462e-11, 6.4564786e-12, 7.1231596e-04,\n",
       "        3.8425109e-25, 9.9928766e-01, 3.3170677e-17, 1.4139238e-13,\n",
       "        3.1058346e-15, 8.6925600e-10],\n",
       "       [9.9999869e-01, 6.5247768e-12, 1.3151516e-06, 6.4917568e-12,\n",
       "        9.2095783e-15, 1.4805157e-10, 1.1843194e-09, 3.6655701e-10,\n",
       "        3.7651790e-10, 2.3940208e-09]], dtype=float32)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-12T17:11:56.481309Z",
     "start_time": "2020-11-12T17:11:56.474906Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9868951"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = [[0, 1, 0], [0, 0, 1]]\n",
    "y_pred = [[0.05, 0.95, 0], [0.1, 0.8, 0.1]]\n",
    "cce = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "cce(y_true, y_pred).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-12T17:11:56.660278Z",
     "start_time": "2020-11-12T17:11:56.621934Z"
    }
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-12T17:11:56.793993Z",
     "start_time": "2020-11-12T17:11:56.789959Z"
    }
   },
   "outputs": [],
   "source": [
    "batch = x_train[0:3]\n",
    "output_batch = model(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-12T17:11:56.951053Z",
     "start_time": "2020-11-12T17:11:56.947432Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 10), dtype=float32, numpy=\n",
       "array([[0.11727271, 0.1837656 , 0.09804658, 0.06271391, 0.09450665,\n",
       "        0.16868013, 0.09000888, 0.06515361, 0.04264797, 0.07720402],\n",
       "       [0.23056899, 0.1483027 , 0.08469895, 0.05953145, 0.08288971,\n",
       "        0.1659654 , 0.0652004 , 0.03859435, 0.04766007, 0.07658791],\n",
       "       [0.11386129, 0.11304498, 0.10339391, 0.05170143, 0.10766418,\n",
       "        0.05228689, 0.10536055, 0.1355347 , 0.09026898, 0.12688312]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-12T17:28:02.556153Z",
     "start_time": "2020-11-12T17:28:02.553150Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_batch(X,Y, batch_size):\n",
    "    n_samples = X.shape[0]\n",
    "    start = 0\n",
    "    indices = np.arange(n_samples)\n",
    "    \n",
    "    for start in range(0, n_samples, batch_size):\n",
    "        end = start + batch_size\n",
    "        batch_idx = indices[start:end]\n",
    "        yield X[batch_idx], Y[batch_idx]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `CategoricalCrossentropy()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-12T17:26:27.712457Z",
     "start_time": "2020-11-12T17:26:27.668419Z"
    }
   },
   "outputs": [],
   "source": [
    "n_epochs  = 2\n",
    "n_classes = len(np.unique(y_train))\n",
    "n_batch   = 16\n",
    "n_samples = x_train.shape[0]\n",
    "n_batches_per_epoch = int(np.ceil(n_samples/n_batch))\n",
    "\n",
    "accuracy  = tf.keras.metrics.CategoricalAccuracy()\n",
    "loss_fn   = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "batch_generator = get_batch(x_train, y_train, n_batch)\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              #loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-12T17:27:22.155328Z",
     "start_time": "2020-11-12T17:26:28.201339Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Step: 0\n",
      "step: 0, accuracy so far: 0.000\n",
      "Step: 1000\n",
      "step: 1000, accuracy so far: 0.734\n",
      "Step: 2000\n",
      "step: 2000, accuracy so far: 0.772\n",
      "Step: 3000\n",
      "step: 3000, accuracy so far: 0.794\n",
      "epoch 1\n",
      "Step: 0\n",
      "step: 0, accuracy so far: 0.809\n",
      "Step: 1000\n",
      "step: 1000, accuracy so far: 0.822\n",
      "Step: 2000\n",
      "step: 2000, accuracy so far: 0.829\n",
      "Step: 3000\n",
      "step: 3000, accuracy so far: 0.839\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "for epoch in range(n_epochs):\n",
    "    print(f\"epoch {epoch}\")\n",
    "    batch_generator = get_batch(x_train, y_train, n_batch)\n",
    "    for step in range(n_batches_per_epoch):\n",
    "        x_batch, y_batch = next(batch_generator)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            out_batch = model(x_batch)\n",
    "            # we NEED to do the one hot encoding because\n",
    "            # loss_fn = CategoricalCrossentropy\n",
    "            y_batch_onehot = tf.one_hot(y_batch, n_classes)\n",
    "            loss_value     = loss_fn(y_batch_onehot, out_batch)\n",
    "        \n",
    "        # Update the state of the `accuracy` metric.\n",
    "        accuracy.update_state(y_batch, np.argmax(out_batch,1))\n",
    "        #acc = np.mean(y_batch == np.argmax(out_batch,1))  \n",
    "\n",
    "        # Get a list of gradients for each layer in the model\n",
    "        gradients = tape.gradient(loss_value, model.trainable_weights)\n",
    "\n",
    "        # Update the weights of the model to minimize the loss value.\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "        \n",
    "        # Logging the current accuracy value so far.\n",
    "        if step % 1000 == 0:\n",
    "            print('Step:', step)        \n",
    "            print(f'step: {step}, accuracy so far: %.3f' % accuracy.result())\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `SparseCategoricalCrossentropy()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs  = 2\n",
    "n_classes = len(np.unique(y_train))\n",
    "n_batch   = 16\n",
    "n_samples = x_train.shape[0]\n",
    "n_batches_per_epoch = int(np.ceil(n_samples/n_batch))\n",
    "\n",
    "accuracy  = tf.keras.metrics.CategoricalAccuracy()\n",
    "loss_fn   = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "batch_generator = get_batch(x_train, y_train, n_batch)\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              #loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "acc = 0\n",
    "for epoch in range(n_epochs):\n",
    "    print(f\"epoch {epoch}\")\n",
    "    batch_generator = get_batch(x_train, y_train, n_batch)\n",
    "    for step in range(n_batches_per_epoch):\n",
    "        x_batch, y_batch = next(batch_generator)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            out_batch = model(x_batch)\n",
    "\n",
    "            # we DO NOT HAVE to pass the one hot encoding of the classes\n",
    "            # in the batch because loss_fn = SparseCategoricalCrossentropy()\n",
    "            loss_value = loss_fn(y_batch, out_batch)\n",
    "        \n",
    "        # Update the state of the `accuracy` metric.\n",
    "        accuracy.update_state(y_batch, np.argmax(out_batch,1))\n",
    "        # acc = np.mean(y_batch == np.argmax(out_batch,1))  \n",
    "        \n",
    "        # Get a list of gradients for each layer in the model\n",
    "        gradients = tape.gradient(loss_value, model.trainable_weights)\n",
    "\n",
    "        # Update the weights of the model to minimize the loss value.\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "\n",
    "        # Logging the current accuracy value so far.\n",
    "        if step % 1000 == 0:\n",
    "            print('Step:', step)        \n",
    "            print(f'step: {step}, accuracy so far: %.3f' % accuracy.result())\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using next in the iterators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-12T17:31:12.403170Z",
     "start_time": "2020-11-12T17:31:12.340293Z"
    }
   },
   "outputs": [],
   "source": [
    "n_epochs  = 2\n",
    "n_classes = len(np.unique(y_train))\n",
    "n_batch   = 16\n",
    "n_samples = x_train.shape[0]\n",
    "n_batches_per_epoch = int(np.ceil(n_samples/n_batch))\n",
    "\n",
    "accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "batch_generator = get_batch(x_train, y_train, n_batch)\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will iterate directly form the generator, instead of using `next`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-12T17:32:06.845269Z",
     "start_time": "2020-11-12T17:31:12.664486Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "batch index: 0, accuracy so far: 0.000\n",
      "batch index: 1000, accuracy so far: 0.731\n",
      "batch index: 2000, accuracy so far: 0.772\n",
      "batch index: 3000, accuracy so far: 0.793\n",
      "epoch 1\n",
      "batch index: 0, accuracy so far: 0.809\n",
      "batch index: 1000, accuracy so far: 0.822\n",
      "batch index: 2000, accuracy so far: 0.831\n",
      "batch index: 3000, accuracy so far: 0.841\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "for epoch in range(n_epochs):\n",
    "    print(f\"epoch {epoch}\")\n",
    "    batch_generator = get_batch(x_train, y_train, n_batch)\n",
    "    for step,(x_batch, y_batch ) in enumerate(batch_generator):\n",
    "\n",
    "        #x_batch, y_batch = next(batch_generator)\n",
    "        with tf.GradientTape() as tape:\n",
    "            out_batch = model(x_batch)\n",
    "\n",
    "            # Compute the loss value for this batch.\n",
    "            y_batch_onehot = tf.one_hot(y_batch, n_classes)\n",
    "            loss_value     = loss_fn(y_batch_onehot, out_batch)\n",
    "\n",
    "        # Update the state of the `accuracy` metric.\n",
    "        accuracy.update_state(y_batch, np.argmax(out_batch,1))\n",
    "    \n",
    "        # acc = np.mean(y_batch == np.argmax(out_batch,1))  \n",
    "        # Get a list of gradients for each layer in the model\n",
    "        gradients = tape.gradient(loss_value, model.trainable_weights)\n",
    "\n",
    "        # Update the weights of the model to minimize the loss value.\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "\n",
    "        # Logging the current accuracy value so far.\n",
    "        if step % 1000 == 0:\n",
    "            print(f'batch index: {step}, accuracy so far: %.3f' % accuracy.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
