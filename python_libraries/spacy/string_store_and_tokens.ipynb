{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T07:39:24.171941Z",
     "start_time": "2022-03-06T07:39:24.167334Z"
    }
   },
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StringStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T07:50:46.726405Z",
     "start_time": "2022-03-06T07:50:46.720806Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'spacy.strings.StringStore'>\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "from spacy.strings import StringStore\n",
    "string_store = StringStore([\"apple\", \"orange\"])\n",
    "print(type(string_store))\n",
    "print(len(string_store))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T07:39:27.251442Z",
     "start_time": "2022-03-06T07:39:27.245889Z"
    }
   },
   "source": [
    "The basic methods we have available for a `StringStore` are "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T07:50:47.472509Z",
     "start_time": "2022-03-06T07:50:47.465459Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_map',\n",
       " '_reset_and_load',\n",
       " 'add',\n",
       " 'as_int',\n",
       " 'as_string',\n",
       " 'from_bytes',\n",
       " 'from_disk',\n",
       " 'to_bytes',\n",
       " 'to_disk']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in dir(StringStore) if x.startswith('__') is False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T07:39:47.861858Z",
     "start_time": "2022-03-06T07:39:47.857630Z"
    }
   },
   "source": [
    "## `.add`: add a new string \n",
    "\n",
    "\n",
    "We can add a new string to a StringStore using `.add`.\n",
    "\n",
    "When a string is added an integer value is returned, which corresponds to a hash value for the added string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T07:53:17.454349Z",
     "start_time": "2022-03-06T07:53:17.448766Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5983625672228268878\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "hash_hello = string_store.add(\"hello\")\n",
    "print(hash_hello)\n",
    "print(len(string_store))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can retrieve strings from a `StringStore` by their hash value, as if it were a dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T07:53:21.888262Z",
     "start_time": "2022-03-06T07:53:21.881563Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_store[hash_hello]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T07:53:37.220573Z",
     "start_time": "2022-03-06T07:53:37.217739Z"
    }
   },
   "source": [
    "## `in`: check if a word is in a `StringStore`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T07:53:59.474792Z",
     "start_time": "2022-03-06T07:53:59.468945Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'hello' in string_store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  `.as_int`: hash value of a string\n",
    "\n",
    "The hash value assigned to a string is provided by `.as_int` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T07:51:18.452649Z",
     "start_time": "2022-03-06T07:51:18.446589Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8566208034543834098"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_store.as_int(\"apple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T07:55:45.606228Z",
     "start_time": "2022-03-06T07:55:45.601545Z"
    }
   },
   "outputs": [],
   "source": [
    "string_store = StringStore([\"apple\", \"orange\"])\n",
    "apple_hash = string_store[\"apple\"]\n",
    "assert apple_hash == 8566208034543834098\n",
    "assert string_store[apple_hash] == \"apple\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The integer assigned to a word is internaly computed using `spacy.strings.hash_string`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T07:56:14.640414Z",
     "start_time": "2022-03-06T07:56:14.636302Z"
    }
   },
   "outputs": [],
   "source": [
    "from spacy.strings import hash_string\n",
    "assert hash_string(\"apple\") == 8566208034543834098"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `.from_bytes`/`.to_bytes`: Load/Store the data from/to bytes\n",
    "\n",
    "Allows loading/storing a `StringStore` from `bytes` data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T08:00:16.362714Z",
     "start_time": "2022-03-06T08:00:16.355798Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.strings.StringStore at 0x7faa105b7ea0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_store = StringStore([\"apple\", \"orange\"])\n",
    "bytes_string_store = string_store.to_bytes()\n",
    "string_store_recovered = StringStore()\n",
    "string_store_recovered.from_bytes(bytes_string_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T08:07:23.118402Z",
     "start_time": "2022-03-06T08:07:23.111390Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apple', 'orange']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in string_store_recovered]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `.to_disk`: save  to disk\n",
    "\n",
    "A StringStore can be saved to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T08:09:38.350430Z",
     "start_time": "2022-03-06T08:09:38.343530Z"
    }
   },
   "outputs": [],
   "source": [
    "string_store = StringStore([\"apple\", \"orange\"])\n",
    "string_store.to_disk(\"string_store.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T08:09:38.908589Z",
     "start_time": "2022-03-06T08:09:38.776681Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\r\n",
      "  \"apple\",\r\n",
      "  \"orange\"\r\n",
      "]"
     ]
    }
   ],
   "source": [
    "!cat string_store.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T08:09:40.118723Z",
     "start_time": "2022-03-06T08:09:40.108052Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.strings.StringStore at 0x7faa105b4d10>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_store_recovered = StringStore()\n",
    "string_store_recovered.from_disk('string_store.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Token`\n",
    "\n",
    "Token information\n",
    "\n",
    "- `.text`: The original word text.\n",
    "- `.lemma_`: The base form of the word.\n",
    "- `.pos_`: The simple UPOS part-of-speech tag.\n",
    "- `.tag_`: The detailed part-of-speech tag.\n",
    "- `.dep_`: Syntactic dependency, i.e. the relation between tokens.\n",
    "- `.shape_`: The word shape â€“ capitalization, punctuation, digits.\n",
    "- `.is_alpha`: Is the token an alpha character?\n",
    "- `.is_stop`: Is the token part of a stop list, i.e. the most common words of the language?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If spacy.load(\"en_core_web_sm\") does not work, execute \n",
    "#!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T18:54:58.412787Z",
     "start_time": "2022-03-06T18:54:57.991461Z"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.en import English\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Create a blank Tokenizer with just the English vocab\n",
    "tokenizer = Tokenizer(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T18:54:58.444364Z",
     "start_time": "2022-03-06T18:54:58.432847Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp('hello there, I am David')\n",
    "type(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T18:54:58.470621Z",
     "start_time": "2022-03-06T18:54:58.464321Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello hello INTJ UH intj xxxx True False\n",
      "there there ADV RB advmod xxxx True True\n",
      ", , PUNCT , punct , False False\n",
      "I I PRON PRP nsubj X True True\n",
      "am be AUX VBP ROOT xx True True\n",
      "David David PROPN NNP attr Xxxxx True False\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "            token.shape_, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T18:43:48.026188Z",
     "start_time": "2022-03-06T18:43:48.023293Z"
    }
   },
   "source": [
    "One can get the lema for each token in the doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T18:55:53.916904Z",
     "start_time": "2022-03-06T18:55:53.913473Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', 'there', ',', 'I', 'be', 'David']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[t.lemma_ for t in doc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify if a sting is a complete sentence\n",
    "\n",
    "We can use Part of speech tags to define templates of usable sub-sentences in an application\n",
    "\n",
    "https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_sentence = nlp('this is cute')\n",
    "incomplete_sentence = nlp('are high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this this PRON DT nsubj xxxx True True\n",
      "is be AUX VBZ ROOT xx True True\n",
      "cute cute ADJ JJ acomp xxxx True False\n"
     ]
    }
   ],
   "source": [
    "for token in complete_sentence:\n",
    "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "            token.shape_, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "valid_sentences = ['high quality',      # 'great game'\n",
    "                   'worked great',      # 'looks great'\n",
    "                   'are high quality',\n",
    "                   'tend to break',\n",
    "                   'it tastes good',\n",
    "                   'very durable',      # 'very cute', 'very comfortable'\n",
    "                   'breaks easily',     # 'works well', 'works perfectly'\n",
    "                   'great quality',\n",
    "                   'well made',\n",
    "                   'great puzzle',      # 'pretty cards'\n",
    "                   'very comfortable',\n",
    "                   'well written',\n",
    "                   'fun game',\n",
    "                   'great game',\n",
    "                   'great book',\n",
    "                   'looks great',      # 'works great'\n",
    "                   'love it',\n",
    "                   ]\n",
    "\n",
    "def build_POS_prototypes(list_of_valid_items):\n",
    "    valid_pos_prototypes = []\n",
    "    POS_prototype_to_examples = defaultdict(list)\n",
    "\n",
    "    for sentence in valid_sentences:\n",
    "        s = '  ' + sentence + ' -->'\n",
    "        sentence = nlp(sentence)\n",
    "        pos_prototype = []\n",
    "        for token in sentence:\n",
    "            s += ' ' + token.pos_\n",
    "            pos_prototype.append(token.pos_)\n",
    "\n",
    "        pos_prototype = tuple(pos_prototype)    \n",
    "        POS_prototype_to_examples[pos_prototype].append(str(sentence))\n",
    "\n",
    "    return POS_prototype_to_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {('ADJ', 'NOUN'): ['high quality',\n",
       "              'great quality',\n",
       "              'great puzzle',\n",
       "              'great game'],\n",
       "             ('VERB', 'ADJ'): ['worked great', 'looks great'],\n",
       "             ('AUX', 'ADJ', 'NOUN'): ['are high quality'],\n",
       "             ('VERB', 'PART', 'VERB'): ['tend to break'],\n",
       "             ('PRON', 'VERB', 'ADJ'): ['it tastes good'],\n",
       "             ('ADV', 'ADJ'): ['very durable', 'very comfortable'],\n",
       "             ('VERB', 'ADV'): ['breaks easily'],\n",
       "             ('INTJ', 'VERB'): ['well made'],\n",
       "             ('ADV', 'VERB'): ['well written'],\n",
       "             ('NOUN', 'NOUN'): ['fun game'],\n",
       "             ('PROPN', 'PROPN'): ['great book'],\n",
       "             ('VERB', 'PRON'): ['love it']})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_POS_prototypes(valid_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_minimalistic_sentences = set([('ADJ', 'NOUN'),        # high quality\n",
    "                                    ('VBZ', 'ADJ'),         # worked great\n",
    "                                    ('VERB', 'ADJ'),        # worked great\n",
    "                                    ('AUX','ADJ', 'NOUN'),  # are high quality\n",
    "                                    ('VERB','PART','VERB'), # tend to break\n",
    "                                    ('PRON','VERB', 'ADJ'), # it tastes good\n",
    "                                    ('ADV', 'ADJ'),         # very durable\n",
    "                                    ('VERB', 'ADV'),        # breaks easily\n",
    "                                    ('ADJ', 'NOUN'),        # great quality\n",
    "                                    ('INTJ', 'VERB'),       # well made\n",
    "                                    ('ADV', 'VERB'),        # well written\n",
    "                                    ('NOUN', 'NOUN'),       # fun game\n",
    "                                    ('PROPN', 'PROPN'),     # great book\n",
    "                                    ('VERB', 'PRON'),       # love it\n",
    "                                   ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might need to run the following in the terminal to load `en_core_web_lg`\n",
    "```\n",
    "python -m spacy download en_core_web_lg\n",
    "python -m spacy download en_core_web_sm\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "d1 = nlp(\"smells good\")\n",
    "d2 = nlp(\"great smell\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9211558682081242"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1.similarity(d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
