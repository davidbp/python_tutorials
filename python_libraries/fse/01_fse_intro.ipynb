{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2917cd99",
   "metadata": {},
   "source": [
    "### fse\n",
    "\n",
    "All fse models require an iterable/generator which produces a tuple. The tuple has two fields: words and index. The index is required for the multi-thread processing, as sentences might not be processed sequentially. The index dictates, which row of the corresponding sentence vector matrix the sentence belongs to.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "13478ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(threadName)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "2c924a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['Hello', 'there'], 0)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fse import SplitIndexedList\n",
    "\n",
    "sentences_a = [\"Hello there\", \"how are you?\"]\n",
    "sentences_b = [\"today is a good day\", \"Lorem ipsum\"]\n",
    "\n",
    "s = SplitIndexedList(sentences_a, sentences_b)\n",
    "print(len(s))\n",
    "s[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "53ddb021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello there', 'how are you?', 'today is a good day', 'Lorem ipsum']"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441e57be",
   "metadata": {},
   "source": [
    "## Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "279db825",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "120f5e32d83f491c9f5a8400161228e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-13 11:28:18,819 : MainThread : INFO : loading Vectors object from /Users/dbuchaca/.cache/huggingface/hub/models--fse--glove-wiki-gigaword-100/snapshots/3282d5e7c5e979c2411ba9703d63a46243a2047e/glove-wiki-gigaword-100.model\n",
      "2023-04-13 11:28:19,435 : MainThread : INFO : loading vectors from /Users/dbuchaca/.cache/huggingface/hub/models--fse--glove-wiki-gigaword-100/snapshots/3282d5e7c5e979c2411ba9703d63a46243a2047e/glove-wiki-gigaword-100.model.vectors.npy with mmap=None\n",
      "2023-04-13 11:28:19,476 : MainThread : INFO : setting ignored attribute vectors_norm to None\n",
      "2023-04-13 11:28:21,247 : MainThread : INFO : KeyedVectors lifecycle event {'fname': '/Users/dbuchaca/.cache/huggingface/hub/models--fse--glove-wiki-gigaword-100/snapshots/3282d5e7c5e979c2411ba9703d63a46243a2047e/glove-wiki-gigaword-100.model', 'datetime': '2023-04-13T11:28:21.247560', 'gensim': '4.1.2', 'python': '3.9.12 (main, Apr  5 2022, 01:53:17) \\n[Clang 12.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'loaded'}\n"
     ]
    }
   ],
   "source": [
    "from fse import Vectors\n",
    "import gensim.downloader as api\n",
    "data = api.load(\"quora-duplicate-questions\")\n",
    "glove = Vectors.from_pretrained(\"glove-wiki-gigaword-100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "307a1faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6468640\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "for d in data:\n",
    "    # Let's blow up the data a bit by replicating each sentence.\n",
    "    for i in range(8):\n",
    "        sentences.append(d[\"question1\"].split())\n",
    "        sentences.append(d[\"question2\"].split())\n",
    "\n",
    "    s = IndexedList(sentences)\n",
    "print(len(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ad62ef7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What',\n",
       " 'is',\n",
       " 'the',\n",
       " 'step',\n",
       " 'by',\n",
       " 'step',\n",
       " 'guide',\n",
       " 'to',\n",
       " 'invest',\n",
       " 'in',\n",
       " 'share',\n",
       " 'market?']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ce9842",
   "metadata": {},
   "source": [
    "## Training Fse\n",
    "\n",
    "To train an fse model you need pretrained word embeddings. Let us use ones form glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7c113fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-13 11:32:31,863 : MainThread : INFO : no frequency mode: using wordfreq for estimation of frequency for language: en\n"
     ]
    }
   ],
   "source": [
    "from fse.models import uSIF\n",
    "model = uSIF(glove, workers=1, lang_freq=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ca70ab65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-13 11:32:36,376 : MainThread : INFO : scanning all indexed sentences and their word counts\n",
      "2023-04-13 11:32:41,378 : MainThread : INFO : SCANNING : finished 5553011 sentences with 61384762 words\n",
      "2023-04-13 11:32:42,478 : MainThread : WARNING : found 16 empty sentences\n",
      "2023-04-13 11:32:42,479 : MainThread : INFO : finished scanning 6468640 sentences with an average length of 11 and 71556728 total words\n",
      "2023-04-13 11:32:42,723 : MainThread : INFO : estimated memory for 6468640 sentences with 100 dimensions and 400000 vocabulary: 2621 MB (2 GB)\n",
      "2023-04-13 11:32:42,723 : MainThread : INFO : initializing sentence vectors for 6468640 sentences\n",
      "2023-04-13 11:32:58,213 : MainThread : INFO : pre-computing uSIF weights for 400000 words\n",
      "2023-04-13 11:32:59,254 : MainThread : INFO : begin training\n",
      "2023-04-13 11:33:04,261 : MainThread : INFO : PROGRESS : finished 42.55% with 2752619 sentences and 20942916 words, 550523 sentences/s\n",
      "2023-04-13 11:33:09,262 : MainThread : INFO : PROGRESS : finished 84.86% with 5489164 sentences and 41766810 words, 547309 sentences/s\n",
      "2023-04-13 11:33:11,082 : MainThread : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2023-04-13 11:33:11,083 : MainThread : INFO : sampling 2684354 vectors to compute principal components\n",
      "2023-04-13 11:33:15,145 : MainThread : INFO : computing 5 principal components took 4s\n",
      "2023-04-13 11:33:19,529 : MainThread : INFO : removing 5 principal components took 4s\n",
      "2023-04-13 11:33:19,531 : MainThread : INFO : training on 6468624 effective sentences with 49255184 effective words took 11s with 546864 sentences/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6468624, 49255184)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d087ef",
   "metadata": {},
   "source": [
    "## Inspecting learned vectors for the different sentences\n",
    "\n",
    "After learning we can inspect the vectors **`model.sv`**.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "0f2807fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are len(model.sv)=6468640 vectors\n",
      "The vector embedding size is len(model.sv[0])=100\n",
      "Note len(model.sv)=len(s)=6468640 which is different than len(glove.vectors)=400000\n"
     ]
    }
   ],
   "source": [
    "print(f'There are len(model.sv)={len(model.sv)} vectors')\n",
    "print(f'The vector embedding size is len(model.sv[0])={len(model.sv[0])}')\n",
    "print(f'Note len(model.sv)=len(s)={len(s)} which is different than len(glove.vectors)={len(glove.vectors)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c4f785c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6468640"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.sv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c2c92264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fse.models.sentencevectors.SentenceVectors at 0x7f87316f13d0>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.sv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842b602b",
   "metadata": {},
   "source": [
    "To compute the similarity or distance between two sentence from the training set you can call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ac23f135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.964\n",
      "0.036\n"
     ]
    }
   ],
   "source": [
    "print(model.sv.similarity(0,1).round(3))\n",
    "print(model.sv.distance(0,1).round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "e21c6ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.168\n"
     ]
    }
   ],
   "source": [
    "print(model.sv.similarity(1000,10).round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "9014d74c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['How',\n",
       " 'is',\n",
       " 'the',\n",
       " 'new',\n",
       " 'Harry',\n",
       " 'Potter',\n",
       " 'book',\n",
       " \"'Harry\",\n",
       " 'Potter',\n",
       " 'and',\n",
       " 'the',\n",
       " 'Cursed',\n",
       " \"Child'?\"]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9231ad55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What',\n",
       " 'is',\n",
       " 'the',\n",
       " 'step',\n",
       " 'by',\n",
       " 'step',\n",
       " 'guide',\n",
       " 'to',\n",
       " 'invest',\n",
       " 'in',\n",
       " 'share',\n",
       " 'market?']"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622fe114",
   "metadata": {},
   "source": [
    "## Inference with the model.\n",
    "\n",
    "One can generate an embedding for a sentence as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "eba1e187",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-13 11:40:14,326 : MainThread : INFO : scanning all indexed sentences and their word counts\n",
      "2023-04-13 11:40:14,328 : MainThread : INFO : finished scanning 1 sentences with an average length of 3 and 3 total words\n",
      "2023-04-13 11:40:14,333 : MainThread : INFO : removing 5 principal components took 0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 2.52873838e-01, -2.85084248e-02,  2.71090940e-02,\n",
       "        -2.78804988e-01, -7.40084723e-02,  4.57522571e-01,\n",
       "        -1.05381116e-01,  2.74592582e-02, -6.45715743e-02,\n",
       "        -3.40565652e-01, -1.88027695e-03, -7.27266222e-02,\n",
       "         1.93650678e-01,  1.54085010e-01, -1.17584080e-01,\n",
       "        -2.86389828e-01,  9.37029570e-02, -1.55728608e-01,\n",
       "        -3.68186563e-01,  3.55130613e-01, -1.01584151e-01,\n",
       "         2.67165512e-01, -3.59775722e-02, -1.73546225e-01,\n",
       "         1.11245878e-01,  9.16430578e-02, -2.18638271e-01,\n",
       "        -5.78938574e-02,  4.64368463e-01,  1.15901031e-01,\n",
       "         2.43736461e-01,  2.93561935e-01,  3.84000361e-01,\n",
       "         1.23893097e-01,  1.68842077e-03,  2.47208923e-01,\n",
       "         1.76382944e-01,  6.20462634e-02,  2.72806257e-01,\n",
       "        -1.29266381e-01, -1.28560856e-01,  1.32527083e-01,\n",
       "         2.21165240e-01, -1.13869853e-01, -1.39036745e-01,\n",
       "        -1.13875166e-01, -4.00712490e-01,  3.18430007e-01,\n",
       "         3.94267976e-01, -1.02989197e-01, -1.09559409e-01,\n",
       "        -2.17160642e-01,  8.64154026e-02,  1.37464076e-01,\n",
       "         9.07414109e-02, -4.49577093e-01,  2.00714916e-04,\n",
       "         2.43292339e-02, -9.71565247e-02,  1.87207401e-01,\n",
       "         5.69904111e-02,  6.35401309e-01,  3.57207917e-02,\n",
       "        -1.72069639e-01,  5.52874804e-02, -8.16236138e-02,\n",
       "         2.58079410e-01,  2.58299798e-01,  2.35299319e-01,\n",
       "        -1.37157589e-02, -1.79385468e-01,  1.29764229e-01,\n",
       "         4.52007651e-02, -4.98948485e-01, -2.24767193e-01,\n",
       "         4.01623100e-01,  3.15281481e-01, -2.19146669e-01,\n",
       "        -4.72863764e-02,  8.12561139e-02, -4.96036559e-02,\n",
       "         4.28628176e-01,  3.55988383e-01, -2.26066172e-01,\n",
       "        -5.20255566e-01, -1.04006968e-01, -3.50398749e-01,\n",
       "         1.44120246e-01, -2.70683408e-01, -2.69016206e-01,\n",
       "        -7.82632977e-02,  6.83554485e-02,  5.69772720e-01,\n",
       "        -2.64232010e-02, -4.07224119e-01, -1.45011738e-01,\n",
       "        -2.33761504e-01,  1.61793888e-01, -7.24395365e-02,\n",
       "         2.83627778e-01]], dtype=float32)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = (\"Hello my friends\".split(), 0)\n",
    "model.infer([tmp])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2e9374",
   "metadata": {},
   "source": [
    "The model allows you to generate a matrix embedding for a given input batch of sentences as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "21875b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-13 12:01:27,807 : MainThread : INFO : scanning all indexed sentences and their word counts\n",
      "2023-04-13 12:01:27,814 : MainThread : INFO : finished scanning 3 sentences with an average length of 4 and 14 total words\n",
      "2023-04-13 12:01:27,821 : MainThread : INFO : removing 5 principal components took 0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3, 100)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = [(\"Hello my friends\".split(), 0),\n",
    "         (\"I loved the old playstation games\".split(), 1),\n",
    "         (\"I liked oldschool nintendo videogames\".split(),2)]\n",
    "\n",
    "model.infer(batch).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877f03c3",
   "metadata": {},
   "source": [
    "## Quering the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e6e0de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb62238",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104337b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad521940",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399cd7f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c5ef04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cc4ec3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38f278a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c70bfe41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "068fb2aa87944749897d353f04d94011",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8598846"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fse\n",
    "from fse import Vectors, Average, IndexedList\n",
    "\n",
    "vecs = Vectors.from_pretrained(\"glove-wiki-gigaword-50\")\n",
    "model = Average(vecs)\n",
    "\n",
    "sentences = [[\"cat\", \"say\", \"meow\"], [\"dog\", \"say\", \"woof\"]]\n",
    "model.train(IndexedList(sentences))\n",
    "model.sv.similarity(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ac0b63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bab0cde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "?fse.SIF.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafaaad1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fe1fea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f769f718",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "sentences = [['cat', 'say', 'meow'], ['dog', 'say', 'woof']]\n",
    "model = Word2Vec(sentences, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd81b94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e460c8dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b429031",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fse import Vectors, Average, IndexedList\n",
    "vecs = Vectors.from_pretrained(\"glove-wiki-gigaword-50\")\n",
    "model = Average(vecs)\n",
    "\n",
    "sentences = [[\"cat\", \"say\", \"meow\"], [\"dog\", \"say\", \"woof\"]]\n",
    "\n",
    "model.train(IndexedList(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9496ec50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fse.models import sentencevectors\n",
    "#se = Sentence2Vec(model)\n",
    "#sentences_emb = se.train(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29d7d1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#?sentencevectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a86ecd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
