{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Download-the-data\" data-toc-modified-id=\"Download-the-data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Download the data</a></span></li><li><span><a href=\"#Train-an-embedding-method\" data-toc-modified-id=\"Train-an-embedding-method-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Train an embedding method</a></span></li><li><span><a href=\"#Create-a-custom-TFIDFTextEncoder\" data-toc-modified-id=\"Create-a-custom-TFIDFTextEncoder-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Create a custom TFIDFTextEncoder</a></span></li><li><span><a href=\"#Create-a-flow\" data-toc-modified-id=\"Create-a-flow-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Create a flow</a></span></li><li><span><a href=\"#Index-the-data\" data-toc-modified-id=\"Index-the-data-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Index the data</a></span></li><li><span><a href=\"#Inspect-the-embeddings-created-with--index_generator\" data-toc-modified-id=\"Inspect-the-embeddings-created-with--index_generator-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Inspect the embeddings created with  <code>index_generator</code></a></span></li><li><span><a href=\"#Query-a-document\" data-toc-modified-id=\"Query-a-document-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Query a document</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-12T13:08:42.120907Z",
     "start_time": "2021-02-12T13:08:41.686244Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import jina\n",
    "from jina.flow import Flow\n",
    "from jina import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-12T13:08:42.148550Z",
     "start_time": "2021-02-12T13:08:42.140165Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jina.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the data\n",
    "\n",
    "The script `01_fetch_dataset.py` will download the 20newsgroup dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-12T13:08:43.291707Z",
     "start_time": "2021-02-12T13:08:42.198121Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"01_fetch_dataset.py\", line 20, in <module>\r\n",
      "    twenty_newsgroup_to_csv()\r\n",
      "  File \"01_fetch_dataset.py\", line 7, in twenty_newsgroup_to_csv\r\n",
      "    os.mkdir(data_path)\r\n",
      "FileExistsError: [Errno 17] File exists: './dataset'\r\n"
     ]
    }
   ],
   "source": [
    "!python 01_fetch_dataset.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-12T13:08:43.426528Z",
     "start_time": "2021-02-12T13:08:43.311771Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20_newsgroup.csv\r\n"
     ]
    }
   ],
   "source": [
    "ls dataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-12T13:08:43.653916Z",
     "start_time": "2021-02-12T13:08:43.453461Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-12T13:08:43.771741Z",
     "start_time": "2021-02-12T13:08:43.671707Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./dataset/20_newsgroup.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-12T13:08:43.823658Z",
     "start_time": "2021-02-12T13:08:43.814564Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I was wondering if anyone out there could enli...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>2021-02-12 13:00:53.168143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>I recently posted an article asking what kind ...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>2021-02-12 13:00:53.168143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>\\nIt depends on your priorities.  A lot of peo...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>2021-02-12 13:00:53.168143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>an excellent automatic can be found in the sub...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>2021-02-12 13:00:53.168143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64</td>\n",
       "      <td>: Ford and his automobile.  I need information...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>2021-02-12 13:00:53.168143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  target  \\\n",
       "0           0  I was wondering if anyone out there could enli...       7   \n",
       "1          17  I recently posted an article asking what kind ...       7   \n",
       "2          29  \\nIt depends on your priorities.  A lot of peo...       7   \n",
       "3          56  an excellent automatic can be found in the sub...       7   \n",
       "4          64  : Ford and his automobile.  I need information...       7   \n",
       "\n",
       "       title                        date  \n",
       "0  rec.autos  2021-02-12 13:00:53.168143  \n",
       "1  rec.autos  2021-02-12 13:00:53.168143  \n",
       "2  rec.autos  2021-02-12 13:00:53.168143  \n",
       "3  rec.autos  2021-02-12 13:00:53.168143  \n",
       "4  rec.autos  2021-02-12 13:00:53.168143  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-12T13:20:05.377316Z",
     "start_time": "2021-02-12T13:20:05.373846Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 5)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-12T13:08:44.041426Z",
     "start_time": "2021-02-12T13:08:43.918755Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",text,target,title,date\r\n",
      "0,\"I was wondering if anyone out there could enlighten me on this car I saw\r\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\r\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\r\n",
      "the front bumper was separate from the rest of the body. This is \r\n",
      "all I know. If anyone can tellme a model name, engine specs, years\r\n",
      "of production, where this car is made, history, or whatever info you\r\n",
      "have on this funky looking car, please e-mail.\",7,rec.autos,2021-02-12 13:00:53.168143\r\n",
      "17,\"I recently posted an article asking what kind of rates single, male\r\n",
      "drivers under 25 yrs old were paying on performance cars. Here's a summary of\r\n"
     ]
    }
   ],
   "source": [
    "!head dataset/20_newsgroup.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train an embedding method\n",
    "\n",
    "Jina will help us build search programs based on embedding data into vectors.\n",
    "Therefore, before we star any project with jina we need a method to transform data into vectors.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-12T13:08:44.084307Z",
     "start_time": "2021-02-12T13:08:44.080634Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def load_data(data_path):\n",
    "    \"\"\"\n",
    "    Load the data from `data_path` and return a list of strings\n",
    "    \"\"\"\n",
    "    import csv\n",
    "    \n",
    "    with open(data_path) as f:\n",
    "        data = csv.reader(f, delimiter=',')\n",
    "        X = [x[1] for x in data][1:]\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-12T13:08:46.170438Z",
     "start_time": "2021-02-12T13:08:44.122083Z"
    }
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pickle\n",
    "\n",
    "data_path = \"./dataset/20_newsgroup.csv\"\n",
    "X = load_data(data_path)\n",
    "    \n",
    "# fit text featurizer descriptor\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_vectorizer.fit(X)\n",
    "\n",
    "# store the object to disk\n",
    "pickle.dump(tfidf_vectorizer, open(\"tfidf_vectorizer.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have an object `tfidf_vectorizer` can can convert our data to vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a custom TFIDFTextEncoder\n",
    "\n",
    "Before we create our flow, we need to define an encoder inside `./pods`.\n",
    "\n",
    "Here we define a `TFIDFTextEncoder(BaseEncoder)` that will be used for indexing the documents.\n",
    "\n",
    "```python\n",
    "class TFIDFTextEncoder(BaseEncoder):\n",
    "    def __init__(self,\n",
    "                 path_vectorizer= \"./pods/tfidf_vectorizer.pickle\",\n",
    "                 *args,\n",
    "                 **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.path_vectorizer = path_vectorizer\n",
    "\n",
    "    def post_init(self):\n",
    "        self.tfidf_vectorizer = pickle.load(open(self.path_vectorizer, \"rb\"))\n",
    "\n",
    "    @batching\n",
    "    @as_ndarray\n",
    "    def encode(self, data: np.ndarray, *args, **kwargs) -> 'np.ndarray':\n",
    "        return self.tfidf_vectorizer.transform(data).toarray()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-12T10:30:05.357195Z",
     "start_time": "2021-02-12T10:30:05.355514Z"
    }
   },
   "source": [
    "## Create a flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-12T13:08:46.544604Z",
     "start_time": "2021-02-12T13:08:46.541106Z"
    }
   },
   "outputs": [],
   "source": [
    "def config():\n",
    "    \"\"\"\n",
    "    Configure environment variables.\n",
    "    \"\"\"\n",
    "    parallel = 1 if sys.argv[1] == 'index' else 1\n",
    "    shards = 1\n",
    "    os.environ['JINA_PARALLEL'] = str(parallel)\n",
    "    os.environ['JINA_SHARDS'] = str(shards)\n",
    "    os.environ['WORKDIR'] = './workspace'\n",
    "    os.makedirs(os.environ['WORKDIR'], exist_ok=True)\n",
    "    os.environ['JINA_PORT'] = os.environ.get('JINA_PORT', str(65481))\n",
    "    os.environ['JINA_DATA_PATH'] = 'dataset/20_newsgroup.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-12T13:08:46.930685Z",
     "start_time": "2021-02-12T13:08:46.927958Z"
    }
   },
   "outputs": [],
   "source": [
    "config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-12T13:08:47.420435Z",
     "start_time": "2021-02-12T13:08:47.302521Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01_fetch_dataset.py                    \u001b[1m\u001b[34mflows\u001b[m\u001b[m/\r\n",
      "02_build_tfidf.py                      jina_search_20newsgroup_dataset.ipynb\r\n",
      "Dockerfile                             \u001b[1m\u001b[34mpods\u001b[m\u001b[m/\r\n",
      "README.md                              tfidf_vectorizer.pickle\r\n",
      "app.py                                 \u001b[1m\u001b[34mworkspace\u001b[m\u001b[m/\r\n",
      "\u001b[1m\u001b[34mdataset\u001b[m\u001b[m/\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-12T13:08:47.828535Z",
     "start_time": "2021-02-12T13:08:47.800448Z"
    }
   },
   "outputs": [],
   "source": [
    "f = Flow.load_config('flows/index.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-12T13:08:48.207259Z",
     "start_time": "2021-02-12T13:08:48.201245Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/svg/JSV7aW5pdDogeyd0aGVtZSc6ICdiYXNlJywgJ3RoZW1lVmFyaWFibGVzJzogeyAncHJpbWFyeUNvbG9yJzogJyMzMkM4Q0QnLCAnZWRnZUxhYmVsQmFja2dyb3VuZCc6JyNmZmYnLCAnY2x1c3RlckJrZyc6ICcjRkZDQzY2J319fSUlCmdyYXBoIExSCmdhdGV3YXkoZ2F0ZXdheSk6OjpHQVRFV0FZIC0tPiB8UFVTSC1QVUxMfGVuY29kZXIoZW5jb2Rlcik6OjpQT0QKZW5jb2RlcihlbmNvZGVyKTo6OlBPRCAtLT4gfFBVU0gtUFVMTHxkb2NfaW5kZXhlcihkb2NfaW5kZXhlcik6OjpQT0QKZG9jX2luZGV4ZXIoZG9jX2luZGV4ZXIpOjo6UE9EIC0tPiB8UFVTSC1QVUxMfGdhdGV3YXlfRU5EKGdhdGV3YXkpOjo6R0FURVdBWQpjbGFzc0RlZiBQT0QgZmlsbDojMzJDOENELHN0cm9rZTojMDA5OTk5CmNsYXNzRGVmIElOU1BFQ1QgZmlsbDojZmY2NjY2LGNvbG9yOiNmZmYKY2xhc3NEZWYgSk9JTl9JTlNQRUNUIGZpbGw6I2ZmNjY2Nixjb2xvcjojZmZmCmNsYXNzRGVmIEdBVEVXQVkgZmlsbDojNkU3Mjc4LGNvbG9yOiNmZmYKY2xhc3NEZWYgSU5TUEVDVF9BVVhfUEFTUyBmaWxsOiNmZmYsY29sb3I6IzAwMCxzdHJva2UtZGFzaGFycmF5OiA1IDUKY2xhc3NEZWYgcGVhIGZpbGw6IzAwOTk5OSxzdHJva2U6IzFFNkU3Mw==\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-12T13:08:48.593188Z",
     "start_time": "2021-02-12T13:08:48.588880Z"
    }
   },
   "outputs": [],
   "source": [
    "def index_generator():\n",
    "    \"\"\"\n",
    "    Define data as Document to be indexed.\n",
    "    \"\"\"\n",
    "    import csv\n",
    "    data_path = os.path.join(os.curdir, os.environ['JINA_DATA_PATH'])\n",
    "\n",
    "    # Get Document and ID\n",
    "    with open(data_path) as f:\n",
    "        reader = csv.reader(f, delimiter=',')\n",
    "        next(reader, None)  # skip the header from 20newsgroup dataset\n",
    "        for i, data in enumerate(reader):\n",
    "            d = Document()\n",
    "            # docid\n",
    "            d.tags['id'] = int(data[0])\n",
    "            # doc\n",
    "            d.text = data[1]\n",
    "            d.tags['label'] = int(data[2])\n",
    "            yield d\n",
    "\n",
    "def index():\n",
    "    \"\"\"\n",
    "    Index data using Index Flow.\n",
    "    \"\"\"\n",
    "    f = Flow.load_config('flows/index.yml')\n",
    "\n",
    "    with f:\n",
    "        f.index(input_fn=index_generator, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can index our data using **`index_generator`**.\n",
    "\n",
    "This will create a folder `workspace` that will contain the indexed documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-12T13:09:10.217764Z",
     "start_time": "2021-02-12T13:08:48.962755Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        encoder@6725[I]:starting jina.peapods.runtimes.zmq.zed.ZEDRuntime...\n",
      "        encoder@6725[I]:input \u001b[33mtcp://0.0.0.0:64474\u001b[0m (PULL_BIND) output \u001b[33mtcp://0.0.0.0:64478\u001b[0m (PUSH_CONNECT) control over \u001b[33mtcp://0.0.0.0:64473\u001b[0m (PAIR_BIND)\n",
      "    doc_indexer@6726[I]:starting jina.peapods.runtimes.zmq.zed.ZEDRuntime...\n",
      "    doc_indexer@6726[I]:input \u001b[33mtcp://0.0.0.0:64478\u001b[0m (PULL_BIND) output \u001b[33mtcp://0.0.0.0:64479\u001b[0m (PUSH_BIND) control over \u001b[33mtcp://0.0.0.0:64477\u001b[0m (PAIR_BIND)\n",
      "TFIDFTextEncoder@6725[I]:post_init may take some time...\n",
      "        gateway@6727[I]:starting jina.peapods.runtimes.asyncio.grpc.GRPCRuntime...\n",
      "        gateway@6727[I]:input \u001b[33mtcp://0.0.0.0:64479\u001b[0m (PULL_CONNECT) output \u001b[33mtcp://0.0.0.0:64474\u001b[0m (PUSH_CONNECT) control over \u001b[33mipc:///var/folders/05/h71x7gh54sx_5y43ppkq9_dw0000gq/T/tmpakvgop4i\u001b[0m (PAIR_BIND)\n",
      "        gateway@6727[S]:\u001b[32mGRPCRuntime is listening at: 0.0.0.0:64484\u001b[0m\n",
      "   NumpyIndexer@6726[I]:post_init may take some time...\n",
      "   NumpyIndexer@6726[I]:post_init may take some time takes 0 seconds (0.00s)\n",
      "   NumpyIndexer@6726[S]:\u001b[32msuccessfully built NumpyIndexer from a yaml config\u001b[0m\n",
      "TFIDFTextEncoder@6725[I]:post_init may take some time takes 0 seconds (0.05s)\n",
      "BinaryPbIndexer@6726[I]:post_init may take some time...\n",
      "BinaryPbIndexer@6726[I]:post_init may take some time takes 0 seconds (0.00s)\n",
      "BinaryPbIndexer@6726[S]:\u001b[32msuccessfully built BinaryPbIndexer from a yaml config\u001b[0m\n",
      "TFIDFTextEncoder@6725[S]:\u001b[32msuccessfully built TFIDFTextEncoder from a yaml config\u001b[0m\n",
      "CompoundIndexer@6726[I]:post_init may take some time...\n",
      "        encoder@6716[S]:\u001b[32mready and listening\u001b[0m\n",
      "CompoundIndexer@6726[I]:post_init may take some time takes 0 seconds (0.00s)\n",
      "CompoundIndexer@6726[S]:\u001b[32msuccessfully built CompoundIndexer from a yaml config\u001b[0m\n",
      "    doc_indexer@6716[S]:\u001b[32mready and listening\u001b[0m\n",
      "        gateway@6716[S]:\u001b[32mready and listening\u001b[0m\n",
      "           Flow@6716[I]:3 Pods (i.e. 3 Peas) are running in this Flow\n",
      "           Flow@6716[S]:\u001b[32m🎉 Flow is ready to use, accepting \u001b[1mgRPC request\u001b[0m\u001b[0m\n",
      "           Flow@6716[I]:\n",
      "\t🖥️ Local access:\t\u001b[4m\u001b[36mtcp://0.0.0.0:64484\u001b[0m\n",
      "\t🔒 Private network:\t\u001b[4m\u001b[36mtcp://192.168.10.100:64484\u001b[0m\n",
      "\t🌐 Public address:\t\u001b[4m\u001b[36mtcp://213.195.114.251:64484\u001b[0m\n",
      "         Client@6716[S]:\u001b[32mconnected to the gateway at 0.0.0.0:64484!\u001b[0m\n",
      "\u001b[36mindex\u001b[0m |\u001b[32m█\u001b[0m                   | 📃      0 ⏱️ 0.0s 🐎 0.0/s      0      batchindex ...\t        gateway@6727[I]:prefetching 50 requests...\n",
      "        gateway@6727[W]:\u001b[40m\u001b[33mif this takes too long, you may want to take smaller \"--prefetch\" or ask client to reduce \"--request-size\"\u001b[0m\n",
      "        encoder@6725[I]:recv IndexRequest  from gateway\u001b[32m▸\u001b[0mencoder/ZEDRuntime\u001b[32m▸\u001b[0m⚐\n",
      "        encoder@6725[I]:#sent: 0 #recv: 1 sent_size: 0 Bytes recv_size: 245.3 KB\n",
      "    doc_indexer@6726[I]:recv IndexRequest  from gateway\u001b[32m▸\u001b[0mencoder/ZEDRuntime\u001b[32m▸\u001b[0mdoc_indexer/ZEDRuntime\u001b[32m▸\u001b[0m⚐\n",
      "        encoder@6725[I]:recv IndexRequest  from gateway\u001b[32m▸\u001b[0mencoder/ZEDRuntime\u001b[32m▸\u001b[0m⚐\n",
      "        gateway@6727[I]:prefetching 50 requests takes 0 seconds (0.95s)\n",
      "        encoder@6725[I]:#sent: 1 #recv: 2 sent_size: 1.4 MB recv_size: 471.4 KB\n",
      "        encoder@6725[I]:recv IndexRequest  from gateway\u001b[32m▸\u001b[0mencoder/ZEDRuntime\u001b[32m▸\u001b[0m⚐\n",
      "        encoder@6725[I]:#sent: 2 #recv: 3 sent_size: 2.8 MB recv_size: 750.6 KB\n",
      "        encoder@6725[I]:recv IndexRequest  from gateway\u001b[32m▸\u001b[0mencoder/ZEDRuntime\u001b[32m▸\u001b[0m⚐\n",
      "    doc_indexer@6726[I]:#sent: 0 #recv: 1 sent_size: 0 Bytes recv_size: 1.4 MB\n",
      "    doc_indexer@6726[I]:recv IndexRequest  from gateway\u001b[32m▸\u001b[0mencoder/ZEDRuntime\u001b[32m▸\u001b[0mdoc_indexer/ZEDRuntime\u001b[32m▸\u001b[0m⚐\n",
      "\u001b[36mindex\u001b[0m |\u001b[32m█\u001b[0m                   | 📃    500 ⏱️ 1.9s 🐎 260.9/s      1      batch        encoder@6725[I]:#sent: 3 #recv: 4 sent_size: 4.2 MB recv_size: 1.1 MB\n",
      "        encoder@6725[I]:recv IndexRequest  from gateway\u001b[32m▸\u001b[0mencoder/ZEDRuntime\u001b[32m▸\u001b[0m⚐\n",
      "        encoder@6725[I]:#sent: 4 #recv: 5 sent_size: 5.9 MB recv_size: 1.5 MB\n",
      "        encoder@6725[I]:recv IndexRequest  from gateway\u001b[32m▸\u001b[0mencoder/ZEDRuntime\u001b[32m▸\u001b[0m⚐\n",
      "    doc_indexer@6726[I]:#sent: 1 #recv: 2 sent_size: 245.5 KB recv_size: 2.8 MB\n",
      "    doc_indexer@6726[I]:recv IndexRequest  from gateway\u001b[32m▸\u001b[0mencoder/ZEDRuntime\u001b[32m▸\u001b[0mdoc_indexer/ZEDRuntime\u001b[32m▸\u001b[0m⚐\n",
      "\u001b[36mindex\u001b[0m |\u001b[32m██\u001b[0m                  | 📃   1000 ⏱️ 2.7s 🐎 370.5/s      2      batch        encoder@6725[I]:#sent: 5 #recv: 6 sent_size: 7.5 MB recv_size: 2.0 MB\n",
      "        encoder@6725[I]:recv IndexRequest  from gateway\u001b[32m▸\u001b[0mencoder/ZEDRuntime\u001b[32m▸\u001b[0m⚐\n",
      "        encoder@6725[I]:#sent: 6 #recv: 7 sent_size: 9.3 MB recv_size: 2.4 MB\n",
      "        encoder@6725[I]:recv IndexRequest  from gateway\u001b[32m▸\u001b[0mencoder/ZEDRuntime\u001b[32m▸\u001b[0m⚐\n",
      "    doc_indexer@6726[I]:#sent: 2 #recv: 3 sent_size: 471.8 KB recv_size: 4.2 MB\n",
      "    doc_indexer@6726[I]:recv IndexRequest  from gateway\u001b[32m▸\u001b[0mencoder/ZEDRuntime\u001b[32m▸\u001b[0mdoc_indexer/ZEDRuntime\u001b[32m▸\u001b[0m⚐\n",
      "\u001b[36mindex\u001b[0m |\u001b[32m███\u001b[0m                 | 📃   1500 ⏱️ 3.7s 🐎 404.2/s      3      batch        encoder@6725[I]:#sent: 7 #recv: 8 sent_size: 11.1 MB recv_size: 2.6 MB\n",
      "        encoder@6725[I]:recv IndexRequest  from gateway\u001b[32m▸\u001b[0mencoder/ZEDRuntime\u001b[32m▸\u001b[0m⚐\n",
      "        encoder@6725[I]:#sent: 8 #recv: 9 sent_size: 12.5 MB recv_size: 3.2 MB\n",
      "    doc_indexer@6726[I]:#sent: 3 #recv: 4 sent_size: 751.1 KB recv_size: 5.9 MB\n",
      "        encoder@6725[I]:recv IndexRequest  from gateway\u001b[32m▸\u001b[0mencoder/ZEDRuntime\u001b[32m▸\u001b[0m⚐\n",
      "    doc_indexer@6726[I]:recv IndexRequest  from gateway\u001b[32m▸\u001b[0mencoder/ZEDRuntime\u001b[32m▸\u001b[0mdoc_indexer/ZEDRuntime\u001b[32m▸\u001b[0m⚐\n",
      "\u001b[36mindex\u001b[0m |\u001b[32m████\u001b[0m                | 📃   2000 ⏱️ 4.7s 🐎 429.1/s      4      batch        encoder@6725[I]:#sent: 9 #recv: 10 sent_size: 14.3 MB recv_size: 3.6 MB\n",
      "        encoder@6725[I]:recv IndexRequest  from gateway\u001b[32m▸\u001b[0mencoder/ZEDRuntime\u001b[32m▸\u001b[0m⚐\n",
      "        encoder@6725[I]:#sent: 10 #recv: 11 sent_size: 15.9 MB recv_size: 3.9 MB\n",
      "    doc_indexer@6726[I]:#sent: 4 #recv: 5 sent_size: 1.1 MB recv_size: 7.5 MB\n",
      "    doc_indexer@6726[I]:recv IndexRequest  from gateway\u001b[32m▸\u001b[0mencoder/ZEDRuntime\u001b[32m▸\u001b[0mdoc_indexer/ZEDRuntime\u001b[32m▸\u001b[0m⚐\n",
      "\u001b[36mindex\u001b[0m |\u001b[32m█████\u001b[0m               | 📃   2500 ⏱️ 5.6s 🐎 449.1/s      5      batch        encoder@6725[I]:recv IndexRequest  from gateway\u001b[32m▸\u001b[0mencoder/ZEDRuntime\u001b[32m▸\u001b[0m⚐\n",
      "        encoder@6725[I]:#sent: 11 #recv: 12 sent_size: 17.4 MB recv_size: 4.2 MB\n",
      "        encoder@6725[I]:recv IndexRequest  from gateway\u001b[32m▸\u001b[0mencoder/ZEDRuntime\u001b[32m▸\u001b[0m⚐\n",
      "        encoder@6725[I]:#sent: 12 #recv: 13 sent_size: 18.9 MB recv_size: 4.5 MB\n",
      "        encoder@6725[I]:recv IndexRequest  from gateway\u001b[32m▸\u001b[0mencoder/ZEDRuntime\u001b[32m▸\u001b[0m⚐\n",
      "    doc_indexer@6726[I]:#sent: 5 #recv: 6 sent_size: 1.5 MB recv_size: 9.3 MB\n",
      "    doc_indexer@6726[I]:recv IndexRequest  from gateway\u001b[32m▸\u001b[0mencoder/ZEDRuntime\u001b[32m▸\u001b[0mdoc_indexer/ZEDRuntime\u001b[32m▸\u001b[0m⚐\n",
      "\u001b[36mindex\u001b[0m |\u001b[32m██████\u001b[0m              | 📃   3000 ⏱️ 7.0s 🐎 426.9/s      6      batch        encoder@6725[I]:#sent: 13 #recv: 14 sent_size: 20.5 MB recv_size: 4.7 MB\n",
      "        encoder@6725[I]:recv IndexRequest  from gateway\u001b[32m▸\u001b[0mencoder/ZEDRuntime\u001b[32m▸\u001b[0m⚐\n",
      "        encoder@6725[I]:#sent: 14 #recv: 15 sent_size: 21.9 MB recv_size: 5.0 MB\n",
      "        encoder@6725[I]:recv IndexRequest  from gateway\u001b[32m▸\u001b[0mencoder/ZEDRuntime\u001b[32m▸\u001b[0m⚐\n",
      "    doc_indexer@6726[I]:#sent: 6 #recv: 7 sent_size: 2.0 MB recv_size: 11.1 MB\n",
      "    doc_indexer@6726[I]:recv IndexRequest  from gateway\u001b[32m▸\u001b[0mencoder/ZEDRuntime\u001b[32m▸\u001b[0mdoc_indexer/ZEDRuntime\u001b[32m▸\u001b[0m⚐\n",
      "\u001b[36mindex\u001b[0m |\u001b[32m███████\u001b[0m             | 📃   3500 ⏱️ 7.9s 🐎 443.4/s      7      batch        encoder@6725[I]:#sent: 15 #recv: 16 sent_size: 23.4 MB recv_size: 5.5 MB\n",
      "        encoder@6725[I]:recv IndexRequest  from gateway\u001b[32m▸\u001b[0mencoder/ZEDRuntime\u001b[32m▸\u001b[0m⚐\n",
      "    doc_indexer@6726[I]:#sent: 7 #recv: 8 sent_size: 2.4 MB recv_size: 12.5 MB\n",
      "\u001b[36mindex\u001b[0m |\u001b[32m████████\u001b[0m            | 📃   4000 ⏱️ 8.7s 🐎 459.9/s      8      batch    doc_indexer@6726[I]:recv IndexRequest  from gateway\u001b[32m▸\u001b[0mencoder/ZEDRuntime\u001b[32m▸\u001b[0mdoc_indexer/ZEDRuntime\u001b[32m▸\u001b[0m⚐\n",
      "        encoder@6725[I]:#sent: 16 #recv: 17 sent_size: 25.1 MB recv_size: 5.9 MB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        encoder@6725[I]:recv IndexRequest  from gateway\u001b[32m▸\u001b[0mencoder/ZEDRuntime\u001b[32m▸\u001b[0m⚐\n",
      "        encoder@6725[I]:#sent: 17 #recv: 18 sent_size: 26.8 MB recv_size: 6.1 MB\n",
      "        encoder@6725[I]:recv IndexRequest  from gateway\u001b[32m▸\u001b[0mencoder/ZEDRuntime\u001b[32m▸\u001b[0m⚐\n",
      "        encoder@6725[I]:#sent: 18 #recv: 19 sent_size: 28.2 MB recv_size: 6.6 MB\n",
      "    doc_indexer@6726[I]:#sent: 8 #recv: 9 sent_size: 2.6 MB recv_size: 14.3 MB\n",
      "    doc_indexer@6726[I]:recv IndexRequest  from gateway\u001b[32m▸\u001b[0mencoder/ZEDRuntime\u001b[32m▸\u001b[0mdoc_indexer/ZEDRuntime\u001b[32m▸\u001b[0m⚐\n",
      "\u001b[36mindex\u001b[0m |\u001b[32m█████████\u001b[0m           | 📃   4500 ⏱️ 9.6s 🐎 467.3/s      9      batch        encoder@6725[I]:recv IndexRequest  from gateway\u001b[32m▸\u001b[0mencoder/ZEDRuntime\u001b[32m▸\u001b[0m⚐\n",
      "        encoder@6725[I]:#sent: 19 #recv: 20 sent_size: 30.0 MB recv_size: 7.2 MB\n",
      "        encoder@6725[I]:recv IndexRequest  from gateway\u001b[32m▸\u001b[0mencoder/ZEDRuntime\u001b[32m▸\u001b[0m⚐\n",
      "    doc_indexer@6726[I]:#sent: 9 #recv: 10 sent_size: 3.2 MB recv_size: 15.9 MB\n",
      "    doc_indexer@6726[I]:recv IndexRequest  from gateway\u001b[32m▸\u001b[0mencoder/ZEDRuntime\u001b[32m▸\u001b[0mdoc_indexer/ZEDRuntime\u001b[32m▸\u001b[0m⚐\n",
      "\u001b[36mindex\u001b[0m |\u001b[32m██████████\u001b[0m          | 📃   5000 ⏱️ 10.4s 🐎 479.5/s     10      batch        encoder@6725[I]:#sent: 20 #recv: 21 sent_size: 32.1 MB recv_size: 7.7 MB\n",
      "        encoder@6725[I]:recv IndexRequest  from gateway\u001b[32m▸\u001b[0mencoder/ZEDRuntime\u001b[32m▸\u001b[0m⚐\n",
      "        encoder@6725[I]:#sent: 21 #recv: 22 sent_size: 34.0 MB recv_size: 8.3 MB\n",
      "    doc_indexer@6726[I]:#sent: 10 #recv: 11 sent_size: 3.6 MB recv_size: 17.4 MB\n",
      "    doc_indexer@6726[I]:recv IndexRequest  from gateway\u001b[32m▸\u001b[0mencoder/ZEDRuntime\u001b[32m▸\u001b[0mdoc_indexer/ZEDRuntime\u001b[32m▸\u001b[0m⚐\n",
      "\u001b[36mindex\u001b[0m |\u001b[32m███████████\u001b[0m         | 📃   5500 ⏱️ 11.3s 🐎 488.5/s     11      batch        encoder@6725[I]:recv IndexRequest  from gateway\u001b[32m▸\u001b[0mencoder/ZEDRuntime\u001b[32m▸\u001b[0m⚐\n",
      "        encoder@6725[I]:#sent: 22 #recv: 23 sent_size: 36.0 MB recv_size: 8.6 MB\n",
      "    doc_indexer@6726[I]:#sent: 11 #recv: 12 sent_size: 3.9 MB recv_size: 18.9 MB\n",
      "    doc_indexer@6726[I]:recv IndexRequest  from gateway\u001b[32m▸\u001b[0mencoder/ZEDRuntime\u001b[32m▸\u001b[0mdoc_indexer/ZEDRuntime\u001b[32m▸\u001b[0m⚐\n",
      "\u001b[36mindex\u001b[0m |\u001b[32m████████████\u001b[0m        | 📃   6000 ⏱️ 12.1s 🐎 497.0/s     12      batch    doc_indexer@6726[I]:#sent: 12 #recv: 13 sent_size: 4.2 MB recv_size: 20.5 MB\n",
      "    doc_indexer@6726[I]:recv IndexRequest  from gateway\u001b[32m▸\u001b[0mencoder/ZEDRuntime\u001b[32m▸\u001b[0mdoc_indexer/ZEDRuntime\u001b[32m▸\u001b[0m⚐\n",
      "\u001b[36mindex\u001b[0m |\u001b[32m█████████████\u001b[0m       | 📃   6500 ⏱️ 12.8s 🐎 509.4/s     13      batch    doc_indexer@6726[I]:#sent: 13 #recv: 14 sent_size: 4.5 MB recv_size: 21.9 MB\n",
      "    doc_indexer@6726[I]:recv IndexRequest  from gateway\u001b[32m▸\u001b[0mencoder/ZEDRuntime\u001b[32m▸\u001b[0mdoc_indexer/ZEDRuntime\u001b[32m▸\u001b[0m⚐\n",
      "\u001b[36mindex\u001b[0m |\u001b[32m██████████████\u001b[0m      | 📃   7000 ⏱️ 13.5s 🐎 519.6/s     14      batch    doc_indexer@6726[I]:#sent: 14 #recv: 15 sent_size: 4.7 MB recv_size: 23.4 MB\n",
      "    doc_indexer@6726[I]:recv IndexRequest  from gateway\u001b[32m▸\u001b[0mencoder/ZEDRuntime\u001b[32m▸\u001b[0mdoc_indexer/ZEDRuntime\u001b[32m▸\u001b[0m⚐\n",
      "\u001b[36mindex\u001b[0m |\u001b[32m███████████████\u001b[0m     | 📃   7500 ⏱️ 14.2s 🐎 528.2/s     15      batch    doc_indexer@6726[I]:#sent: 15 #recv: 16 sent_size: 5.1 MB recv_size: 25.1 MB\n",
      "    doc_indexer@6726[I]:recv IndexRequest  from gateway\u001b[32m▸\u001b[0mencoder/ZEDRuntime\u001b[32m▸\u001b[0mdoc_indexer/ZEDRuntime\u001b[32m▸\u001b[0m⚐\n",
      "\u001b[36mindex\u001b[0m |\u001b[32m████████████████\u001b[0m    | 📃   8000 ⏱️ 14.9s 🐎 536.6/s     16      batch    doc_indexer@6726[I]:#sent: 16 #recv: 17 sent_size: 5.5 MB recv_size: 26.8 MB\n",
      "    doc_indexer@6726[I]:recv IndexRequest  from gateway\u001b[32m▸\u001b[0mencoder/ZEDRuntime\u001b[32m▸\u001b[0mdoc_indexer/ZEDRuntime\u001b[32m▸\u001b[0m⚐\n",
      "\u001b[36mindex\u001b[0m |\u001b[32m█████████████████\u001b[0m   | 📃   8500 ⏱️ 15.7s 🐎 542.9/s     17      batch    doc_indexer@6726[I]:#sent: 17 #recv: 18 sent_size: 5.9 MB recv_size: 28.2 MB\n",
      "\u001b[36mindex\u001b[0m |\u001b[32m██████████████████\u001b[0m  | 📃   9000 ⏱️ 16.3s 🐎 551.3/s     18      batch    doc_indexer@6726[I]:recv IndexRequest  from gateway\u001b[32m▸\u001b[0mencoder/ZEDRuntime\u001b[32m▸\u001b[0mdoc_indexer/ZEDRuntime\u001b[32m▸\u001b[0m⚐\n",
      "    doc_indexer@6726[I]:#sent: 18 #recv: 19 sent_size: 6.1 MB recv_size: 30.0 MB\n",
      "    doc_indexer@6726[I]:recv IndexRequest  from gateway\u001b[32m▸\u001b[0mencoder/ZEDRuntime\u001b[32m▸\u001b[0mdoc_indexer/ZEDRuntime\u001b[32m▸\u001b[0m⚐\n",
      "\u001b[36mindex\u001b[0m |\u001b[32m███████████████████\u001b[0m | 📃   9500 ⏱️ 17.0s 🐎 558.5/s     19      batch    doc_indexer@6726[I]:#sent: 19 #recv: 20 sent_size: 6.6 MB recv_size: 32.1 MB\n",
      "    doc_indexer@6726[I]:recv IndexRequest  from gateway\u001b[32m▸\u001b[0mencoder/ZEDRuntime\u001b[32m▸\u001b[0mdoc_indexer/ZEDRuntime\u001b[32m▸\u001b[0m⚐\n",
      "\u001b[36mindex\u001b[0m |\u001b[32m████████████████████\u001b[0m| 📃  10000 ⏱️ 17.7s 🐎 565.2/s     20      batch\n",
      "    doc_indexer@6726[I]:#sent: 20 #recv: 21 sent_size: 7.2 MB recv_size: 34.0 MB\n",
      "    doc_indexer@6726[I]:recv IndexRequest  from gateway\u001b[32m▸\u001b[0mencoder/ZEDRuntime\u001b[32m▸\u001b[0mdoc_indexer/ZEDRuntime\u001b[32m▸\u001b[0m⚐\n",
      "\u001b[36mindex\u001b[0m |\u001b[32m█\u001b[0m                   | 📃  10500 ⏱️ 18.4s 🐎 572.0/s     21      batch    doc_indexer@6726[I]:#sent: 21 #recv: 22 sent_size: 7.7 MB recv_size: 36.0 MB\n",
      "    doc_indexer@6726[I]:recv IndexRequest  from gateway\u001b[32m▸\u001b[0mencoder/ZEDRuntime\u001b[32m▸\u001b[0mdoc_indexer/ZEDRuntime\u001b[32m▸\u001b[0m⚐\n",
      "\u001b[36mindex\u001b[0m |\u001b[32m██\u001b[0m                  | 📃  11000 ⏱️ 19.0s 🐎 578.2/s     22      batch    doc_indexer@6726[I]:#sent: 22 #recv: 23 sent_size: 8.3 MB recv_size: 37.2 MB\n",
      "\u001b[36mindex\u001b[0m |\u001b[32m███\u001b[0m                 | 📃  11500 ⏱️ 19.5s 🐎 590.7/s     23      batch\u001b[32m    19 seconds (19.48s)\u001b[0m\n",
      "        gateway@6727[I]:#sent: 23 #recv: 23 sent_size: 8.6 MB recv_size: 8.6 MB\n",
      "\t\u001b[32m✅ done in ⏱ 19 seconds 🐎 590.3/s\u001b[0m\n",
      "        gateway@6716[S]:\u001b[32mterminated\u001b[0m\n",
      "    doc_indexer@6726[I]:recv ControlRequest  from ctl\u001b[32m▸\u001b[0mdoc_indexer/ZEDRuntime\u001b[32m▸\u001b[0m⚐\n",
      "    doc_indexer@6726[I]:#sent: 24 #recv: 24 sent_size: 8.6 MB recv_size: 37.2 MB\n",
      "   NumpyIndexer@6726[I]:indexer size: 11314 physical size: 43.4 MB\n",
      "   NumpyIndexer@6726[S]:\u001b[32martifacts of this executor (vecidx) is persisted to ./workspace/vecidx.bin\u001b[0m\n",
      "BinaryPbIndexer@6726[I]:indexer size: 11314 physical size: 45.0 MB\n",
      "BinaryPbIndexer@6726[S]:\u001b[32martifacts of this executor (docidx) is persisted to ./workspace/docidx.bin\u001b[0m\n",
      "   NumpyIndexer@6726[I]:no update since 2021-02-12 14:09:09, will not save. If you really want to save it, call \"touch()\" before \"save()\" to force saving\n",
      "BinaryPbIndexer@6726[I]:no update since 2021-02-12 14:09:09, will not save. If you really want to save it, call \"touch()\" before \"save()\" to force saving\n",
      "    doc_indexer@6726[I]:no update since 2021-02-12 14:08:49, will not save. If you really want to save it, call \"touch()\" before \"save()\" to force saving\n",
      "    doc_indexer@6716[S]:\u001b[32mterminated\u001b[0m\n",
      "        encoder@6725[I]:recv ControlRequest  from ctl\u001b[32m▸\u001b[0mencoder/ZEDRuntime\u001b[32m▸\u001b[0m⚐\n",
      "        encoder@6725[I]:#sent: 24 #recv: 24 sent_size: 37.2 MB recv_size: 8.6 MB\n",
      "        encoder@6725[I]:no update since 2021-02-12 14:08:49, will not save. If you really want to save it, call \"touch()\" before \"save()\" to force saving\n",
      "        encoder@6716[S]:\u001b[32mterminated\u001b[0m\n",
      "           Flow@6716[S]:\u001b[32mflow is closed and all resources are released, current build level is 0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "with f:\n",
    "    f.index(input_fn=index_generator, request_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-12T13:19:38.512635Z",
     "start_time": "2021-02-12T13:19:38.389551Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01_fetch_dataset.py                    \u001b[1m\u001b[34mflows\u001b[m\u001b[m/\r\n",
      "02_build_tfidf.py                      jina_search_20newsgroup_dataset.ipynb\r\n",
      "Dockerfile                             \u001b[1m\u001b[34mpods\u001b[m\u001b[m/\r\n",
      "README.md                              tfidf_vectorizer.pickle\r\n",
      "app.py                                 \u001b[1m\u001b[34mworkspace\u001b[m\u001b[m/\r\n",
      "\u001b[1m\u001b[34mdataset\u001b[m\u001b[m/\r\n"
     ]
    }
   ],
   "source": [
    "ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-12T13:19:41.242116Z",
     "start_time": "2021-02-12T13:19:41.239082Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 5)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-12T13:09:11.248332Z",
     "start_time": "2021-02-12T13:09:11.129315Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc.gz       doc.gz.head  docidx.bin   vec.gz       vecidx.bin\r\n"
     ]
    }
   ],
   "source": [
    "ls workspace/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect the embeddings created with  `index_generator`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-12T13:11:41.771787Z",
     "start_time": "2021-02-12T13:11:41.769301Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_embeddings(path, num_dim):    \n",
    "    with gzip.open(path, 'rb') as fp:\n",
    "        b = fp.read()\n",
    "        return np.frombuffer(b, dtype=np.float64).reshape([-1, num_dim])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-12T13:12:46.273798Z",
     "start_time": "2021-02-12T13:12:46.240430Z"
    }
   },
   "outputs": [],
   "source": [
    "f_embedding_method = open('./pods/tfidf_vectorizer.pickle','rb')\n",
    "embedder = pickle.load(f_embedding_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-12T13:13:35.949642Z",
     "start_time": "2021-02-12T13:13:35.947508Z"
    }
   },
   "outputs": [],
   "source": [
    "n_dimensions = len(embedder.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-12T13:14:15.721024Z",
     "start_time": "2021-02-12T13:14:03.559889Z"
    }
   },
   "outputs": [],
   "source": [
    "path = './workspace/vec.gz' \n",
    "X = load_embeddings(path, n_dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-12T13:16:00.618502Z",
     "start_time": "2021-02-12T13:16:00.615093Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5657, 101631), 56570)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-12T13:15:38.221565Z",
     "start_time": "2021-02-12T13:15:38.215366Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<10x101631 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1315 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedder.transform(df['text'][0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query a document\n",
    "\n",
    "\n",
    "Now that we have the documents stored as a `vec.gz` we can search for similar documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-12T15:23:27.421363Z",
     "start_time": "2021-02-12T15:23:27.416831Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def print_resp(resp, text):\n",
    "    \"\"\"\n",
    "    Print response.\n",
    "    \"\"\"\n",
    "    for d in resp.search.docs:\n",
    "        print(f\"Ranked list of related documents: {text} \\n\")\n",
    "\n",
    "        # d.matches contains the closests top_k documents in order \n",
    "        # from closer to farther from the query.\n",
    "        for idx, match in enumerate(d.matches):\n",
    "\n",
    "            score = match.score.value\n",
    "            if score < 0.0:\n",
    "                continue\n",
    "            answer = match.text.strip()\n",
    "            print(f'> {idx+1:>2d}. \"{answer}\"\\n Score: ({score:.2f})')\n",
    "\n",
    "\n",
    "def search():\n",
    "    \"\"\"\n",
    "    Search results using Query Flow.\n",
    "    \"\"\"\n",
    "    f = Flow.load_config('flows/query.yml')\n",
    "\n",
    "    with f:\n",
    "        while True:\n",
    "            text = input(\"Introduce a sentece as query: \")\n",
    "            if not text:\n",
    "                break\n",
    "\n",
    "            def ppr(x):\n",
    "                print_resp(x, text)\n",
    "\n",
    "            f.search_lines(lines=[text, ], on_done=ppr, top_k=2, line_format=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-12T15:24:20.063141Z",
     "start_time": "2021-02-12T15:23:29.160495Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        encoder@8296[I]:starting jina.peapods.runtimes.zmq.zed.ZEDRuntime...\n",
      "        encoder@8296[I]:input \u001b[33mtcp://0.0.0.0:59879\u001b[0m (PULL_BIND) output \u001b[33mtcp://0.0.0.0:59883\u001b[0m (PUSH_CONNECT) control over \u001b[33mtcp://0.0.0.0:59878\u001b[0m (PAIR_BIND)\n",
      "    doc_indexer@8297[I]:starting jina.peapods.runtimes.zmq.zed.ZEDRuntime...\n",
      "    doc_indexer@8297[I]:input \u001b[33mtcp://0.0.0.0:59883\u001b[0m (PULL_BIND) output \u001b[33mtcp://0.0.0.0:59884\u001b[0m (PUSH_BIND) control over \u001b[33mtcp://0.0.0.0:59882\u001b[0m (PAIR_BIND)\n",
      "        gateway@8298[I]:starting jina.peapods.runtimes.asyncio.grpc.GRPCRuntime...\n",
      "TFIDFTextEncoder@8296[I]:post_init may take some time...\n",
      "        gateway@8298[I]:input \u001b[33mtcp://0.0.0.0:59884\u001b[0m (PULL_CONNECT) output \u001b[33mtcp://0.0.0.0:59879\u001b[0m (PUSH_CONNECT) control over \u001b[33mipc:///var/folders/05/h71x7gh54sx_5y43ppkq9_dw0000gq/T/tmpr2xpve_p\u001b[0m (PAIR_BIND)\n",
      "        gateway@8298[S]:\u001b[32mGRPCRuntime is listening at: 0.0.0.0:59889\u001b[0m\n",
      "   NumpyIndexer@8297[I]:post_init may take some time...\n",
      "   NumpyIndexer@8297[I]:post_init may take some time takes 0 seconds (0.00s)\n",
      "   NumpyIndexer@8297[S]:\u001b[32mrestore NumpyIndexer from ./workspace/vecidx.bin\u001b[0m\n",
      "BinaryPbIndexer@8297[I]:post_init may take some time...\n",
      "BinaryPbIndexer@8297[I]:post_init may take some time takes 0 seconds (0.00s)\n",
      "BinaryPbIndexer@8297[S]:\u001b[32mrestore BinaryPbIndexer from ./workspace/docidx.bin\u001b[0m\n",
      "TFIDFTextEncoder@8296[I]:post_init may take some time takes 0 seconds (0.04s)\n",
      "CompoundIndexer@8297[I]:post_init may take some time...\n",
      "TFIDFTextEncoder@8296[S]:\u001b[32msuccessfully built TFIDFTextEncoder from a yaml config\u001b[0m\n",
      "CompoundIndexer@8297[I]:post_init may take some time takes 0 seconds (0.01s)\n",
      "        encoder@6716[S]:\u001b[32mready and listening\u001b[0m\n",
      "CompoundIndexer@8297[S]:\u001b[32msuccessfully built CompoundIndexer from a yaml config\u001b[0m\n",
      "    doc_indexer@6716[S]:\u001b[32mready and listening\u001b[0m\n",
      "        gateway@6716[S]:\u001b[32mready and listening\u001b[0m\n",
      "           Flow@6716[I]:3 Pods (i.e. 3 Peas) are running in this Flow\n",
      "           Flow@6716[S]:\u001b[32m🎉 Flow is ready to use, accepting \u001b[1mgRPC request\u001b[0m\u001b[0m\n",
      "           Flow@6716[I]:\n",
      "\t🖥️ Local access:\t\u001b[4m\u001b[36mtcp://0.0.0.0:59889\u001b[0m\n",
      "\t🔒 Private network:\t\u001b[4m\u001b[36mtcp://192.168.10.100:59889\u001b[0m\n",
      "\t🌐 Public address:\t\u001b[4m\u001b[36mtcp://213.195.114.251:59889\u001b[0m\n",
      "Please type a question: The operating system that the Apple computer use is usually more stable than Windows.\n",
      "         Client@6716[S]:\u001b[32mconnected to the gateway at 0.0.0.0:59889!\u001b[0m\n",
      "\u001b[36msearch\u001b[0m |\u001b[32m█\u001b[0m                   | 📃      0 ⏱️ 0.0s 🐎 0.0/s      0      batchsearch ...\t        gateway@8298[I]:prefetching 50 requests...\n",
      "        gateway@8298[W]:\u001b[40m\u001b[33mif this takes too long, you may want to take smaller \"--prefetch\" or ask client to reduce \"--request-size\"\u001b[0m\n",
      "        gateway@8298[I]:prefetching 50 requests takes 0 seconds (0.00s)\n",
      "        encoder@8296[I]:recv SearchRequest  from gateway\u001b[32m▸\u001b[0mencoder/ZEDRuntime\u001b[32m▸\u001b[0m⚐\n",
      "        encoder@8296[I]:#sent: 0 #recv: 1 sent_size: 0 Bytes recv_size: 542 Bytes\n",
      "    doc_indexer@8297[I]:recv SearchRequest  from gateway\u001b[32m▸\u001b[0mencoder/ZEDRuntime\u001b[32m▸\u001b[0mdoc_indexer/ZEDRuntime\u001b[32m▸\u001b[0m⚐\n",
      "   NumpyIndexer@8297[I]:loading index from ./workspace/vec.gz...\n",
      "   NumpyIndexer@8297[I]:indexer size: 11314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidbuchaca1/Documents/git_stuff/jina/jina/executors/indexers/vector.py:278: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return A / np.linalg.norm(A, ord=2, axis=1, keepdims=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BinaryPbIndexer@8297[I]:indexer size: 11314\n",
      "    doc_indexer@8297[I]:#sent: 0 #recv: 1 sent_size: 0 Bytes recv_size: 397.6 KB\n",
      "Enter a snippet of text used as query: The operating system that the Apple computer use is usually more stable than Windows. \n",
      "\n",
      ">  1. \"This is the official Request for Discussion (RFD) for the creation of two\n",
      "new newsgroups for Microsoft Windows NT.  This is a second RFD, replacing\n",
      "the one originally posted in January '93 (and never taken to a vote).  The\n",
      "proposed groups are described below:\n",
      "\n",
      "NAME: \t comp.os.ms-windows.nt.setup\n",
      "STATUS:  Unmoderated.\n",
      "PURPOSE: Discussions about setting up and installing Windows NT, and about\n",
      "\t system and peripheral compatability issues for Windows NT.\n",
      "\n",
      "NAME:\t comp.os.ms-windows.nt.misc\n",
      "STATUS:\t Unmoderated.\n",
      "PURPOSE: Miscellaneous non-programming discussions about using Windows NT,\n",
      "\t including issues such as security, networking features, console\n",
      "\t mode and Windows 3.1 (Win16) compatability.\n",
      "\n",
      "RATIONALE:\n",
      "\tMicrosoft NT is the newest member of the Microsoft Windows family\n",
      "\tof operating systems (or operating environments for those who wish\n",
      "\tto argue about the meaning of an \"OS\").  The family ranges from\n",
      "\tModular Windows through Windows 3.1 and Windows for Workgroups to\n",
      "\tWindows NT at the high end.  To date, Microsoft has shipped over\n",
      "\t50,000 beta copies and pre-release SDKs of Windows NT -- the\n",
      "\tactual release is slated for May/June '93.\n",
      "\n",
      "\tWhile Windows NT has an entirely new design internally, it shares\n",
      "\tan application programming interface with the other members of the\n",
      "\tWindows family; its Win32 API includes the Win16 API used in Win-\n",
      "\tdows 3.1, and the Win32s API subset (Win32 less threads, networking\n",
      "\tand security) can be used to create 32-bit applications for\n",
      "\tWindows 3.1.\n",
      "\n",
      "\tThe user interface is also practically identical to that of Windows\n",
      "\t3.1, with the addition of logins and a few other features.  It uses\n",
      "\tProgram Manager, File Manager and other applets, and generally pre-\n",
      "\tsents an identical appearance to the user.  Many of the announced\n",
      "\tWindows NT applications are ports of existing Windows 3.1 apps, and\n",
      "\tNT also runs existing 3.1 applications.\n",
      "\n",
      "\tThus, it appears logical that Windows NT should share the following\n",
      "\tgroups with the other members of the Windows family:\n",
      "\t\tcomp.os.ms-windows.apps\n",
      "\t\tcomp.os.ms-windows.programmer.tools\n",
      "\t\tcomp.os.ms-windows.programmer.misc\n",
      "\t\tcomp.os.ms-windows.programmer.win32\n",
      "\t\n",
      "\tThe following groups are also clearly applicable to Windows NT as\n",
      "\twell as Windows 3.1:\n",
      "\t\tcomp.os.ms-windows.announce\n",
      "\t\tcomp.os.ms-windows.advocacy\n",
      "\t\n",
      "\tIn conclusion, the only clear argument for the separation of the\n",
      "\tWindows 3.1 and Windows NT hierarchies is different internal\n",
      "\tstructures of Windows 3.1 and Windows NT.  And yet operating\n",
      "\tsystems such as OS/2, Macintosh OS, Xenix and Coherent all have\n",
      "\tundergone major rewrites without having been split into separate\n",
      "\tnewsgroup hierarchies.\n",
      "\n",
      "\tFurther, Windows 3.1 is due for a major rewrite itself in 1994 --\n",
      "\twhen the fully 32-bit, protected-mode and with-DOS-built-in next-\n",
      "\tgeneration Windows, \"Chicago\", debuts next year, surely it should\n",
      "\tremain in the same hierarchy.  And what, then, would be the jus-\n",
      "\ttification for separating Windows NT from other Windows versions?\n",
      "\n",
      "\n",
      "DISCUSSION PERIOD:\n",
      "\tThe discussion period will run from 27 April, 1992 to 18 May, 1993.  \n",
      "\n",
      "VOTING:\n",
      "\tThe CFV (Call for Votes) will be issued around 19 May, 1993, based on\n",
      "\tthe feedback received during the discussion period.  No votes will\n",
      "\tbe accepted prior to the CFV.\"\n",
      " Score: (0.76)\n",
      ">  2. \"In comp.os.ms-windows.misc you write:\n",
      "\n",
      "\n",
      "you might want to look in windows FAQ for this one, but here is my best\n",
      "explanation.  But I can't guarantee that I'm not way off base...\n",
      "\n",
      "The permenant swap file is read/written to by windows by talking\n",
      "directly to the hard disk controller card.  The controller card must\n",
      "use the protocal set up by western digital (or something like that).\n",
      "Windows creates a file called spart.par in your windows directory that\n",
      "points to that file.  It then uses the physical information about your\n",
      "disk to index to information in that file.\n",
      "\n",
      "compressed disks are actually \"logical\" disks.  These disks have different\n",
      "characteristics than the actual physical disk.  Furthermore, the information\n",
      "on the compressed disks must be uncompressed before it is used.  (i.e it must\n",
      "go through the decompression program that traps disk reads at the operating\n",
      "system level or the BIOS level).  Because of this \"inbetween\" program, windows\n",
      "cannot use direct methods to read from the \"logical\" disk.\n",
      "\n",
      "a permenant swap file is only there to \"reserve\" an area of the disk that\n",
      "windows can use and to block that space from DOS.  Windows would theoretically\n",
      "not even have to access the file from DOS to use that disk space. (I don't\n",
      "know if it does or doesn't...but it checks for it somewhere everytime you\n",
      "boot windows.)\n",
      "\n",
      "a temporary swap file is just a normal DOS file that is accessed by windows\n",
      "via DOS and the BIOS.  If a disk compression program or other TSR is loaded\n",
      "the file access must go through DOS...TSR'S (disk compression)...and BIOS in\n",
      "order to be access. (i.e. NEVER USE A TEMPORARY SWAP FILE...NEVER)\n",
      "\n",
      "more on permenent swap files...\n",
      "\n",
      "i'm sure everyone who has an uncompressed part of their compressed hard disk\n",
      "has seen the message \"you have selected a swap file greater than the suggested\n",
      "size...windows will only use the size suggested...do you wan't to create this\n",
      "swap file anyway\" or something like that.\n",
      "\n",
      "well, a friend of mine (ROBERT) called microsoft and asked them what and why.\n",
      "what they said is that windows checks the amount of free disk space and\n",
      "divides that number by 2.  Then it checks for the largest contiguous block\n",
      "of free disk space.  Windows then suggests the smaller of the two numbers.\n",
      "\n",
      "They also said that under absolutely no circumstances...NONE!...will windows\n",
      "uses a swap file larger than the suggested size.  Well...that's what he \n",
      "said!\n",
      "\n",
      "I call bull@#$#.  If this is true why does windows report the memory is\n",
      "available to me if it's not going to use it?\n",
      "\n",
      "any takers?\n",
      "\n",
      "James\"\n",
      " Score: (0.78)\n",
      "\u001b[36msearch\u001b[0m |\u001b[32m█\u001b[0m                   | 📃    100 ⏱️ 20.7s 🐎 4.8/s      1      batch\u001b[32m    20 seconds (20.70s)\u001b[0m\n",
      "\t\u001b[32m✅ done in ⏱ 20 seconds 🐎 4.8/s\u001b[0m\n",
      "Please type a question: \n",
      "        gateway@8298[I]:#sent: 1 #recv: 1 sent_size: 611 Bytes recv_size: 6.7 KB\n",
      "        gateway@6716[S]:\u001b[32mterminated\u001b[0m\n",
      "    doc_indexer@8297[I]:recv ControlRequest  from ctl\u001b[32m▸\u001b[0mdoc_indexer/ZEDRuntime\u001b[32m▸\u001b[0m⚐\n",
      "    doc_indexer@8297[I]:#sent: 2 #recv: 2 sent_size: 7.0 KB recv_size: 397.8 KB\n",
      "   NumpyIndexer@8297[I]:indexer size: 11314 physical size: 45.0 MB\n",
      "   NumpyIndexer@8297[I]:no update since 2021-02-12 14:08:49, will not save. If you really want to save it, call \"touch()\" before \"save()\" to force saving\n",
      "BinaryPbIndexer@8297[I]:indexer size: 11314 physical size: 45.0 MB\n",
      "BinaryPbIndexer@8297[I]:no update since 2021-02-12 14:08:49, will not save. If you really want to save it, call \"touch()\" before \"save()\" to force saving\n",
      "   NumpyIndexer@8297[I]:no update since 2021-02-12 14:08:49, will not save. If you really want to save it, call \"touch()\" before \"save()\" to force saving\n",
      "BinaryPbIndexer@8297[I]:no update since 2021-02-12 14:08:49, will not save. If you really want to save it, call \"touch()\" before \"save()\" to force saving\n",
      "    doc_indexer@8297[I]:no update since 2021-02-12 16:23:29, will not save. If you really want to save it, call \"touch()\" before \"save()\" to force saving\n",
      "    doc_indexer@6716[S]:\u001b[32mterminated\u001b[0m\n",
      "        encoder@8296[I]:recv ControlRequest  from ctl\u001b[32m▸\u001b[0mencoder/ZEDRuntime\u001b[32m▸\u001b[0m⚐\n",
      "        encoder@8296[I]:#sent: 2 #recv: 2 sent_size: 397.9 KB recv_size: 679 Bytes\n",
      "        encoder@8296[I]:no update since 2021-02-12 16:23:29, will not save. If you really want to save it, call \"touch()\" before \"save()\" to force saving\n",
      "        encoder@6716[S]:\u001b[32mterminated\u001b[0m\n",
      "           Flow@6716[S]:\u001b[32mflow is closed and all resources are released, current build level is 0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
