{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Sklearn-inside-a-Process\" data-toc-modified-id=\"Sklearn-inside-a-Process-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Sklearn inside a Process</a></span><ul class=\"toc-item\"><li><span><a href=\"#Spawn-a-single-Process\" data-toc-modified-id=\"Spawn-a-single-Process-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Spawn a single Process</a></span></li><li><span><a href=\"#Spawn-multiple-processes-in-parallel\" data-toc-modified-id=\"Spawn-multiple-processes-in-parallel-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Spawn multiple processes in parallel</a></span></li><li><span><a href=\"#Encapsulating-more-than-a-simple-fit\" data-toc-modified-id=\"Encapsulating-more-than-a-simple-fit-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Encapsulating more than a simple fit</a></span></li><li><span><a href=\"#Measure-Time-execution-time-of-a-process\" data-toc-modified-id=\"Measure-Time-execution-time-of-a-process-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Measure Time execution time of a process</a></span><ul class=\"toc-item\"><li><span><a href=\"#Timing-individually\" data-toc-modified-id=\"Timing-individually-1.4.1\"><span class=\"toc-item-num\">1.4.1&nbsp;&nbsp;</span>Timing individually</a></span></li><li><span><a href=\"#Two-at-a-time\" data-toc-modified-id=\"Two-at-a-time-1.4.2\"><span class=\"toc-item-num\">1.4.2&nbsp;&nbsp;</span>Two at a time</a></span></li><li><span><a href=\"#More-applications-than-resources\" data-toc-modified-id=\"More-applications-than-resources-1.4.3\"><span class=\"toc-item-num\">1.4.3&nbsp;&nbsp;</span>More applications than resources</a></span></li><li><span><a href=\"#Without-the-join.()\" data-toc-modified-id=\"Without-the-join.()-1.4.4\"><span class=\"toc-item-num\">1.4.4&nbsp;&nbsp;</span>Without the join.()</a></span></li><li><span><a href=\"#With-joblib\" data-toc-modified-id=\"With-joblib-1.4.5\"><span class=\"toc-item-num\">1.4.5&nbsp;&nbsp;</span>With joblib</a></span></li></ul></li><li><span><a href=\"#Control-resource-usage\" data-toc-modified-id=\"Control-resource-usage-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Control resource usage</a></span></li></ul></li><li><span><a href=\"#Scheduling--processes/resources\" data-toc-modified-id=\"Scheduling--processes/resources-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Scheduling  processes/resources</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#n_jobs\" data-toc-modified-id=\"n_jobs-2.0.1\"><span class=\"toc-item-num\">2.0.1&nbsp;&nbsp;</span>n_jobs</a></span></li><li><span><a href=\"#pre_dispatch\" data-toc-modified-id=\"pre_dispatch-2.0.2\"><span class=\"toc-item-num\">2.0.2&nbsp;&nbsp;</span>pre_dispatch</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn inside a Process\n",
    "\n",
    "\n",
    "Sklearn gridsearch memory\n",
    "\n",
    "- https://stackoverflow.com/questions/24406937/scikit-learn-joblib-bug-multiprocessing-pool-self-value-out-of-range-for-i-fo/24411581#24411581\n",
    "\n",
    "\n",
    "Working with numerical data in shared memory (memmaping)\n",
    "- https://pythonhosted.org/joblib/parallel.html#working-with-numerical-data-in-shared-memory-memmaping\n",
    "\n",
    "Set number cpus julia\n",
    "- https://stackoverflow.com/questions/27931026/obtain-the-number-of-cpu-cores-in-julia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MNIST_path = \"/home/david/Datasets/MNIST/train_mnist.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from os.path import expanduser\n",
    "home = expanduser(\"~\")\n",
    "\n",
    "X_tr = pd.read_csv(os.path.join(home,\"Datasets/MNIST/train_mnist.csv\"), header=None)\n",
    "X_tr = X_tr.values\n",
    "y_tr = X_tr[:,0]\n",
    "X_tr = X_tr[:,1:]\n",
    "\n",
    "X_te = pd.read_csv(os.path.join(home,\"Datasets/MNIST/test_mnist.csv\"), header=None)\n",
    "X_te = X_te.values\n",
    "y_te = X_te[:,0]\n",
    "X_te = X_te[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (10000, 784))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr.shape, X_te.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spawn a single Process\n",
    "\n",
    "Infor about the multiprocessing module\n",
    "- https://docs.python.org/2/library/multiprocessing.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
       "      fit_intercept=True, max_iter=None, n_iter=None, n_iter_no_change=5,\n",
       "      n_jobs=None, penalty=None, random_state=0, shuffle=True, tol=None,\n",
       "      validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.linear_model.Perceptron()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m1 = linear_model.Perceptron(n_jobs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code snippet prints true because the main Python process, the one executing the notebook is not blocked by the spawned process `p`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/anaconda/envs/py3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "p = mp.Process(target=m1.fit, args=(X_tr, y_tr))\n",
    "p.start()\n",
    "p.is_alive() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code snippet prints False because the `p.join()` blocks the Python process, the one executing the notebook, until  `p` ends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/anaconda/envs/py3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = mp.Process(target=m1.fit, args=(X_tr, y_tr))\n",
    "p.start()\n",
    "p.join()\n",
    "p.is_alive() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spawn multiple processes in parallel\n",
    "\n",
    "We can define several Python Process objects and start them in parallel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m1 = linear_model.Perceptron(n_jobs=1)\n",
    "m2 = linear_model.Perceptron(n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p1 = mp.Process(target=m1.fit, args=(X_tr, y_tr))\n",
    "p2 = mp.Process(target=m2.fit, args=(X_tr, y_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/anaconda/envs/py3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/david/anaconda/envs/py3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "p1.start()\n",
    "p2.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1.is_alive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2.is_alive()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encapsulating more than a simple fit\n",
    "\n",
    "Assume we want to fit in parallel different models and once fitted we want to generate predictions for a test set.\n",
    "\n",
    "Let us create a function that recieves as input a model, data to train the model, and test data to generate predictions. That is `fit_and_return_test_preds(model, X_tr, y_tr, X_te)`.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# y_preds = np.zeros(sample_submission.shape[0])\n",
    "# y_oof   = np.zeros(X_train.shape[0])\n",
    "# \n",
    "# 253     clf = pipe_cv.best_estimator_\n",
    "# 254     X_tr, X_vl = X_train.iloc[tr_idx, :], X_train.iloc[val_idx, :]\n",
    "# 255     y_tr, y_vl = y_train.iloc[tr_idx], y_train.iloc[val_idx]\n",
    "# 256     clf.fit(X_tr, y_tr)\n",
    "# 257     y_pred_train = clf.predict_proba(X_vl)[:,1]\n",
    "# 258     y_oof[val_idx] = y_pred_train\n",
    "# 259     print('ROC AUC {}'.format(roc_auc_score(y_vl, y_pred_train)))\n",
    "# 260     y_preds+= clf.predict_proba(X_test)[:,1]/EPOCHS\n",
    "# 261\n",
    "# 262\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def fit_and_return_preds(p_id,\n",
    "                         return_predictions,\n",
    "                         model, \n",
    "                         X:                pd.core.frame.DataFrame or np.ndarray,\n",
    "                         y:                pd.core.frame.DataFrame or np.ndarray,\n",
    "                         tr_idx:              np.ndarray or list,\n",
    "                         va_idx:              np.ndarray or list, \n",
    "                         X_te:                pd.core.frame.DataFrame or np.ndarray,\n",
    "                         evaluation_metric):\n",
    "    \"\"\"\n",
    "    This function is meant to be used to train a model on the rows of `X` specified by `tr_idx`.\n",
    "    Then it computes valudation metric in the rows `val_idx`.\n",
    "    Finally it computes predictions on `X_te`\n",
    "    \"\"\"\n",
    "    assert type(X) in [pd.DataFrame, np.ndarray], \"type(X)={} but it should be a pd.DataFrame or np.ndarray\".format(type(X))\n",
    "    assert type(y) in [pd.DataFrame, np.ndarray], \"type(y)={} but it should be a pd.DataFrame or np.ndarray\".format(type(X))\n",
    "    assert type(tr_idx)== np.ndarray, \"type(tr_idx)={} but it should be a np.ndarray\".format(type(train_idx))\n",
    "    assert type(va_idx)== np.ndarray, \"type(va_idx)={} but it should be a np.ndarray\".format(type(train_idx))\n",
    "    \n",
    "    if type(X) == pd.DataFrame:\n",
    "        X_tr, X_va = X.iloc[tr_idx, :],  X.iloc[va_idx, :]\n",
    "        y_tr, y_va = y.iloc[tr_idx],     y.iloc[va_idx]\n",
    "    else:\n",
    "        X_tr, X_va = X[tr_idx, :],  X[va_idx, :]\n",
    "        y_tr, y_va = y[tr_idx],     y[va_idx]\n",
    "        \n",
    "    model    = model.fit(X_tr, y_tr)\n",
    "    y_te_hat = model.predict(X_te)\n",
    "        \n",
    "    y_tr_pred = model.predict_proba(X_tr)[:,1]\n",
    "    y_va_pred = model.predict_proba(X_va)[:,1]\n",
    "    print('{} train: {}'.format(evaluation_metric.__name__, evaluation_metric(y_tr, y_tr_pred)))\n",
    "    print('{} valid: {}'.format(evaluation_metric.__name__, evaluation_metric(y_va, y_va_pred)))\n",
    "\n",
    "    y_te_pred = model.predict_proba(X_te)[:,1]\n",
    "    \n",
    "    return_predictions[p_id] = y_te_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import multiprocessing as mp\n",
    "\n",
    "def fit_and_average_k_models(model, X, y, X_te, k):\n",
    "    \n",
    "    manager            = mp.Manager()\n",
    "    return_predictions = manager.dict()\n",
    "    evaluation_function = sklearn.metrics.roc_auc_score\n",
    "    kf = sklearn.model_selection.KFold(n_splits = k, shuffle = True)\n",
    "    \n",
    "    processes=[]\n",
    "    for p_id, (tr_idx, va_idx) in enumerate(kf.split(X, y)):\n",
    "        processes.append(mp.Process(target=fit_and_return_preds, \n",
    "                                    args=(p_id, return_predictions, \n",
    "                                          copy.deepcopy(model),\n",
    "                                          X, y , tr_idx, va_idx, X_te, evaluation_function)))\n",
    "\n",
    "    for p in processes:\n",
    "        p.start()\n",
    "        \n",
    "    for p in processes:\n",
    "        p.join()\n",
    "        \n",
    "    y_pred = np.zeros(X_te.shape[0])\n",
    "    for y_k in return_predictions.values():\n",
    "        y_pred += y_k\n",
    "    \n",
    "    y_pred = y_pred/k\n",
    "    \n",
    "    return y_pred, return_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-639995373ac8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minds_01\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_or\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_tr\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_tr\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_tr_01\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_tr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minds_01\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my_tr_01\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_tr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minds_01\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0minds_01\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_or\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_te\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_te\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "inds_01 = np.logical_or(y_tr==0,y_tr==1)\n",
    "X_tr_01 = X_tr[inds_01,:]\n",
    "y_tr_01 = y_tr[inds_01]\n",
    "\n",
    "inds_01 = np.logical_or(y_te==0,y_te==1)\n",
    "X_te_01 = X_te[inds_01,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_tr_01' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-8e39ebb56841>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_tr_01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tr_01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_te_01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'y_tr_01' is not defined"
     ]
    }
   ],
   "source": [
    "len(y_tr_01), len(X_tr_01), len(X_te_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/anaconda/envs/py3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/david/anaconda/envs/py3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc_score train: 0.999880379961358\n",
      "roc_auc_score valid: 0.999308584193171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/anaconda/envs/py3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc_score train: 0.9997705203676407\n",
      "roc_auc_score valid: 0.9999991962060928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/anaconda/envs/py3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc_score train: 0.9998824024211869\n",
      "roc_auc_score valid: 0.9999800033034543\n",
      "roc_auc_score train: 0.9999927026591687\n",
      "roc_auc_score valid: 0.9999843467099393\n"
     ]
    }
   ],
   "source": [
    "model = sklearn.neural_network.MLPClassifier(hidden_layer_sizes=[30], max_iter=2)\n",
    "y_pred, return_predictions = fit_and_average_k_models(model, X_tr_01, y_tr_01, X_te_01, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure Time execution time of a process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m1 = linear_model.Perceptron(n_jobs=1, n_iter=30)\n",
    "m2 = linear_model.Perceptron(n_jobs=1, n_iter=30)\n",
    "m3 = linear_model.Perceptron(n_jobs=1, n_iter=30)\n",
    "m4 = linear_model.Perceptron(n_jobs=1, n_iter=30)\n",
    "\n",
    "p1 = mp.Process(target=m1.fit, args=(X_tr, y_tr))\n",
    "p2 = mp.Process(target=m2.fit, args=(X_tr, y_tr))\n",
    "p3 = mp.Process(target=m3.fit, args=(X_tr, y_tr))\n",
    "p4 = mp.Process(target=m4.fit, args=(X_tr, y_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "p1.start()\n",
    "p2.start()\n",
    "p3.start()\n",
    "p4.start()\n",
    "p1.join()\n",
    "p2.join()\n",
    "p3.join()\n",
    "p4.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m1 = linear_model.Perceptron(n_jobs=2, n_iter=30)\n",
    "m2 = linear_model.Perceptron(n_jobs=2, n_iter=30)\n",
    "m3 = linear_model.Perceptron(n_jobs=2, n_iter=30)\n",
    "m4 = linear_model.Perceptron(n_jobs=2, n_iter=30)\n",
    "\n",
    "p1 = mp.Process(target=m1.fit, args=(X_tr, y_tr))\n",
    "p2 = mp.Process(target=m2.fit, args=(X_tr, y_tr))\n",
    "p3 = mp.Process(target=m3.fit, args=(X_tr, y_tr))\n",
    "p4 = mp.Process(target=m4.fit, args=(X_tr, y_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "p1.start()\n",
    "p2.start()\n",
    "p1.join()\n",
    "p2.join()\n",
    "p3.start()\n",
    "p4.start()\n",
    "p3.join()\n",
    "p4.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m1 = linear_model.Perceptron(n_jobs=4, n_iter=30)\n",
    "m2 = linear_model.Perceptron(n_jobs=4, n_iter=30)\n",
    "m3 = linear_model.Perceptron(n_jobs=4, n_iter=30)\n",
    "m4 = linear_model.Perceptron(n_jobs=4, n_iter=30)\n",
    "\n",
    "p1 = mp.Process(target=m1.fit, args=(X_tr, y_tr))\n",
    "p2 = mp.Process(target=m2.fit, args=(X_tr, y_tr))\n",
    "p3 = mp.Process(target=m3.fit, args=(X_tr, y_tr))\n",
    "p4 = mp.Process(target=m4.fit, args=(X_tr, y_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "p1.start()\n",
    "p1.join()\n",
    "p2.start()\n",
    "p2.join()\n",
    "p3.start()\n",
    "p3.join()\n",
    "p4.start()\n",
    "p4.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m1 = linear_model.Perceptron(n_jobs=3, n_iter=30)\n",
    "m2 = linear_model.Perceptron(n_jobs=1, n_iter=30)\n",
    "m3 = linear_model.Perceptron(n_jobs=3, n_iter=30)\n",
    "m4 = linear_model.Perceptron(n_jobs=1, n_iter=30)\n",
    "\n",
    "p1 = mp.Process(target=m1.fit, args=(X_tr, y_tr))\n",
    "p2 = mp.Process(target=m2.fit, args=(X_tr, y_tr))\n",
    "p3 = mp.Process(target=m3.fit, args=(X_tr, y_tr))\n",
    "p4 = mp.Process(target=m4.fit, args=(X_tr, y_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "p1.start()\n",
    "p2.start()\n",
    "p1.join()\n",
    "p2.join()\n",
    "p3.start()\n",
    "p4.start()\n",
    "p3.join()\n",
    "p4.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Timing individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "m1 = linear_model.Perceptron(n_jobs=4, n_iter=30)\n",
    "p1 = mp.Process(target=m1.fit, args=(X_tr, y_tr))\n",
    "p1.start()\n",
    "p1.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "m1 = linear_model.Perceptron(n_jobs=3, n_iter=30)\n",
    "p1 = mp.Process(target=m1.fit, args=(X_tr, y_tr))\n",
    "p1.start()\n",
    "p1.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "m1 = linear_model.Perceptron(n_jobs=2, n_iter=30)\n",
    "p1 = mp.Process(target=m1.fit, args=(X_tr, y_tr))\n",
    "p1.start()\n",
    "p1.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "m1 = linear_model.Perceptron(n_jobs=1, n_iter=30)\n",
    "p1 = mp.Process(target=m1.fit, args=(X_tr, y_tr))\n",
    "p1.start()\n",
    "p1.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Two at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "m1 = linear_model.Perceptron(n_jobs=1, n_iter=30)\n",
    "p1 = mp.Process(target=m1.fit, args=(X_tr, y_tr))\n",
    "m2 = linear_model.Perceptron(n_jobs=1, n_iter=30)\n",
    "p2 = mp.Process(target=m1.fit, args=(X_tr, y_tr))\n",
    "p1.start()\n",
    "p2.start()\n",
    "p2.join()\n",
    "p1.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "m1 = linear_model.Perceptron(n_jobs=1, n_iter=30)\n",
    "p1 = mp.Process(target=m1.fit, args=(X_tr, y_tr))\n",
    "m2 = linear_model.Perceptron(n_jobs=1, n_iter=30)\n",
    "p2 = mp.Process(target=m1.fit, args=(X_tr, y_tr))\n",
    "m3 = linear_model.Perceptron(n_jobs=1, n_iter=30)\n",
    "p3 = mp.Process(target=m1.fit, args=(X_tr, y_tr))\n",
    "m4 = linear_model.Perceptron(n_jobs=1, n_iter=30)\n",
    "p4 = mp.Process(target=m1.fit, args=(X_tr, y_tr))\n",
    "\n",
    "p1.start()\n",
    "p2.start()\n",
    "p2.join()\n",
    "p1.join()\n",
    "p3.start()\n",
    "p4.start()\n",
    "p3.join()\n",
    "p4.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "m1 = linear_model.Perceptron(n_jobs=1, n_iter=30)\n",
    "p1 = mp.Process(target=m1.fit, args=(X_tr, y_tr))\n",
    "m2 = linear_model.Perceptron(n_jobs=1, n_iter=30)\n",
    "p2 = mp.Process(target=m1.fit, args=(X_tr, y_tr))\n",
    "m3 = linear_model.Perceptron(n_jobs=1, n_iter=30)\n",
    "p3 = mp.Process(target=m1.fit, args=(X_tr, y_tr))\n",
    "m4 = linear_model.Perceptron(n_jobs=1, n_iter=30)\n",
    "p4 = mp.Process(target=m1.fit, args=(X_tr, y_tr))\n",
    "\n",
    "p1.start()\n",
    "p2.start()\n",
    "p3.start()\n",
    "p4.start()\n",
    "p2.join()\n",
    "p1.join()\n",
    "p3.join()\n",
    "p4.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More applications than resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "m1 = linear_model.Perceptron(n_jobs=1, n_iter=30)\n",
    "p1 = mp.Process(target=m1.fit, args=(X_tr, y_tr))\n",
    "m2 = linear_model.Perceptron(n_jobs=1, n_iter=30)\n",
    "p2 = mp.Process(target=m2.fit, args=(X_tr, y_tr))\n",
    "m3 = linear_model.Perceptron(n_jobs=1, n_iter=30)\n",
    "p3 = mp.Process(target=m3.fit, args=(X_tr, y_tr))\n",
    "m4 = linear_model.Perceptron(n_jobs=1, n_iter=30)\n",
    "p4 = mp.Process(target=m4.fit, args=(X_tr, y_tr))\n",
    "m5 = linear_model.Perceptron(n_jobs=1, n_iter=30)\n",
    "p5 = mp.Process(target=m5.fit, args=(X_tr, y_tr))\n",
    "m6 = linear_model.Perceptron(n_jobs=1, n_iter=30)\n",
    "p6 = mp.Process(target=m6.fit, args=(X_tr, y_tr))\n",
    "\n",
    "p1.start()\n",
    "p2.start()\n",
    "p3.start()\n",
    "p4.start()\n",
    "p5.start()\n",
    "p6.start()\n",
    "\n",
    "p2.join()\n",
    "p1.join()\n",
    "p3.join()\n",
    "p4.join()\n",
    "p5.join()\n",
    "p6.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "m1 = linear_model.Perceptron(n_jobs=2, n_iter=30)\n",
    "p1 = mp.Process(target=m1.fit, args=(X_tr, y_tr))\n",
    "m2 = linear_model.Perceptron(n_jobs=1, n_iter=30)\n",
    "p2 = mp.Process(target=m2.fit, args=(X_tr, y_tr))\n",
    "m3 = linear_model.Perceptron(n_jobs=1, n_iter=30)\n",
    "p3 = mp.Process(target=m3.fit, args=(X_tr, y_tr))\n",
    "m4 = linear_model.Perceptron(n_jobs=1, n_iter=30)\n",
    "p4 = mp.Process(target=m4.fit, args=(X_tr, y_tr))\n",
    "m5 = linear_model.Perceptron(n_jobs=2, n_iter=30)\n",
    "p5 = mp.Process(target=m5.fit, args=(X_tr, y_tr))\n",
    "m6 = linear_model.Perceptron(n_jobs=2, n_iter=30)\n",
    "p6 = mp.Process(target=m6.fit, args=(X_tr, y_tr))\n",
    "\n",
    "p1.start()\n",
    "p2.start()\n",
    "p3.start()\n",
    "p4.start()\n",
    "p2.join()\n",
    "p5.start()\n",
    "p6.start()\n",
    "p1.join()\n",
    "p3.join()\n",
    "p4.join()\n",
    "p5.join()\n",
    "p6.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Without the join.()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m1 = linear_model.Perceptron(n_jobs=2, n_iter=30)\n",
    "m2 = linear_model.Perceptron(n_jobs=2, n_iter=30)\n",
    "m3 = linear_model.Perceptron(n_jobs=2, n_iter=30)\n",
    "m4 = linear_model.Perceptron(n_jobs=2, n_iter=30)\n",
    "\n",
    "p1 = mp.Process(target=m1.fit, args=(X_tr, y_tr))\n",
    "p2 = mp.Process(target=m2.fit, args=(X_tr, y_tr))\n",
    "p3 = mp.Process(target=m3.fit, args=(X_tr, y_tr))\n",
    "p4 = mp.Process(target=m4.fit, args=(X_tr, y_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "p1.start()\n",
    "p2.start()\n",
    "p3.start()\n",
    "p4.start()\n",
    "\n",
    "p1.join()\n",
    "p2.join()\n",
    "p3.join()\n",
    "p4.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With joblib\n",
    "\n",
    "\n",
    "- https://machinelearningmastery.com/save-load-machine-learning-models-python-scikit-learn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "from joblib import Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mem = Memory(cachedir=\"/tmp/joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m1 = linear_model.Perceptron(n_jobs=1, n_iter=30)\n",
    "m2 = linear_model.Perceptron(n_jobs=1, n_iter=30)\n",
    "m3 = linear_model.Perceptron(n_jobs=1, n_iter=30)\n",
    "m4 = linear_model.Perceptron(n_jobs=1, n_iter=30)\n",
    "\n",
    "models = [m1, m2, m3, m4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Control resource usage\n",
    "- https://docs.python.org/2/library/resource.html#module-resource"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scheduling  processes/resources\n",
    "\n",
    "We would like to, given a set of models to train, control what resources each model is going to use.\n",
    "\n",
    "#### n_jobs\n",
    "\n",
    "    Number of jobs to run in parallel.\n",
    "\n",
    "\n",
    "Some models have the argument `n_jobs` which allows the implementation to use `n_jobs` jobs in parallel using `n_jobs` CPU threads. Not all models have the  `n_jobs`  parameter. \n",
    "\n",
    "#### pre_dispatch\n",
    "\n",
    "```\n",
    "Controls the number of jobs that get dispatched during parallel execution.\n",
    "\n",
    "Reducing this number can be useful to avoid an explosion of memory consumption when more jobs get dispatched than CPUs can process. This parameter can be:\n",
    "    \n",
    "    - None, in which case all the jobs are immediately created and spawned. Use this for lightweight and fast-running jobs, to avoid delays due to on-demand spawning of the jobs\n",
    "    - An int, giving the exact number of total jobs that are spawned\n",
    "    - A string, giving an expression as a function of n_jobs, as in ‘2*n_jobs’\n",
    "```\n",
    "\n",
    "Some functions like `sklearn.model_selection.GridSearchCV` \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
